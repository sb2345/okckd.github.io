<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Design | Woodstock Blog]]></title>
  <link href="http://okckd.github.io/blog/categories/design/atom.xml" rel="self"/>
  <link href="http://okckd.github.io/"/>
  <updated>2015-02-05T23:59:04+08:00</updated>
  <id>http://okckd.github.io/</id>
  <author>
    <name><![CDATA[Charlie Brown]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[[Design] Winning Games Rank (Pagerank)]]></title>
    <link href="http://okckd.github.io/blog/2015/02/05/winning-game-rank-pagerank/"/>
    <updated>2015-02-05T00:00:00+08:00</updated>
    <id>http://okckd.github.io/blog/2015/02/05/winning-game-rank-pagerank</id>
    <content type="html"><![CDATA[### Question

> We have a history of match result of pingpong games, assume each match is <player1, player2, result, timestamp>, player1 and player2 are long type, result is a bit value (1 means player1 win). 

> design a algorithm to sort the players by their possibility to win future games. 

### Solution

For each play, 

> winning score = score_diff * {delay factor^(current time - winning time)}; 

### Pagerank 

[PageRank](http://google.about.com/od/searchengineoptimization/a/pagerankexplain.htm) is what Google uses to __determine the importance of a web page__. 

It determines which pages appear in search results.

Named after Larry Page. 

#### Details

1. PageRank thinks of links as votes to another page.

1. It also looks at the importance of the page that contains the link. 
    
    1. Pages with __higher PageRank__ have more weight in "voting". 
    
    1. Pages with __smaller total number of links__ on the page have more weight.

#### Increase your PageRank?

If you'd like to increase your PageRank, you need to have "back-links," or other people linking to your website. You can __trade links__ with other people, but make sure you only trade relevant links, and make sure you're not trading links with a __link farm__. 

You can register your website with directories, such as the __Open Directory Project__, but use directories with high PageRank whenever possible.

You can create some of __your own back-links__ by linking to relevant pages __within__ your own website. However, remember that the number of links you create counts into the equation. Don't overdo it.
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[[Design] Speed Up Webpage for Slow Connection (2)]]></title>
    <link href="http://okckd.github.io/blog/2015/02/05/speed-up-web-page-2/"/>
    <updated>2015-02-05T00:00:00+08:00</updated>
    <id>http://okckd.github.io/blog/2015/02/05/speed-up-web-page-2</id>
    <content type="html"><![CDATA[[ref](www.geeksforgeeks.org/amazon-interview-set-72-campus-sde-1)

### Question

> Suppose you are handling Amazon website and you have 10 MB size home page. Optimize the homepage for a customer who has 100 kbps internet connection.

> Further he asked for the customer who has 100 mbps internet connection.

### Website KPI

There are [3 interesting phases](https://community.compuwareapm.com/community/display/PUB/Best+Practices+on+Web+Site+Performance+Optimization) of a web site from an end-user performance perspective. 

1. First Impression
1. OnLoad 
1. Fully Loaded Time.

### Loading Time

__Question: what percentage of the time a user spends waiting for your page to load is spent after the HTML comes back to their browser__? 

It is typically __[over 90%](http://www.sitepoint.com/seven-mistakes-that-make-websites-slow/)__. 

Most of the time users spend waiting on your website is spent after the HTML page has been retrieved by their browser. 

#### Fetching the HTML is just the beginning

__In a nutshell, browsers parse your page’s HTML, sequentially discovering its assets__ (such as scripts, stylesheets, and images), requesting and then either parsing and executing them or displaying them as appropriate. 

But these assets are not simply fetched all at once. Instead, the __browser opens a limited number of connections to the server(s)__ referenced by the page. There is __overhead involved in establishing TCP and HTTP connections__, and some __unavoidable latency__ in pushing the request and response bytes back and forth across the network.

So, in general, round trips between the browser and server are expensive. The structure of the HTML markup, the number and the ordering of its assets, are absolutely critical factors in its performance.

### What hijacks your load time

#### 1. Too Many HTTP Requests

This is the single biggest contributor to performance problems in most web pages. 

1. Concatenate scripts and stylesheets

1. Combine images with sprites (put common images into a single large image file, then use CSS to position and selectively display the appropriate portion of the sprite image)

1. Use fewer images, more CSS. 

#### 2. Minimal Client-side Processing

1. Validation on client. (eg. form input)

1. Use web standards and MVC separation, making a maintainable, accessible, future-proof and max-performance website. 

    Think of the HTML as the model, the CSS as the view, and the JavaScript as the controller. This separation tends to make code more efficient and maintainable, and makes many optimization techniques much more practical to apply.

1. Push presentation code into the client tier (eg. Charts and graphs — push raw data to the client in JSON format, and use JavaScript and CSS to create pretty graphs.)

1. Leverage Ajax techniques (only requiring small parts of the page to change in response to user actions)

#### 3. Low Number of Parallel Requests

Fetch a script, parse and execute it, then fetch another one... this will use up all the available connections. There are things you can do to your HTML to allow virtually any browser to make many requests at once, which has a huge impact on latency.

1. Use browser-appropriate domain sharding

1. Use intelligent script loading

1. Leverage Keep-Alive (reuse the same TCP connection for multiple HTTP request/response cycles)

#### 4. Failure to leverage browser cache / local storage

1. [HTTP cache overview](http://www.mnot.net/cache_docs/)

1. Leverage local storage

#### 5. Third-party widgets

1. Avoid third-party widgets!
1. Try to use widgets that provide asynchronous implementations, so their inevitably terrible performance impacts their widget without dragging down your entire UX with it.

#### 7. Failure to Use a Global Network

Amazon S3. 

Ref: http://www.sitepoint.com/seven-mistakes-that-make-websites-slow/
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[[Design] Speed Up Webpage for Slow Connection (1)]]></title>
    <link href="http://okckd.github.io/blog/2015/02/05/speed-up-web-page-1/"/>
    <updated>2015-02-05T00:00:00+08:00</updated>
    <id>http://okckd.github.io/blog/2015/02/05/speed-up-web-page-1</id>
    <content type="html"><![CDATA[[ref](www.geeksforgeeks.org/amazon-interview-set-72-campus-sde-1)

### Question

> Suppose you are handling Amazon website and you have 10 MB size home page. Optimize the homepage for a customer who has 100 kbps internet connection.

> Further he asked for the customer who has 100 mbps internet connection.

### Reading

[This](http://sixrevisions.com/web-development/site-speed-performance/) is a very nice article about website speedup. Below is the full quoted text. 

#### 1. Defer Loading Content When Possible

Ajax allows us to build web pages that can be __asynchronously updated__ at any time. This means that instead of reloading an entire page when a user performs an action, we can simply update parts of that page.

We can use an image gallery as an example. Image files are big and heavy; they can slow down page-loading speeds of web pages. Instead of loading all of the images when a user first visits the web page, we can just display thumbnails of the images and then when the user clicks on them, we can asynchronously request the full-size images from the server and update the page. This way, if a user only wants to see a few pictures, they don’t have to suffer waiting for all of the pictures to download. This development pattern is called __lazy loading__.

__Ajax/web development libraries__ like jQuery, Prototype, and MooTools can make deferred content-loading easier to implement.

#### 2. Use External JS and CSS Files

When the user first loads your web page, the browser will cache external resources like CSS and JavaScript files. Thus, instead of inline JavaScript and CSS files, it’s best to __place them in external files__.

Using inline CSS also increases the rendering time of a web page; having everything defined in your main CSS file lets the browser do less work when rendering the page, since it already knows all the style rules that it needs to apply.

__As a bonus__, using external JavaScript and CSS files makes site maintenance easier because you only need to maintain global files instead of code scattered in multiple web pages.

#### 3. Use Caching Systems

If you find that your site is connecting to your database in order to create the same content, it’s time to start using a __caching system__. By having a caching system in place, your site will only have to create the content once instead of creating the content every time the page is visited by your users. Don’t worry, caching systems periodically refresh their caches depending on how you set it up — so even constantly-changing web pages (like a blog post with comments) can be cached.

__Popular content management systems__ like WordPress and Drupal will have __static caching features__ that convert dynamically generated pages to static HTML files to reduce unnecessary server processing. For WordPress, check out [WP Super Cache](https://wordpress.org/plugins/wp-super-cache/) (one of the six critical WordPress plugins which, claimed by the author, enjoyed a improvement by 259.1% for content-heavy pages). Drupal has a page-caching feature in the core.

There are also __database caching and server-side scripts caching systems__ that you can install on your web server (if you have the ability to do so). For example, PHP has extensions called PHP accelerators that optimize performance through caching and various other methods; one example of a [PHP accelerator](http://en.wikipedia.org/wiki/PHP_accelerator) is APC. [Database caching](http://en.wikipedia.org/wiki/Database_caching) improves performance and scalability of your web applications by reducing the work associated with database read/write/access processes; __[memcached](http://www.memcached.org/)__, for example, caches frequently used database queries. 

#### 8. Load JavaScript at the End of Your Document

It’s best if you have your scripts loading at the end of the page rather than at the beginning. It allows for the browser to render everything before getting started with the JavaScript. This makes your web pages feel more responsive because the way JavaScript works is that it blocks anything below it from rendering until it has finished downloading. If possible, reference JavaScript right before the closing (body) tag of your HTML documents. To learn more, read about deferring the loading of JavaScript.

#### 9. Use a Content Delivery Network (CDN)

Your site’s speed is greatly affected by where the user’s location is, relative to your web server. The farther away they are, the more distance the data being transmitted has to travel. Having your content cached __across multiple, strategically placed geographical locations__ helps take care of this problem. 

A CDN will often make your operating cost a little higher, but you definitely gain a speed bonus. Check out MaxCDN or __Amazon Simple Storage Service (Amazon S3)__.

#### 10. Optimize Web Caching

Along with using caching systems, you should create websites that utilize __web caching__ as much as possible. Web caching is when files are __cached by the web browser__ for later use. Things that browsers can cache include CSS files, JavaScript files, and images.

Aside from the basics, such as putting CSS and JavaScript code that are used in multiple pages in external files, there are many ways to make sure that you are caching your files in the most efficient way possible.

For example, you can set HTTP response headers such as Expires and Last-Modified to reduce the need of re-downloading certain files when the user comes back to your site. To learn more, read about [caching in HTTP](http://www.w3.org/Protocols/rfc2616/rfc2616-sec13.html) and [leveraging browser caching](https://developers.google.com/speed/docs/insights/LeverageBrowserCaching?csw=1#LeverageBrowserCaching).

To set up HTTP Expires headers in Apache, read this tutorial on adding future expires headers.

#### Other mentions

4. __Avoid Resizing Images in HTML__ (using HTML’s width and height attributes), for the sake of smaller file size. 

6. __Optimize Image Sizes by Using the Correct File Format__. Eg. JPG format often displays photographic images at smaller file sizes than PNG. 

7. __Optimize the Way You Write Code__. For example, instead of using (h1)(em)Your heading(em)(h1), you can easily use CSS to make your headings italics. 

    Writing code efficiently not only reduces file sizes of your HTML and CSS documents, but also makes it easier to maintain.

Ref: http://sixrevisions.com/web-development/site-speed-performance/
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[[Design] Monitor Rps for Past Sec/min/hr]]></title>
    <link href="http://okckd.github.io/blog/2015/02/03/monitor-request-per-second/"/>
    <updated>2015-02-03T00:00:00+08:00</updated>
    <id>http://okckd.github.io/blog/2015/02/03/monitor-request-per-second</id>
    <content type="html"><![CDATA[### Question

[link](http://www.careercup.com/question?id=6005446611566592)

> Given a server that has requests coming in. 

> Design a data structure such that you can fetch the count of the number requests in the last second, minute and hour.

### Solution 1

__Keep a record of all request timestamps__, suggested by the top answer by [whatevva](http://www.careercup.com/question?id=6005446611566592): 

1. Use a queue implemented as a resizable array to store the timestamps of all new requests 

1. maintain head/tail pointers as usual 

1. Also maintain three pointers, for past sec, past min and past hr. 

Whenever a request comes in, update 3 pointers. Then in the for-loop of the thread, remove old entries and also update 3 pointers. 

Print Rps in real time. I posted my code below (the code is without thread-safety consideration).

### Solution 2

This solution does not store all timestamps, and it does not generate real-time Rps data. But it's good enough because result is only updated every 1 second, so its performance is better. 

Keep an array of int of size 60 * 60. Each second, use the __number of request in the past second__ to update the array values __in a rolling way__. 

### Code 

Solution 1. this is my code so please correct me! 

    public class SetRps {

        AtomicInteger count = new AtomicInteger(0);
        int limit = -1;
        int printIndex = 1;
        long startTimestamp = -1;

        void setRPS(int num) {
            limit = num;
        }

        boolean process(long timestamp) {
            // suppose timestamp is ms
            synchronized (this) {
                if (count.get() < limit) {
                    // can process
                    count.incrementAndGet();
                    System.out.println(printIndex++ + ". processing request "
                            + timestamp % 100000 / 1000 + "," + timestamp % 1000);
                    return true;
                }
                if (timestamp - startTimestamp >= 1000) {
                    // every 1 seconds, reset
                    count.set(0);
                    startTimestamp = timestamp;
                    System.out.println("clear!");
                    return true;
                }
            }
            return false;
        }
    }
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[[Design] Limit the Request Per Second]]></title>
    <link href="http://okckd.github.io/blog/2015/02/01/limit-request-per-second/"/>
    <updated>2015-02-01T00:00:00+08:00</updated>
    <id>http://okckd.github.io/blog/2015/02/01/limit-request-per-second</id>
    <content type="html"><![CDATA[### Question

[link](http://www.mitbbs.com/article_t/JobHunting/32841633.html)

> 有一个接口叫 void setRPS(int num);

> 接下来不断有request过来，如何实现下面的接口，返回accept或者deny，

    bool process(int timestamp){
    
    }

### Solution

Suggested by level 5 of [this post](http://www.mitbbs.com/article_t/JobHunting/32841633.html):

1. maintain a variable for the number of request processed/rejected.
    1. This variable must be atomic, thus a __AtomicInteger__. 
    1. the variable is called 'count'
1. have a method to process request
    1. if count < limit, do it
    1. otherwise, reject
1. __This is the most important__: clear the count every 1 seconds! 
    1. eg. LIMIT = 5r/s, so: 
    1. the __first 5 number of requests in every second__ are getting fulfilled
    1. from 6th request onward, the request all rejected, until the next second.

### Code 

    public class SetRps {

        AtomicInteger count = new AtomicInteger(0);
        int limit = -1;
        int printIndex = 1;
        long startTimestamp = -1;

        void setRPS(int num) {
            limit = num;
        }

        boolean process(long timestamp) {
            // suppose timestamp is ms
            synchronized (this) {
                if (count.get() < limit) {
                    // can process
                    count.incrementAndGet();
                    System.out.println(printIndex++ + ". processing request "
                            + timestamp % 100000 / 1000 + "," + timestamp % 1000);
                    return true;
                }
                if (timestamp - startTimestamp >= 1000) {
                    // every 1 seconds, reset
                    count.set(0);
                    startTimestamp = timestamp;
                    System.out.println("clear!");
                    return true;
                }
            }
            return false;
        }
    }
]]></content>
  </entry>
  
</feed>
