<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Design | My Octopress Blog]]></title>
  <link href="http://okckd.github.io/blog/categories/design/atom.xml" rel="self"/>
  <link href="http://okckd.github.io/"/>
  <updated>2014-08-09T18:51:42+08:00</updated>
  <id>http://okckd.github.io/</id>
  <author>
    <name><![CDATA[Your Name]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[[Design] Functional Programming]]></title>
    <link href="http://okckd.github.io/blog/2014/08/09/Functional-programming/"/>
    <updated>2014-08-09T00:00:00+08:00</updated>
    <id>http://okckd.github.io/blog/2014/08/09/Functional-programming</id>
    <content type="html"><![CDATA[### Overview

__[A functional language](http://stackoverflow.com/a/23290) allows you to write a mathematical function__, i.e. a function that takes n arguments and returns a value. If the program is executed, this function is evaluated. 

A purely functional program __always yields the same value for an input__, and the order of evaluation is not well-defined; which means that uncertain values like user input or random values are hard to model in purely functional languages. 

__Functional programming is like describing your [problem to a mathematician](http://stackoverflow.com/a/23475). Imperative programming is like giving instructions to an idiot__. 

Pros and Cons

Functional programming allows coding [with fewer potentials for bugs](http://stackoverflow.com/a/24294) because each component is completely isolated. Also, using recursion and first-class functions allows for __simple proofs of correctness__ which typically mirror the structure of the code.

Functional programming languages are typically [less efficient](http://en.wikipedia.org/wiki/Functional_programming#Efficiency_issues) in their use of CPU and memory than imperative languages such as C and Pascal.
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[[Design] Thread Pool Pattern]]></title>
    <link href="http://okckd.github.io/blog/2014/08/08/Thread-pool-pattern/"/>
    <updated>2014-08-08T00:00:00+08:00</updated>
    <id>http://okckd.github.io/blog/2014/08/08/Thread-pool-pattern</id>
    <content type="html"><![CDATA[### Overview

[Thread pool](http://programmers.stackexchange.com/a/173580) is a collection of managed threads usually organized in a queue, which execute the tasks in the task queue.

<img class="middle" src="/assets/images/thread-pool.png">

[A sample thread pool](http://en.wikipedia.org/wiki/Thread_pool_pattern) (green boxes) with waiting tasks (blue) and completed tasks (yellow)

### Why Thread Pool?

[Many server applications](http://www.ibm.com/developerworks/library/j-jtp0730/), such as __Web servers (eg. Tomcat)__, database servers, file servers, or mail servers must process a large number of tasks received from a network protocol. Often, the task is short-lived and the number of requests is large. 

__Thread Pools are useful when you need to limit the number of threads__ running in your application at the same time. 

### More details

A thread pool is a group of pre-instantiated, idle threads which stand ready to be given work. These are preferred over instantiating new threads for each task when there is __a large number of short tasks__ to be done __rather than a small number of long ones__. 

Instead of starting a new thread for every task to execute concurrently, the __task can be passed to a thread pool__. As soon as the pool has any idle threads the task is assigned to one of them and executed.

Thread pools are often used in multi threaded servers. Each connection __arriving at the server via the network is wrapped as a task__ and passed on to a thread pool. The threads in the thread pool will process the requests on the connections concurrently.

### Code

__a [simple thread pool implementation](http://tutorials.jenkov.com/java-concurrency/thread-pools.html)__

Pool Class: 

	public class ThreadPool {

	  private BlockingQueue taskQueue = null;
	  private List<PoolThread> threads = new ArrayList<PoolThread>();
	  private boolean isStopped = false;

	  public ThreadPool(int noOfThreads, int maxNoOfTasks){
	    taskQueue = new BlockingQueue(maxNoOfTasks);

	    for(int i=0; i<noOfThreads; i++){
	      threads.add(new PoolThread(taskQueue));
	    }
	    for(PoolThread thread : threads){
	      thread.start();
	    }
	  }

	  public void synchronized execute(Runnable task){
	    if(this.isStopped) throw
	      new IllegalStateException("ThreadPool is stopped");

	    this.taskQueue.enqueue(task);
	  }

	  public synchronized void stop(){
	    this.isStopped = true;
	    for(PoolThread thread : threads){
	      thread.stop();
	    }
	  }
	}

Thread Class: 

	public class PoolThread extends Thread {

	  private BlockingQueue taskQueue = null;
	  private boolean       isStopped = false;

	  public PoolThread(BlockingQueue queue){
	    taskQueue = queue;
	  }

	  public void run(){
	    while(!isStopped()){
	      try{
	        Runnable runnable = (Runnable) taskQueue.dequeue();
	        runnable.run();
	      } catch(Exception e){
	        //log or otherwise report exception,
	        //but keep pool thread alive.
	      }
	    }
	  }

	  public synchronized void stop(){
	    isStopped = true;
	    this.interrupt(); //break pool thread out of dequeue() call.
	  }

	  public synchronized void isStopped(){
	    return isStopped;
	  }
	}

An explanation: 

> The thread pool implementation consists of two parts. A ThreadPool class which is the public interface to the thread pool, and a PoolThread class which implements the threads that execute the tasks.

> To execute a task the method ThreadPool.execute(Runnable r) is called with a Runnable implementation as parameter. The Runnable is enqueued in the blocking queue internally, waiting to be dequeued.

> The Runnable will be dequeued by an idle PoolThread and executed. You can see this in the PoolThread.run() method. After execution the PoolThread loops and tries to dequeue a task again, until stopped.

> To stop the ThreadPool the method ThreadPool.stop() is called. The stop called is noted internally in the isStopped member. Then each thread in the pool is stopped by calling PoolThread.stop(). Notice how the execute() method will throw an IllegalStateException if execute() is called after stop() has been called.

> The threads will stop after finishing any task they are currently executing. Notice the this.interrupt() call in PoolThread.stop(). This makes sure that a thread blocked in a wait() call inside the taskQueue.dequeue() call breaks out of the wait() call, and leaves the dequeue() method call with an InterruptedException thrown. This exception is caught in the PoolThread.run() method, reported, and then the isStopped variable is checked. Since isStopped is now true, the PoolThread.run() will exit and the thread dies.

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[[Design] Producer Consumer Problem]]></title>
    <link href="http://okckd.github.io/blog/2014/08/08/Producer-consumer-problem/"/>
    <updated>2014-08-08T00:00:00+08:00</updated>
    <id>http://okckd.github.io/blog/2014/08/08/Producer-consumer-problem</id>
    <content type="html"><![CDATA[### Overview

Producer-consumer problem illustrates the need for __synchronization__ in systems where __many processes share a resource__. 

[In the problem](http://cs.gmu.edu/cne/modules/ipc/aqua/producer.html), two processes share a fixed-size buffer. One process produces information and puts it in the buffer, while the other process consumes information from the buffer. These processes do not take turns accessing the buffer, they both work concurrently. 

### Inadequate Solution

<img class="middle" src="/assets/images/producer-workflow.gif">

<img class="middle" src="/assets/images/consumer-workflow.gif">

__The code might look like this__: 

	BufferSize = 3;
	  count = 0;

	Producer()
	{
	    int widget;
	    WHILE (true) {                   // loop forever
	      make_new(widget);              // create a new widget to put in the buffer
	      IF(count==BufferSize)
	           Sleep();                  // if the buffer is full, sleep
	      put_item(widget);              // put the item in the buffer
	      count = count + 1;             // increment count of items
	      IF (count==1)
	         Wakeup(Consumer);           // if the buffer was previously empty, wake
	   }                                 //  the consumer
	}

	Consumer()
	{
	    int widget;
	    WHILE(true) {                    // loop forever
	      IF(count==0)
	           Sleep();                  // if the buffer is empty, sleep
	      remove_item(widget);           // take an item from the buffer
	      count = count + 1;             // decrement count of items
	      IF(count==N-1)
	            Wakeup(Producer);        // if buffer was previously full, wake
	                                     //  the producer
	      Consume_item(widget);          // consume the item
	    }
	}

This [will cause problems](http://en.wikipedia.org/wiki/Producer%E2%80%93consumer_problem#Inadequate_implementation), because __it contains a race condition__ that can lead to a deadlock. Or in simply words, it has the potential of [losing wakeups](http://cs.gmu.edu/cne/modules/ipc/purple/prodsem.html). 

An alternative analysis is that if the programming language does not define the semantics of __concurrent accesses to shared variables (in this case itemCount)__ without use of synchronization, then the solution is unsatisfactory for that reason, without needing to explicitly demonstrate a race condition.

Solutions are: __semaphores or monitors__.

### Semaphore

	semaphore mutex = 1;
	semaphore fillCount = 0;
	semaphore emptyCount = BUFFER_SIZE;
	 
	procedure producer() {
	    while (true) {
	        item = produceItem();
	        down(emptyCount);
	            down(mutex);
	                putItemIntoBuffer(item);
	            up(mutex);
	        up(fillCount);
	    }
	}
	 
	procedure consumer() {
	    while (true) {
	        down(fillCount);
	            down(mutex);
	                item = removeItemFromBuffer();
	            up(mutex);
	        up(emptyCount);
	        consumeItem(item);
	    }
	}

### Monitor

	monitor ProducerConsumer {
	    int itemCount;
	    condition full;
	    condition empty;
	 
	    procedure add(item) {
	        while (itemCount == BUFFER_SIZE) {
	            wait(full);
	        }
	 
	        putItemIntoBuffer(item);
	        itemCount = itemCount + 1;
	 
	        if (itemCount == BUFFER_SIZE -1) {
	            notify(full);
	        }
	    }
	    procedure remove() {
	        while (itemCount == 0) {
	            wait(empty);
	        }
	 
	        item = removeItemFromBuffer();
	        itemCount = itemCount - 1;
	 
	        if (itemCount == 1) {
	            notify(empty);
	        }
	 
	 
	        return item;
	    }
	}
	 
	procedure producer() {
	    while (true) {
	        item = produceItem();
	        ProducerConsumer.add(item);
	    }
	}
	 
	procedure consumer() {
	    while (true) {
	        item = ProducerConsumer.remove();
	        consumeItem(item);
	    }
	}
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[[Design] Composition Over Inheritance]]></title>
    <link href="http://okckd.github.io/blog/2014/08/08/Composition-over-inheritance/"/>
    <updated>2014-08-08T00:00:00+08:00</updated>
    <id>http://okckd.github.io/blog/2014/08/08/Composition-over-inheritance</id>
    <content type="html"><![CDATA[### Overview

[Composition over inheritance](http://en.wikipedia.org/wiki/Composition_over_inheritance) in OOP is a technique by which classes achieve __polymorphic behavior and code reuse__ by containing other classes __instead of__ through inheritance. 

### Benefits

[It gives](http://en.wikipedia.org/wiki/Composition_over_inheritance#Benefits) the design __higher flexibility__, giving business-domain classes and more stable business domain in the long term. In other words, HAS-A can be better than an IS-A relationship.

__And inheritance [breaks encapsulation](http://stackoverflow.com/a/891908)__! This post also points out these (which is hard to understand): 

> 1. You can't change the implementation inherited from super classes at runtime (obviously because inheritance is defined at compile time).

> 1. Inheritance exposes a subclass to details of its parent's class implementation, that's why it's often said that inheritance breaks encapsulation (in a sense that you really need to focus on interfaces only not implementation, so reusing by sub classing is not always preferred).

> 1. The tight coupling provided by inheritance makes the implementation of a subclass very bound up with the implementation of a super class that any change in the parent implementation will force the sub class to change.

> 1. Excessive reusing by sub-classing can make the inheritance stack very deep and very confusing too.
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[[Design] Distributed Network Bottleneck]]></title>
    <link href="http://okckd.github.io/blog/2014/08/07/Distributed-network-bottleneck/"/>
    <updated>2014-08-07T00:00:00+08:00</updated>
    <id>http://okckd.github.io/blog/2014/08/07/Distributed-network-bottleneck</id>
    <content type="html"><![CDATA[## Question

[link](http://www.mitbbs.com/article_t/JobHunting/32702821.html)

> 一个distributed的环境，有很多机器，现在你发现性能有问题，可能是网络带宽造成的，你怎么解决？ (你不能更换网络设备的前提下)

### Answer

1. Identify problem 

首先得判定是否真的是网络造成的，就算是网络问题，哪些机器之间的网络问题？ 这个得先大概了解high level component dependency relationship，

看看是不是cpu memory disk都没有问题。 可以profile几个机器看看是不是 a lot of time spent waiting for network calls.

2. Locate the faulty component

判定是网络问题之后看是哪些components之间，或是某个component里面有很多网络通讯。

3. Improvement

不能更换设备的话，能不能改network topology来让critical path machine之间的带宽有改善。

要是不能改topology就只能改程序了。还是先identify top offender,然后就只能慢慢改了

4. What's more

要还有时间的话就可以聊聊问啥不能换设备，是资金问题还是用的已经是top of the line了？

或者是在public cloud上？

Answer suggested by user __remus__. 
]]></content>
  </entry>
  
</feed>
