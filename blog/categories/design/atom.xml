<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Design | Woodstock Blog]]></title>
  <link href="http://okckd.github.io/blog/categories/design/atom.xml" rel="self"/>
  <link href="http://okckd.github.io/"/>
  <updated>2015-01-07T21:57:37+08:00</updated>
  <id>http://okckd.github.io/</id>
  <author>
    <name><![CDATA[Charlie Brown]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[[Design] P2P Technology]]></title>
    <link href="http://okckd.github.io/blog/2015/01/07/P2P-technology/"/>
    <updated>2015-01-07T00:00:00+08:00</updated>
    <id>http://okckd.github.io/blog/2015/01/07/P2P-technology</id>
    <content type="html"><![CDATA[### Overview

__[Peer-to-peer](http://en.wikipedia.org/wiki/Peer-to-peer) (P2P) networking__ is a distributed application architecture that partitions tasks or work loads between peers. 

Peers are __both suppliers and consumers__ of resources, in contrast to the traditional client-server model where communication is usually to and from a central server. A typical example of a file transfer that uses the client-server model is the __File Transfer Protocol__ (FTP) service in which the client and server programs are distinct: the clients initiate the transfer, and the servers satisfy these requests.

This architecture was popularized by the file sharing system Napster, originally released in 1999. 

#### Precedure

1. Alice run P2P client software. 
    1. connect to Internet and get new IP address for each connection
    1. register her files in P2P system
    1. request "Harry Potter"
    1. find other peers who have the copy
    1. choose one and copy to her PC.
    1. meanwhile, Alice is servig her files for other people
1. Act like a server
1. Act like a client
1. User keyword to search content (like google)

### P2P Types

1. Unstructured P2P: __no coupling between nodes and file location__
    1. Napster
    1. Gnutella
    1. KaZaA
    
1. Structured P2P: __tight coupling between nodes and file location__
    1. DHT

#### Napster

Register at Napster server.

Centralized search, and P2P distributing. 

#### Gnutella

__Decentralized__ design for searching:

1. No central directory server
1. Each node maintain a list of neighbors (overlay network)

__Search by flooding__:

1. BFS traversal. 
1. Define maximum number of hops
1. Expanded-ring TTL search means to try 1 hop first, then try 2 hops, then 3...

Join nodes:

1. Use Bootstrap node to get some IP addresses
1. Join these IP, which becomes neighbors.

Shortcomings:

1. Flooding is __NOT a scalable design__.
1. Download may not complete. 
1. Possibility of search failure, even then the resource presents.

#### KaZaA

Combines Napster and Gnutella. 

Each peer is a supernode or assigned to a supernode. Each supernode connects to 30~50 other supernodes. The supernode acts like a mini-Napster hub. 

At registration, a PC connects to a supernode. If a supernode goes down, obtains updated list and elect another one. 

Search within supernode, then in other supernodes. If found many nodes holding the file, do parallel downloading. 

Automatic recovery if 1 server peer goes down. Use __ContentHash__ to search.

#### Structured P2P

For Distributed HashTable services, refer to __[Design] Distributed hash table__. 

### Conclusion

1. Unstructured P2P: 
    1. __no coupling between nodes and file location__
    1. Centralized direcotry service (except Gnutella)
    1. Search by flooding (overhead)
    1. Hierarchical architecture (non-scalable)

1. Structured P2P: 
    1. __tight coupling between nodes and file location__
    1. DHT using consistent hashing (eg. Chord, and many other types)
    1. A node is assigned to hold particular content
    1. Search with more efficiency
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[[Design] Distributed Hash Table]]></title>
    <link href="http://okckd.github.io/blog/2015/01/06/distributed-hash-table/"/>
    <updated>2015-01-06T00:00:00+08:00</updated>
    <id>http://okckd.github.io/blog/2015/01/06/distributed-hash-table</id>
    <content type="html"><![CDATA[[ref](http://blog.csdn.net/yfkiss/article/details/6977509)

### Distributed hash table

__A [distributed hash table](http://en.wikipedia.org/wiki/Distributed_hash_table) (DHT) is a class of a decentralized distributed system__ that provides a lookup service similar to a hash table. (key,value) pairs are stored in a DHT, and any participating node can efficiently retrieve the value associated with a given key.

对于一个key/value对，DHT在分布式集群中，提供像HashTable一样的服务，例如简单快捷的存取、查询。

<img class="middle" src="/assets/images/DHT.png">

DHTs form an infrastructure that can be used to build more complex services, such as anycast, cooperative Web caching, distributed file systems, domain name services, instant messaging, multicast, and also __peer-to-peer file sharing__ and content distribution systems. 

#### Properties 

Unlike unstructured P2P, __DHT is tightly coupled between nodes and file locations__. (when request a content, directly go to the content instead of __searching by flooding__) 

DHT has the following properties: 

1. __Autonomy and Decentralization__: the nodes collectively form the system without any central coordination.

1. __Fault tolerance__: the system should be reliable (in some sense) even with nodes continuously joining, leaving, and failing.

1. __Scalability__: the system should function efficiently even with thousands or millions of nodes.

#### Building a DHT

1. Hash function that maps a file to a unique ID. Eg. hash("Harry Potter") -> 3912. 
2. Distribute __range space__ for all nodes in the network. 
3. The desinated node stores the location of the file. (this is indirect approach)

<img class="middle" src="/assets/images/range-space.png">

#### Search in DHT

1. Search query __routed to the node whose range covers the file__. 
2. Each node would retains a __routing information__ that is implemented in a fully distributed manner (i.e. no central point, no single point of failure). 

There is different hashing and routing techniques associated with DHT. The most important is __Consistent Hashing__ and __Chord Routing__. 

### Consistent Hashing

--[Consistent hashing](http://en.wikipedia.org/wiki/Consistent_hashing)__ is a special kind of hashing such that when a hash table is resized and consistent hashing is used, __only K/n keys need to be remapped__ on average, where K is the number of keys, and n is the number of slots. 

#### Motivation

In most traditional hash tables, a change in the number of array slots causes __nearly all keys__ to be remapped. Specifically, [the 3 cases below](http://blog.csdn.net/sparkliang/article/details/5279393) can end up in a technology crisis: 

1. leaves/failures - 一个 cache 服务器 m down 掉了（在实际应用中必须要考虑这种情况），这样所有映射到 cache m 的对象都会失效，怎么办，需要把 cache m 从 cache 中移除，这时候 cache 是 N-1 台，映射公式变成了 hash(object)%(N-1)；

1. join - 由于访问加重，需要添加 cache ，这时候 cache 是 N+1 台，映射公式变成了 hash(object)%(N+1)

1. scalability - 由于硬件能力越来越强，你可能想让后面添加的节点多做点活，显然上面的 hash 算法也做不到。

#### Technique

Consistent hashing is based on mapping each object to a point on the edge of a circle. The system maps each available machine to pseudo-randomly distributed points on the edge of the same circle.

1. 假定哈希key均匀的分布在一个环上
1. 所有的节点也都分布在同一环上
1. 每个节点只负责一部分Key，当节点加入、退出时只影响加入退出的节点和其邻居节点或者其他节点只有少量的Key受影响

For a very detailed steps of consistent hashing, read [this Chinese blog](http://blog.csdn.net/sparkliang/article/details/5279393).

<img class="middle" src="/assets/images/consistent-hashing.png">

In this way, 一致性Hash在node加入/离开时，不会导致映射关系的重大变化。

### Routing (searching)

__Simple Routing__ would search successor node, and runtime is linear. These node would keep O(1) __routing information__, and spend O(n) time in __query routing__. 

Otherwise, we make every node store ID and IP of all nodes, thus query routing takes O(1) but routing information is O(n). 

We'll now discuss __Chord Routing__.

#### Chord Routing

Each node stores more info __closely following it__ on the identifier circle than nodes further away. That is, the subsequent nodes at position 1, 2, 4, 8, 16, 32... (each entry is called a __finger__)

<img class="middle" src="/assets/images/consistent-hashing.png">

为网络中每个Node分配一个唯一id（可以通过机器的mac地址做Hash），假设整个网络有N 个节点，我们可以认为这些整数首尾相连形成一个环，称之为Chord环。两个节点间的距离定义为节点间下标差，每个节点会存储一张路由表(Finger表)，表内顺时针按照离本节点2、4、8、16、32.……2i的距离选定log2N个其他节点的ip信息来记录。

__Routing information__ maintained at each node: O(logN). 

__Query routing__ take O(logN) time. 

### Join and leave in Chord

It's very much like insertion and removal in Doubly Linked List. Read it yourself. 

<img class="middle" src="/assets/images/chord-routing.PNG">

Special thanks to the online resources written by some CSDN bloggers. 
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[[Design] Cloud, Grid and Cluster]]></title>
    <link href="http://okckd.github.io/blog/2015/01/06/cloud-grid-cluster/"/>
    <updated>2015-01-06T00:00:00+08:00</updated>
    <id>http://okckd.github.io/blog/2015/01/06/cloud-grid-cluster</id>
    <content type="html"><![CDATA[[ref](http://stackoverflow.com/questions/9723040/what-is-the-difference-between-cloud-grid-and-cluster)

### Cluster VS. Grid

__[Cluster differs](http://stackoverflow.com/a/9753568) from Cloud and Grid in that__ 

1. a cluster is a group of computers connected by a local area network (LAN)
1. cloud and grid are more wide scale and can be geographically distributed. 

Another way to put it is to say that

1. a cluster is tightly coupled
1. a Grid or a cloud is loosely coupled. 

Also, __the hardware__: 

1. clusters are made up of machines with similar hardware
1. clouds and grids are made up of machines with possibly very different hardware configurations. 

### Computer cluster

__[A computer cluster](http://en.wikipedia.org/wiki/Computer_cluster)__ consists of a set of tightly connected computers that work together as a single system. 

Unlike grid computers, computer clusters have each node set to __perform the same task__, controlled and scheduled by software. 

In most circumstances, all of the nodes use the __same hardware and OS__. They are connected in __LAN__ with each node running its __own piece__ of OS. 

They are used to improve __performance__ and __availability__ over that of a single computer, while being more __cost effective__. 

Computer clusters emerged as a result of: 

1. low-cost microprocessors, 
1. high-speed networks, 
1. software for high-performance distributed computing

### Grid computing

__[Grid computing](http://en.wikipedia.org/wiki/Grid_computing)__ is the collection of computer resources from multiple locations to reach a common goal. Each computer have __non-interactive workloads__. It's like a __"super virtual computer”__ composed of many networked loosely coupled computers acting together to perform large tasks. 

Unlike conventional high performance computing systems such as __cluster computing__, grid computers have each node set to __perform a different task__. 

Grid computers also tend to be more __geographically dispersed__ than cluster computers. Grids are often constructed with general-purpose grid middleware software libraries. 

Major disadvantage with Grid Computing is, __if one piece of software on a node fails__, other pieces of the software on the other nodes may fail. 

### Cloud computing

__[Cloud computing](http://en.wikipedia.org/wiki/Cloud_computing)__ is terminology based on utility and __consumption of computing resources__. 

#### SaaS

An application doesn't access resources it requires directly, rather it accesses them through __something [like a service](http://stackoverflow.com/a/1068133)__. Instead of talking to a specific hard drive for storage, and a specific CPU for computation, etc, it talks to some __service that provides these resources__. The service then maps any requests for resources to its physical resources. 

The services themselves [have long been referred to](http://stackoverflow.com/a/9753568) as __Software as a Service (SaaS)__. The datacenter hardware and software is what we call __a Cloud__. When a Cloud is made available in a pay-as-you-go manner to the general public, we call it a __Public Cloud__; the service being sold is __Utility Computing__. 

#### Sharing of Resources

Usually the service __dynamically allocate resources__ to maximize the effectiveness of the shared resources(per users and per demand). 

For example, a cloud computer facility that serves European users during European business hours with a specific application (e.g., email) may reallocate the same resources to serve North American users during North America's business hours with a different application (e.g., a web server). 

With cloud computing, multiple users can access a single server to retrieve and update their data __without purchasing licenses for different applications__.

#### Scalability

1. If an application requires only __a small amount of some resource__, say computation, then the service only allocates a small amount, say a small share on a single physical CPU. 

1. If the application requires __a large amount of some resource__, then the service allocates that large amount, say a grid of CPUs. 

All the complex handling and coordination is performed __by the service, not the application__. In this way the application can scale well. 

[For example](http://stackoverflow.com/a/1068133) a web site written "on the cloud" may share a server with many other web sites while it has a low amount of traffic. If it ever has massive amounts of traffic, it may be moved to its own dedicated server, or __grid of servers__. This is all handled __by the cloud service (provider)__, so the application shouldn't have to be modified drastically to cope.

#### Other Advantages

Using Cloud Computing, companies can [scale upto High capacities](http://www.ibeehosting.com/blog/what-is-the-difference-between-cloud-computing-and-grid-computing.html) immediately without investing in new infrastructure, training the people or new software licensing. It is more useful for small and medium scale businesses who wants to outsource their Data Center infrastructure, or some larger companies also prefer if they want to cut down the costs of building data-centers internally in order to get peak load capacity. In short, consumers use what they need and pay accordingly.

### Grid Computing VS. Cloud Computing

1. Grid Computing is the parent of Cloud computing, cloud actually evolves from Grid Computing. 

1. A cloud would usually use a grid. A grid is not necessarily a cloud. 

1. Resource distribution: Cloud computing is a centralized model whereas grid computing is a decentralized model where the computation could occur over many administrative domains.

1. Ownership: A grid is a collection of computers which is owned by multiple parties in multiple locations and connected together so that users can share the combined power of resources. Whereas a cloud is a collection of computers usually owned by a single party.

#### Examples

Examples of Clouds: Amazon Web Services (AWS), Google App Engine, Dropbox, Gmail, Facebook, Youtube, Rapidshare

Examples of Grids: FutureGrid
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[[Design] Big Data Storage]]></title>
    <link href="http://okckd.github.io/blog/2015/01/06/big-data-storage/"/>
    <updated>2015-01-06T00:00:00+08:00</updated>
    <id>http://okckd.github.io/blog/2015/01/06/big-data-storage</id>
    <content type="html"><![CDATA[[ref](http://www.mitbbs.com/article/JobHunting/32580869_0.html)

### Question

__Given 1 trillion messages__ on fb and each message has at max 10 words. 

How do you build the __index table__ and how many machines do you need on the __cluster__ to store the index table?

### One possible answer

Total data = 1 trillion * 10 words * 6 bytes / word = 60TB = one small NetApp box

__Index by hashed userid__; will distribute traffic effectively across servers; cache active users recent messages in memory. 

[Cannot use Netapp box](http://www.glassdoor.com/Interview/Given-a-set-of-n-jobs-with-start-time-end-time-cost-find-a-subset-so-that-no-2-jobs-overlap-and-the-cost-is-maximum-QTN_440168.htm). From what I read in FB engg blog, they have all the info in main memory of server.

Total data = 1 trillion * 10 words * 6 bytes / word = 60TB + 1TB for Indexes.

Considering servers have 64 GB ram. 61 GB usable to store index, 1000 servers. 

#### For more information

Read 2 other posts: __[Design] Distributed hash table__ and __[Design] Cloud, Grid and Cluster__. 
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[[Design] Database Indexing]]></title>
    <link href="http://okckd.github.io/blog/2014/12/27/database-indexing/"/>
    <updated>2014-12-27T00:00:00+08:00</updated>
    <id>http://okckd.github.io/blog/2014/12/27/database-indexing</id>
    <content type="html"><![CDATA[[ref 1](http://stackoverflow.com/a/1130) [ref 2](http://www.interspire.com/content/2006/02/15/introduction-to-database-indexes/)

### Why Indexing?

In database disks (we're talking about disk-based storage devices), data is stored as blocks. These blocks are accessed atomically. It's like a linked list with pointers to the blocks. 

Because of this, searching in database is linear time. That's why we need indexing. 

__Indexing is a way of sorting a number of records on multiple fields__. Creating an index on a field in a table creates another data structure which holds the field value, and pointer to the record it relates to. This index structure is then sorted, allowing Binary Searches to be performed on it. 

In other words, indexing speed up search. 

### Downside

First disadvantage is __the additional space usage__. For example, in MyISAM engine, indexes are stored together with the data in one table. So the indexing files can quickly reach the size limits if many fields are indexed. 

Second disadvantage is that __using too many indexes can actually slow your database down__. Each time a page or database row is updated or removed, the reference or index also has to be updated. 

So indexes speed up finding data, but slow down inserting, updating or deleting data.

### Primary keys

__Some fields are automatically indexed__. 

A primary key or a field marked as ‘unique’ – for example an email address, a userid or a social security number – are __automatically indexed__ so the database can quickly check to make sure that you’re not going to introduce bad data.

### When to use

Since indexes are __only__ used to speed up the searching, it's not wise to have indexing used only for output. 

__The general rule__ is, anything that is used to limit the number of results you’re trying to find. For more details, read [ref 2](http://www.interspire.com/content/2006/02/15/introduction-to-database-indexes/). 

### How to create index

[The following](http://stackoverflow.com/a/1157) is SQL92 standard that's supported by major RDMBSs:

    CREATE INDEX [index name] ON [table name] ( [column name] )
]]></content>
  </entry>
  
</feed>
