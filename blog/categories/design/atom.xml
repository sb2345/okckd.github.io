<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Design | My Octopress Blog]]></title>
  <link href="http://okckd.github.io/blog/categories/design/atom.xml" rel="self"/>
  <link href="http://okckd.github.io/"/>
  <updated>2014-08-12T00:38:27+08:00</updated>
  <id>http://okckd.github.io/</id>
  <author>
    <name><![CDATA[Your Name]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[[Design] TCP 3-Way Handshake]]></title>
    <link href="http://okckd.github.io/blog/2014/08/11/Tcp-3way-handshake/"/>
    <updated>2014-08-11T00:00:00+08:00</updated>
    <id>http://okckd.github.io/blog/2014/08/11/Tcp-3way-handshake</id>
    <content type="html"><![CDATA[### Handshaking

__[Handshaking](http://en.wikipedia.org/wiki/Handshaking) is an automated process of negotiation__ that dynamically sets parameters of a communications channel established between two entities before normal communication over the channel begins. 

It is usually a process that takes place when a computer is about to communicate with a foreign device to establish rules for communication. 

### TCP three-way handshake

__[TCP three-way handshake](http://www.inetdaemon.com/tutorials/internet/tcp/3-way_handshake.shtml)__ is the method used by TCP set up a TCP/IP connection over an Internet Protocol based network. 

It's commonly referred to as "__SYN-SYN-ACK__". 

<img class="middle" src="/assets/images/3way-Tcp-handshake.png">

### Process

1. Host A sends a TCP __SYN__chronize packet to Host B
1. Host B receives A's SYN
1. Host B sends a __SYN__chronize-__ACK__nowledgement 
1. Host A receives B's SYN-ACK
1. Host A sends __ACK__nowledge
1. Host B receives ACK. 
1. TCP socket connection is ESTABLISHED.

Alternatively, there's a good illustration on [wiki](http://en.wikipedia.org/wiki/Handshaking): 

> Establishing a normal TCP connection requires three separate steps:

> 1. The first host (Alice) sends the second host (Bob) a "synchronize" (SYN) message with its own sequence number x, which Bob receives.
>
> 1. Bob replies with a synchronize-acknowledgment (SYN-ACK) message with its own sequence number y and acknowledgement number x + 1, which Alice receives.
>
> 1. Alice replies with an acknowledgment message with acknowledgement number y + 1, which Bob receives and to which he doesn't need to reply.

### Two more thing

Note that __FTP, Telnet, HTTP, HTTPS, SMTP, POP3, IMAP, SSH__ and any other protocol that rides over TCP __also has a three way handshake__ performed as connection is opened.

TCP 'rides' on top of Internet Protocol (IP) in the protocol stack. IP handles __IP addressing and routing__ and gets the packets from one place to another, but TCP manages the __actual communication sockets__ between endpoints. 
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[[Design] Big Data - Top K Questions (Summarize)]]></title>
    <link href="http://okckd.github.io/blog/2014/08/10/big-data-top-k-questions-summarize/"/>
    <updated>2014-08-10T00:00:00+08:00</updated>
    <id>http://okckd.github.io/blog/2014/08/10/big-data-top-k-questions-summarize</id>
    <content type="html"><![CDATA[### Question 

[link](http://dongxicheng.org/big-data/select-ten-from-billions/)

> 在海量数据中找出出现频率最高的前K个数，或者从海量数据中找出最大的前K个数，这类问题通常称为“top K”问题，

> 1. top K value
> 1. top K frequency

### Analysis

__Standard solution__ is 【分治+trie树/hash+小顶堆】, which I covered in another post [Big Data - Top k Frequency](/blog/2014/07/25/big-data-Top-k-frequency/). Briefly it is 3 steps: 

1. 先将数据集按照hash方法分解成多个小数据集，
1. 使用trie树或者hash统计每个小数据集中的query词频，
1. 用小顶堆求出每个数据集中出频率最高的前K个数

But, there're other senarios where different solutions may apply. Consider: 

1. Single core vs. multiple core

1. Single PC vs. multiple PC

1. Large RAM vs. limited RAM

1. Distributed system

### 1. 单机+单核+足够大内存

设每个查询词平均占8Byte，则10亿个查询词所需的内存大约是10^9*8=8G内存。如果你有这么大的内存，直接在内存中对查询词进行排序，顺序遍历找出10个出现频率最大的10个即可。这种方法简单快速，更加实用。当然，也可以先用HashMap求出每个词出现的频率，然后求出出现频率最大的10个词。

### 2. 单机+单核+受限内存

这种情况下，需要将原数据文件切割成一个一个小文件，如，采用hash(x)%M，将原文件中的数据切割成M小文件，如果小文件仍大于内存大小，继续采用hash的方法对数据文件进行切割，直到每个小文件小于内存大小，这样，每个文件可放到内存中处理。采用3.1节的方法依次处理每个小文件。

### 3. 单机+多核+足够大内存

这时可以直接在内存中实用hash方法将数据划分成n个partition，每个partition交给一个线程处理，线程的处理逻辑是同[1]节类似，最后一个线程将结果归并。

该方法存在一个瓶颈会明显影响效率，即数据倾斜，每个线程的处理速度可能不同，快的线程需要等待慢的线程，最终的处理速度取决于慢的线程。解决方法是，__将数据划分成 (c x n)个partition（c>1），每个线程处理完当前partition后主动取下一个partition继续处理__，直到所有数据处理完毕，最后由一个线程进行归并。

### 4. 多机+受限内存

这种情况下，为了合理利用多台机器的资源，可将数据分发到多台机器上，每台机器采用[3]节中的策略解决本地的数据。可采用__hash + socket__方法进行数据分发。

### 5. Distributed

Top k问题很适合采用__MapReduce框架__解决，用户只需编写一个map函数和两个reduce 函数，然后提交到Hadoop（采用mapchain和reducechain）上即可解决该问题。

A map function. 对于map函数，采用hash算法，将hash值相同的数据交给同一个reduce task. 

2 reduce functions. 对于__第一个reduce函数__，采用HashMap统计出每个词出现的频率，对于__第二个reduce函数__，统计所有reduce task输出数据中的top k即可。

### 6. Other

公司一般不会自己写个程序进行计算，而是提交到自己核心的数据处理平台上计算，该平台的计算效率可能不如直接写程序高，但它具有__良好的扩展性和容错性__，而这才是企业最看重的。
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[[Design] Big Data - Top K Frequency 2]]></title>
    <link href="http://okckd.github.io/blog/2014/08/10/big-data-top-k-frequency-2/"/>
    <updated>2014-08-10T00:00:00+08:00</updated>
    <id>http://okckd.github.io/blog/2014/08/10/big-data-top-k-frequency-2</id>
    <content type="html"><![CDATA[### Question 

[link](http://blog.csdn.net/v_july_v/article/details/7382693)

> 一个文本文件，大约有一万行，每行一个词，要求统计出其中最频繁出现的前10个词，请给出思想，给出时间复杂度分析。

### Analysis

__The basic solution for 'Top K' questions__ is 【分治+trie树/hash+小顶堆】. 

In the previous post [Big Data - Top k Frequency](/blog/2014/07/25/big-data-Top-k-frequency/), we used HashMap for calculating query frequency. Now we __use Trie to do it__. 

> 这题是考虑时间效率。用trie树统计每个词出现的次数，时间复杂度是O(n x le)（le表示单词的平准长度）。然后是找出出现最频繁的前10个词，可以用堆来实现，前面的题中已经讲到了，时间复杂度是O(n x lg10)。所以总的时间复杂度，是O(n x le)与O(n x lg10)中较大的哪一个。

#### How to use Trie to calculate word frequency? 

在Trie的node节点中[添加count域后](http://blog.csdn.net/ohmygirl/article/details/7953814)，可以统计单词出现的次数。统计的方法就是在插入单词的时候，令相应的count域加1（初始化为0）. 
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[[Design] Big Data - Fuzzy Search Url]]></title>
    <link href="http://okckd.github.io/blog/2014/08/10/big-data-fuzzy-search-url/"/>
    <updated>2014-08-10T00:00:00+08:00</updated>
    <id>http://okckd.github.io/blog/2014/08/10/big-data-fuzzy-search-url</id>
    <content type="html"><![CDATA[### Question 

[link](http://blog.csdn.net/v_july_v/article/details/7382693)

> 给你A,B两个文件，各存放50亿条URL，每条URL占用64字节，内存限制是4G，让你找出A,B文件共同的URL。如果是三个乃至n个文件呢？

### Bloom Filter

自从Burton Bloom在70年代提出[Bloom Filter](http://blog.csdn.net/v_july_v/article/details/6685894)之后，Bloom Filter就被广泛用于__拼写检查和数据库系统中__。

#### 基本原理及要点

An empty Bloom filter is __a bit array of m bits__, all set to 0. There must also be __k different hash functions__ defined, each of which maps or hashes some set element to one of the m array positions with a uniform random distribution. 

很明显这个过程并不保证查找的结果是100%正确的。同时也不支持删除一个已经插入的关键字，因为该关键字对应的位会牵动到其他的关键字。

所以一个简单的改进就是 counting Bloom filter，用一个counter数组代替位数组，就可以支持删除了。 

### Error rate

    m: length of BF array (in bits)
    n: number of input elements
    k: number of hash functions

A Bloom filter [with 1% error](http://en.wikipedia.org/wiki/Bloom_filter#Space_and_time_advantages) and an optimal value of k, in contrast, requires only about 9.6 bits per element (means m = 9.6 x n). 

#### Usage

Bloom Filter可以用来实现数据字典，进行数据的判重，或者集合求交集.

### Solution

Of course we can always use __【分治+trie树/hash+小顶堆】__ standard solution, but for __Fuzzy search, BF is the best__. 

4G = 2^32 大概是40亿 x 8大概是340亿bit，n = 50亿，如果按出错率0.01算需要的大概是480亿个bit。现在可用的是340亿，相差并不多，这样可能会使出错率上升些。
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[[Design] Big Data - Find Median Numbers]]></title>
    <link href="http://okckd.github.io/blog/2014/08/10/big-data-find-median/"/>
    <updated>2014-08-10T00:00:00+08:00</updated>
    <id>http://okckd.github.io/blog/2014/08/10/big-data-find-median</id>
    <content type="html"><![CDATA[### Question 

[link](http://blog.csdn.net/v_july_v/article/details/7382693)

> 5亿个int找它们的中位数.

### Analysis

Categorized under __双层桶划分__.

Idea: 首先我们将int划分为2^16个区域，然后读取数据统计落到各个区域里的数的个数，之后我们根据统计结果就可以判断中位数落到那个区域，同时知道这个区域中的第几大数刚好是中位数。然后第二次扫描我们只统计落在这个区域中的那些数就可以了。

### Details

开一个大小为65536的Int数组，第一遍读取，统计Int32的高16位的情况(就相当于用该数除以65536)。每读取一个数，数组中对应的计数+1。第一遍统计之后，遍历数组，逐个累加统计，看中位数处于哪个区间。

第二遍统计同上面的方法类似，但这次只统计处于区间k的情况，这次计数之后，再统计一下，看中位数所处的区间，最后将高位和低位组合一下就是结果了。

And this can be done more than 2 times, depending on the input size (eg. if input is int64, then do 24/20/20 bits).
]]></content>
  </entry>
  
</feed>
