<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Design | Woodstock Blog]]></title>
  <link href="http://okckd.github.io/blog/categories/design/atom.xml" rel="self"/>
  <link href="http://okckd.github.io/"/>
  <updated>2015-02-03T10:17:58+08:00</updated>
  <id>http://okckd.github.io/</id>
  <author>
    <name><![CDATA[Charlie Brown]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[[Design] Limit the Request Per Second]]></title>
    <link href="http://okckd.github.io/blog/2015/02/01/limit-request-per-second/"/>
    <updated>2015-02-01T00:00:00+08:00</updated>
    <id>http://okckd.github.io/blog/2015/02/01/limit-request-per-second</id>
    <content type="html"><![CDATA[### Question

[link](http://www.mitbbs.com/article_t/JobHunting/32841633.html)

> 有一个接口叫 void setRPS(int num);

> 接下来不断有request过来，如何实现下面的接口，返回accept或者deny，

    bool process(int timestamp){
    
    }

### Solution

Suggested by level 5 of [this post](http://www.mitbbs.com/article_t/JobHunting/32841633.html):

1. maintain a variable for the number of request processed/rejected.
    1. This variable must be atomic, thus a __AtomicInteger__. 
    1. the variable is called 'count'
1. have a method to process request
    1. if count < limit, do it
    1. otherwise, reject
1. __This is the most important__: clear the count every 1 seconds! 
    1. eg. LIMIT = 5r/s, so: 
    1. the __first 5 number of requests in every second__ are getting fulfilled
    1. from 6th request onward, the request all rejected, until the next second.

### Code 

    public class SetRps {

        AtomicInteger count = new AtomicInteger(0);
        int limit = -1;
        int printIndex = 1;
        long startTimestamp = -1;

        void setRPS(int num) {
            limit = num;
        }

        boolean process(long timestamp) {
            // suppose timestamp is ms
            synchronized (this) {
                if (count.get() < limit) {
                    // can process
                    count.incrementAndGet();
                    System.out.println(printIndex++ + ". processing request "
                            + timestamp % 100000 / 1000 + "," + timestamp % 1000);
                    return true;
                }
                if (timestamp - startTimestamp >= 1000) {
                    // every 1 seconds, reset
                    count.set(0);
                    startTimestamp = timestamp;
                    System.out.println("clear!");
                    return true;
                }
            }
            return false;
        }
    }
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[[Design] Speed Up Webpage for Slow Connection (2)]]></title>
    <link href="http://okckd.github.io/blog/2015/01/28/speed-up-web-page-2/"/>
    <updated>2015-01-28T00:00:00+08:00</updated>
    <id>http://okckd.github.io/blog/2015/01/28/speed-up-web-page-2</id>
    <content type="html"><![CDATA[[ref](www.geeksforgeeks.org/amazon-interview-set-72-campus-sde-1)

### Question

> Suppose you are handling Amazon website and you have 10 MB size home page. Optimize the homepage for a customer who has 100 kbps internet connection.

> Further he asked for the customer who has 100 mbps internet connection.

### Website KPI

There are [3 interesting phases](https://community.compuwareapm.com/community/display/PUB/Best+Practices+on+Web+Site+Performance+Optimization) of a web site from an end-user performance perspective. 

1. First Impression
1. OnLoad 
1. Fully Loaded Time.

### Loading Time

__Question: what percentage of the time a user spends waiting for your page to load is spent after the HTML comes back to their browser__? 

It is typically __[over 90%](http://www.sitepoint.com/seven-mistakes-that-make-websites-slow/)__. 

Most of the time users spend waiting on your website is spent after the HTML page has been retrieved by their browser. 

#### Fetching the HTML is just the beginning

__In a nutshell, browsers parse your page’s HTML, sequentially discovering its assets__ (such as scripts, stylesheets, and images), requesting and then either parsing and executing them or displaying them as appropriate. 

But these assets are not simply fetched all at once. Instead, the __browser opens a limited number of connections to the server(s)__ referenced by the page. There is __overhead involved in establishing TCP and HTTP connections__, and some __unavoidable latency__ in pushing the request and response bytes back and forth across the network.

So, in general, round trips between the browser and server are expensive. The structure of the HTML markup, the number and the ordering of its assets, are absolutely critical factors in its performance.

### What hijacks your load time

#### 1. Too Many HTTP Requests

This is the single biggest contributor to performance problems in most web pages. 

1. Concatenate scripts and stylesheets

1. Combine images with sprites (put common images into a single large image file, then use CSS to position and selectively display the appropriate portion of the sprite image)

1. Use fewer images, more CSS. 

#### 2. Minimal Client-side Processing

1. Validation on client. (eg. form input)

1. Use web standards and MVC separation, making a maintainable, accessible, future-proof and max-performance website. 

    Think of the HTML as the model, the CSS as the view, and the JavaScript as the controller. This separation tends to make code more efficient and maintainable, and makes many optimization techniques much more practical to apply.

1. Push presentation code into the client tier (eg. Charts and graphs — push raw data to the client in JSON format, and use JavaScript and CSS to create pretty graphs.)

1. Leverage Ajax techniques (only requiring small parts of the page to change in response to user actions)

#### 3. Low Number of Parallel Requests

Fetch a script, parse and execute it, then fetch another one... this will use up all the available connections. There are things you can do to your HTML to allow virtually any browser to make many requests at once, which has a huge impact on latency.

1. Use browser-appropriate domain sharding

1. Use intelligent script loading

1. Leverage Keep-Alive (reuse the same TCP connection for multiple HTTP request/response cycles)

#### 4. Failure to leverage browser cache / local storage

1. [HTTP cache overview](http://www.mnot.net/cache_docs/)

1. Leverage local storage

#### 5. Third-party widgets

1. Avoid third-party widgets!
1. Try to use widgets that provide asynchronous implementations, so their inevitably terrible performance impacts their widget without dragging down your entire UX with it.

#### 7. Failure to Use a Global Network

Amazon S3. 

Ref: http://www.sitepoint.com/seven-mistakes-that-make-websites-slow/
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[[Design] Speed Up Webpage for Slow Connection (1)]]></title>
    <link href="http://okckd.github.io/blog/2015/01/28/speed-up-web-page-1/"/>
    <updated>2015-01-28T00:00:00+08:00</updated>
    <id>http://okckd.github.io/blog/2015/01/28/speed-up-web-page-1</id>
    <content type="html"><![CDATA[[ref](www.geeksforgeeks.org/amazon-interview-set-72-campus-sde-1)

### Question

> Suppose you are handling Amazon website and you have 10 MB size home page. Optimize the homepage for a customer who has 100 kbps internet connection.

> Further he asked for the customer who has 100 mbps internet connection.

### Reading

[This](http://sixrevisions.com/web-development/site-speed-performance/) is a very nice article about website speedup. Below is the full quoted text. 

#### 1. Defer Loading Content When Possible

Ajax allows us to build web pages that can be __asynchronously updated__ at any time. This means that instead of reloading an entire page when a user performs an action, we can simply update parts of that page.

We can use an image gallery as an example. Image files are big and heavy; they can slow down page-loading speeds of web pages. Instead of loading all of the images when a user first visits the web page, we can just display thumbnails of the images and then when the user clicks on them, we can asynchronously request the full-size images from the server and update the page. This way, if a user only wants to see a few pictures, they don’t have to suffer waiting for all of the pictures to download. This development pattern is called __lazy loading__.

__Ajax/web development libraries__ like jQuery, Prototype, and MooTools can make deferred content-loading easier to implement.

#### 2. Use External JS and CSS Files

When the user first loads your web page, the browser will cache external resources like CSS and JavaScript files. Thus, instead of inline JavaScript and CSS files, it’s best to __place them in external files__.

Using inline CSS also increases the rendering time of a web page; having everything defined in your main CSS file lets the browser do less work when rendering the page, since it already knows all the style rules that it needs to apply.

__As a bonus__, using external JavaScript and CSS files makes site maintenance easier because you only need to maintain global files instead of code scattered in multiple web pages.

#### 3. Use Caching Systems

If you find that your site is connecting to your database in order to create the same content, it’s time to start using a __caching system__. By having a caching system in place, your site will only have to create the content once instead of creating the content every time the page is visited by your users. Don’t worry, caching systems periodically refresh their caches depending on how you set it up — so even constantly-changing web pages (like a blog post with comments) can be cached.

__Popular content management systems__ like WordPress and Drupal will have __static caching features__ that convert dynamically generated pages to static HTML files to reduce unnecessary server processing. For WordPress, check out [WP Super Cache](https://wordpress.org/plugins/wp-super-cache/) (one of the six critical WordPress plugins which, claimed by the author, enjoyed a improvement by 259.1% for content-heavy pages). Drupal has a page-caching feature in the core.

There are also __database caching and server-side scripts caching systems__ that you can install on your web server (if you have the ability to do so). For example, PHP has extensions called PHP accelerators that optimize performance through caching and various other methods; one example of a [PHP accelerator](http://en.wikipedia.org/wiki/PHP_accelerator) is APC. [Database caching](http://en.wikipedia.org/wiki/Database_caching) improves performance and scalability of your web applications by reducing the work associated with database read/write/access processes; __[memcached](http://www.memcached.org/)__, for example, caches frequently used database queries. 

#### 8. Load JavaScript at the End of Your Document

It’s best if you have your scripts loading at the end of the page rather than at the beginning. It allows for the browser to render everything before getting started with the JavaScript. This makes your web pages feel more responsive because the way JavaScript works is that it blocks anything below it from rendering until it has finished downloading. If possible, reference JavaScript right before the closing (body) tag of your HTML documents. To learn more, read about deferring the loading of JavaScript.

#### 9. Use a Content Delivery Network (CDN)

Your site’s speed is greatly affected by where the user’s location is, relative to your web server. The farther away they are, the more distance the data being transmitted has to travel. Having your content cached __across multiple, strategically placed geographical locations__ helps take care of this problem. 

A CDN will often make your operating cost a little higher, but you definitely gain a speed bonus. Check out MaxCDN or __Amazon Simple Storage Service (Amazon S3)__.

#### 10. Optimize Web Caching

Along with using caching systems, you should create websites that utilize __web caching__ as much as possible. Web caching is when files are __cached by the web browser__ for later use. Things that browsers can cache include CSS files, JavaScript files, and images.

Aside from the basics, such as putting CSS and JavaScript code that are used in multiple pages in external files, there are many ways to make sure that you are caching your files in the most efficient way possible.

For example, you can set HTTP response headers such as Expires and Last-Modified to reduce the need of re-downloading certain files when the user comes back to your site. To learn more, read about [caching in HTTP](http://www.w3.org/Protocols/rfc2616/rfc2616-sec13.html) and [leveraging browser caching](https://developers.google.com/speed/docs/insights/LeverageBrowserCaching?csw=1#LeverageBrowserCaching).

To set up HTTP Expires headers in Apache, read this tutorial on adding future expires headers.

#### Other mentions

4. __Avoid Resizing Images in HTML__ (using HTML’s width and height attributes), for the sake of smaller file size. 

6. __Optimize Image Sizes by Using the Correct File Format__. Eg. JPG format often displays photographic images at smaller file sizes than PNG. 

7. __Optimize the Way You Write Code__. For example, instead of using (h1)(em)Your heading(em)(h1), you can easily use CSS to make your headings italics. 

    Writing code efficiently not only reduces file sizes of your HTML and CSS documents, but also makes it easier to maintain.

Ref: http://sixrevisions.com/web-development/site-speed-performance/
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[[Design] Distributed Caching - Memcached]]></title>
    <link href="http://okckd.github.io/blog/2015/01/24/distributed-caching-memcached/"/>
    <updated>2015-01-24T00:00:00+08:00</updated>
    <id>http://okckd.github.io/blog/2015/01/24/distributed-caching-memcached</id>
    <content type="html"><![CDATA[### What is Memcached?

[Memcached](http://memcached.org/) is an __in-memory key-value store for small chunks of arbitrary data__ (strings, objects) from results of database calls, API calls, or page rendering.

1. Free & open source
1. high-performance, distributed memory object caching system
1. generic in nature
1. intended for use in speeding up dynamic web applications by alleviating database load

Definition from [wiki](http://en.wikipedia.org/wiki/Memcached): 

> Memcached is a __general-purpose distributed memory caching system__. It is often used to speed up dynamic database-driven websites by __caching data and objects in RAM__ to reduce the number of times an __external data source__ (such as a database or API) must be read.

### Who uses Memcached?

1. Facebook
1. YouTube
1. Twitter
1. Amazon
1. Reddit
1. Yahoo
1. Zynga

### Why Memcached?

Run memcached on one or more hosts and then use the shared cache to store objects. Because each host’s RAM is storing information, the access speed [will be much faster than](http://www.blogs.zeenor.com/category/interview-questions/page/9) having to load the information from disk. This can provide __a significant performance boost in retrieving data__ versus loading the data natively from a database. 

Also, because the cache is just a repository for information, you can use the cache to store __any data, including complex structures__ that would normally require a significant amount of effort to create, but in __a ready-to-use format__, helping to reduce the load on your MySQL servers. 

### FAQ

__What is Memcached?__

[It is component](http://www.web-technology-experts-notes.in/2014/09/memcached-interview-questions-and-answers.html) which stored the data temporary for 1 Hour/ 6 Hour/1 Day etc. When we integrate the Memcached with our application, performance of application increased.

Memcached is open source, high-performance distributed memory object used for caching so that execution can be enhanced at nth level.

__Where Memcached can be used?__

•  Social Networking -> Profile Caching
•  Content Aggregation -> HTML/ Page Caching
•  Ad targeting -> Cookie/profile tracking
•  Relationship -> Session caching
•  E-commerce -> Session and HTML caching
•  Location-based services -> Data-base query scaling
•  Gaming and entertainment -> Session caching

__Why use Memcached?__

•  Speed up application processes
•  It determines what to store and what not to
•  Reduce the number of retrieval requests to the database
•  Cuts down the I/O ( Input/Output) access (hard disk)

__In what condition does retrieving cache fail?__

•  Memory allocated for the cache is exhausted
•  Item from cache is deleted
•  Individual item in the cache is expired

__What is the drawback of Memcached?__
 
•  It is not a persistent data store
•  Not a database
•  It is not an application specific
•  It cannot cache large object

__Give more details about memcached failures__

[Memcached servers](http://programmers.stackexchange.com/a/187101) are indeed independent of each other. Memcached server is just an efficient key-value store implemented as in-memory hash table. 

__What makes memcached distributed is the client__, which in most implementations can connect to a pool of servers. Typical implementations use consistent hashing, which means that when you add or remove server to/from a pool of N servers, you only have to remap 1/N keys. 

Typically keys are __not duplicated__ on various hosts, as memcached is __not meant to be persistent store__ and gives no guarantees that your value will persist (for example when running out of assigned memory, memcached server drops least recently used (LRU) elements). Thus it's assumed that your application should handle missing keys.
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[[Design] Design Google Suggest (Autocomplete)]]></title>
    <link href="http://okckd.github.io/blog/2015/01/24/design-google-suggest-autocomplete/"/>
    <updated>2015-01-24T00:00:00+08:00</updated>
    <id>http://okckd.github.io/blog/2015/01/24/design-google-suggest-autocomplete</id>
    <content type="html"><![CDATA[### Overview 

__Google Suggest__ was [launched in 2004](http://googleblog.blogspot.sg/2004/12/ive-got-suggestion.html) as a 20% time project from Google engineer Kevin Gibbs. He developed the idea on a [Google shuttle bus](http://www.theatlantic.com/technology/archive/2013/08/how-googles-autocomplete-was-created-invented-born/278991/).

### Design

1. Use trie. 
1. Use cache (distributed cache)

#### Trie

Just make use of all keywords (including space) and build a trie out of it. Then you are good to go just search in Trie. 

A comparison of speed between DB, Set and Trie can be found [here](http://sujitpal.blogspot.sg/2007/02/three-autocomplete-implementations.html). A lot of implementation code can be found [here](http://stackoverflow.com/questions/7058724/how-to-create-an-efficient-auto-complete). 

#### Memcached

Distributed caching + LRU replacement algorithm. Refer to __[Design] Distributed Caching - memcached__ for more. 
]]></content>
  </entry>
  
</feed>
