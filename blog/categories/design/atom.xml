<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: design | Shuatiblog.com]]></title>
  <link href="http://www.shuatiblog.com/blog/categories/design/atom.xml" rel="self"/>
  <link href="http://www.shuatiblog.com/"/>
  <updated>2015-09-07T00:34:57+08:00</updated>
  <id>http://www.shuatiblog.com/</id>
  <author>
    <name><![CDATA[CodeMonkey]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[[Design] Facebook Photo Storage ]]></title>
    <link href="http://www.shuatiblog.com/blog/2015/09/02/Facebook-photo-storage/"/>
    <updated>2015-09-02T00:00:00+08:00</updated>
    <id>http://www.shuatiblog.com/blog/2015/09/02/Facebook-photo-storage</id>
    <content type="html"><![CDATA[# Stats

Facebook has 1.5 billion monthly active users, 970 million daily active users [as of June 2015](http://newsroom.fb.com/company-info/). 

<img class="middle" src="/assets/images/facebook-user-count.png">

image from [statista.com](http://www.statista.com/statistics/264810/number-of-monthly-active-facebook-users-worldwide/). 

In 2009, Facebook stores 15 billion photos for the user, which grows at 220 million per week, and 550,000 per second at peak. 
    
It's 2015 now, you might want to mulitply these numbers by 3~6. 

I have roughly estimated the statistics of Facebook users, Facebook photos and growth rate, just to give you an idea of the size of data Facebook has got: 

> Total user: 1.5b
>
> Total photoes: 150b, which is 100 photo/user
>
> Each photo got 4 different sizes, so 600b photos are stored. 
>
> New photo per day: 500m
>
> New photo per second: 6,000
>
> Peak incoming photo per second: 3m

# Old architecture

3 tiers design:

1. __Upload tier__ receives users’ photo uploads, scales the original images and saves them on the NFS storage tier.

1. __Photo serving tier__ receives HTTP requests for photo images and serves them from the NFS storage tier.

1. __NFS storage tier__ built on top of commercial storage appliances.

> __[Network File System](https://en.wikipedia.org/wiki/Network_File_System)__ (NFS) is a distributed file system protocol originally developed by Sun Microsystems in 1984, allowing a user on a client computer to access files over a network much like local storage is accessed. 

## Problem

1. there is an __enormous amount of metadata__ 

    ... so much that is [exceeds the caching abilities of the NFS storage tier](https://code.facebook.com/posts/685565858139515/needle-in-a-haystack-efficient-storage-of-billions-of-photos/), __ resulting in multiple I/O operations__ per photo upload or read request

## Solution

1. relies heavily on CDNs to serve photos. 

1. Cachr: a caching server tier caching Facebook "profile" images.

1. NFS file handle cache - deployed on the photo serving tier eliminates some of the NFS storage tier metadata overhead

# Haystack Photo Infrastructure 

The new photo infrastructure merges the __photo serving__ and __storage tier__ into one physical tier. It implements __a HTTP based photo server__ which stores photos in a generic object store called Haystack. 

Goal: eliminate any unnecessary metadata overhead for photo read operations, so that each read I/O operation was only reading actual photo data

5 main functional layers:

1. HTTP server

1. Photo Store

1. Haystack Object Store

1. Filesystem

1. Storage

## Storage 

The commodity machine HW typically is 2x quadcore CPU + 32GB RAM + 512MB NV-RAM cache + 12TB SATA drives. 

> [Non-volatile random-access memory](https://en.wikipedia.org/wiki/Non-volatile_random-access_memory) (NVRAM) is random-access memory that retains its information when power is turned off (non-volatile).  
>
> This is in contrast to dynamic random-access memory (DRAM) and static random-access memory (SRAM) 

So each __storage blade__ is around 10TB. Configured as __RAID-6__ partition. 

> [RAID 6](http://searchstorage.techtarget.com/definition/RAID-6-redundant-array-of-independent-disks), also known as double-parity RAID, uses two parity stripes on each disk. It allows for two disk failures within the RAID set before any data is lost.

Pros:

1. adequate redundancy 
1. excellent read performance 
1. low storage cost down 

Cons:

__The poor write performance__ is partially mitigated by the __RAID controller NVRAM write-back cache__. Since the reads are mostly random, the NVRAM cache is fully reserved for writes. 

__The disk caches are disabled__ in order to guarantee data consistency in the event of a crash or a power loss.

## Filesystem 

### How does filesystem read pictures?

Photo read requests result in __read() system calls__ at known offsets in these files.

Each file in the filesystem is represented by a structure called an inode which contains a block map that maps the logical file offset to the physical block offset on the physical volume. 

For large files, the block map can be quite large.

### Problem

__Block based filesystems__ maintain mappings for __each logical block__, and for large files, this information will not typically fit into the cached inode and is stored in indirect address blocks instead, which must be traversed in order to read the data for a file. 

There can be several layers of indirection, so a single read could result in __several I/Os__ (if not cached).

### Solution

__Extent based filesystems__ maintain mappings only for contiguous ranges of blocks (extents). A block map for a contiguous large file could consist of only one extent which would fit in the inode itself. 

> [An extent](https://goo.gl/uQA35V) is a contiguous area of storage reserved for a file in a file system, represented as a range. A file can consist of zero or more extents; __one file fragment requires one extent__. The direct benefit is in storing each range compactly as two numbers, instead of canonically storing every block number in the range.
>
> Extent-based file systems can also __eliminate most of the metadata overhead of large files__ that would traditionally be taken up by the block allocation tree... saving on storage space is pretty slight, but... __the reduction in metadata is significant and reduces exposure to file system corruption__ as one bad sector in the _block allocation tree_ causes much greater data loss than one bad sector in stored data.

### Problem of Extent-based file systems

However, if the file is severely fragmented and its blocks are not contiguous on the underlying volume, its block map can grow large as well. 

### The solution

Fragmentation can be mitigated by __aggressively allocating a large chunk of space__ whenever growing the physical file. 

Currently, the filesystem of choice is XFS, an extent based filesystem providing efficient file preallocation. 

> __[XFS](https://en.wikipedia.org/wiki/XFS)__ is a high-performance 64-bit journaling file system created by Silicon Graphics, Inc (SGI) in 1993.
>
> ...was ported to the Linux kernel in 2001. As of June 2014, XFS is supported by most Linux distributions, some of which use it as the default file system.
>
> XFS enables __extreme scalability of I/O threads__, file system bandwidth, and size of files and of the file system itself when spanning multiple physical storage devices. 
>
> Space allocation is performed via extents with __data structures stored in B+ trees__, improving the overall performance of the file system, especially when handling large files.
>
> __Delayed allocation__ assists in the prevention of file system fragmentation; __online defragmentation__ is also supported. A feature unique to XFS is the __pre-allocation of I/O bandwidth__ at a pre-determined rate, which is suitable for many real-time applications.

## Haystack

Haystack is a simple __log structured (append-only) object store__. Many images store in one Haystack. Typically, [Haystack Store is 100GB size](http://jishu.zol.com.cn/17742.html). 

A Haystack consists of two files:

1. __haystack store file__ (containing the needles)
    1. superblock
    1. needles (1 needle is 1 image)
1. __an index file__

### 1. haystack store file 

<img class="middle" src="/assets/images/851582_1409519009260319_311676661_n.jpg">

1. The first 8KB of the haystack store is occupied by the __superblock__. 

1. following the superblock are __needles__

    __Needles represents the stored objects__. Needle consisting of a header, the data, and a footer: 

    <img class="middle" src="/assets/images/851578_319395058204993_541487263_n.jpg">

    A needle is uniquely identified by its \<Offset, Key, Alternate Key, Cookie\> tuple. 

    Haystack doesn’t put any restriction on the values of the keys, and there can be needles with duplicate keys. 

### 2. Index File

__Needle__ consisting of a header, the data, and a footer: 

<img class="middle" src="/assets/images/851582_1374324519464800_699636937_n.jpg">

The index file provides the minimal metadata required to locate a particular needle in the haystack store file. 

<img class="middle" src="/assets/images/851582_314454922033518_1196942525_n.jpg">

The index file is not critical, as it can be rebuilt from the haystack store file if required. 

The main purpose of the index: quick loading of the needle metadata into memory without traversing the larger Haystack store file, since the index is usually less than 1% the size of the store file. 

### Summary

All needles are stored in Haystack store file, and their location information is stored in Index File. 

What is Needle? Needles represents the stored objects (1 needle - 1 image). 

## Haystack Operations

1. __write__

    append new needle to haystack store file.
    
    later, corresponding index records are __updated async__. 
    
    In case of failure, any partial needles are discarded, and fix index from the end of the haystack.
    
    You can't overwrite any needle, but you can insert using same key. Later, the needle __with dup keys but largest offset__ became the most recent one. 

1. __read__

    __parameters passed in__: offset, key, alt key, cookie, data size
    
    if key, alt key and cookie matches, and checksum correct and needle is not marked as deleted, return. 

1. __delete__

    marks needle as deleted (set 1 bit), but index is not modified. 
    
    the deleted space is not reclaimed unless __compact the haystack__

## Photo Store Server 

Photo Store Server is responsible for accepting HTTP requests and translating them to the corresponding Haystack store operations. 

In order to minimize the number of I/Os required to retrieve photos, the server keeps an __in-memory index of all photo offsets__. 

At startup, __the (photo) server reads the haystack index file and populates the in-memory index__. The in-memory index is different from the index file in Haystack, as it stores lesser information, like this: 

<img class="middle" src="/assets/images/851584_503528913060377_1268325854_n.jpg">

1. __Photo Store Write/Modify Operation__

    1. writes photos to the haystack 
    1. updates the in-memory index 
    
    if there are duplicate images, the one stored at a larger offset is valid.

1. __Photo Store Read Operation__

    passed in:
    
    1. haystack id 
    1. a photo key, 
    1. size 
    1. cookie 
    
    The server performs a lookup in the in-memory index based on the photo key and retrieves the offset of the needle containing the requested image.
    
    Since haystack delete operation doesn’t update the haystack index file record. Therefore a freshly populated in-memory index can contain stale entries for the previously deleted photos. Read such photo will fail and the in-memory index is updated to 0.

1. __Photo Store Delete Operation__

    After calling the haystack delete operation, the in-memory index is updated to 'offset = zero' 

1. __Compaction__

    Compaction is an online operation which reclaims the space used by the deleted and duplicate needles.
    
    creates a new haystack 

1. __HTTP Server__

    evhttp server 

    multiple threads, with each serving a single HTTP request. Workload is mostly I/O bound, thus the performance of the HTTP server is not critical.

# Summary 

Storing photos as needles in the haystack __eliminates the metadata overhead__ by aggregating hundreds of thousands of images in a single haystack store file. 

This keeps the metadata overhead very small and allows us to __store each needle’s location in the store file in an in-memory index__. 

This allows retrieval of an image’s data in __a minimal number of I/O operations__, eliminating all unnecessary metadata overhead. 

Ref: https://code.facebook.com/posts/685565858139515/needle-in-a-haystack-efficient-storage-of-billions-of-photos/
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[[Design] How Google search works ]]></title>
    <link href="http://www.shuatiblog.com/blog/2015/08/30/how-google-search-works/"/>
    <updated>2015-08-30T00:00:00+08:00</updated>
    <id>http://www.shuatiblog.com/blog/2015/08/30/how-google-search-works</id>
    <content type="html"><![CDATA[# Overview

Launched on Sep 15th, 1997

__60 trillion individual pages. 100 million GB data__. 

__40,000 search per second__, or 3 billion search per day. 

As of Feb 2015, 65% market share in US.

# 1. Crawl

Google crawl from 1 page to another using __[Googlebot](https://support.google.com/webmasters/answer/182072?vid=1-635765406868848825-432642872)__. It starts from previous urls crawled, or augmented with __[Sitemap data](https://en.wikipedia.org/wiki/Site_map)__

> __A sitemap__ is a list of pages of a web site accessible to crawlers or users. It can be either a document in any form used as a planning tool for Web design, or a Web page that lists the pages on a Web site, typically organized in hierarchical fashion.

# 2. Indexing 

Compile the data (key content tags, atrributes, like title tags, ALT attributes). Google don't process rich media or dynamic files. 

# 3. Algorithm

When search, pull all relevant results from the Index. 

Rank the result based on 200+ factors, one of which is the __[PageRank](https://en.wikipedia.org/wiki/PageRank)__ for a given page.

> __PageRank__ is the measure of the importance of a page based on the incoming links from other pages. In simple terms, each link to a page on your site from another site adds to your site's PageRank. 

> Not all links are equal: Google works hard to identify spam links. The best types of links are those that are given based on the quality of your content.

To rank higher, follow [Webmaster Guidelines](https://support.google.com/webmasters/answer/35769?vid=1-635765406868848825-432642872).
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[[Design] How is Pipe implemented in Unix/Linux ]]></title>
    <link href="http://www.shuatiblog.com/blog/2015/07/23/how-is-pipe-implemented-unix/"/>
    <updated>2015-07-23T00:00:00+08:00</updated>
    <id>http://www.shuatiblog.com/blog/2015/07/23/how-is-pipe-implemented-unix</id>
    <content type="html"><![CDATA[# Overview

In Unix-like OS, __[a pipeline is a set of processes](https://goo.gl/0NAqd9) chained by their standard streams__, so that the output of each process (stdout) feeds directly as input (stdin) to the next one. 

[Pipes are unidirectional byte streams which connect the standard output](http://stackoverflow.com/a/17503877) from one process into the standard input of another process. __Neither process is aware of this redirection__ and behaves just as it would normally. It is the shell which sets up these temporary pipes between the processes.

# Process

1. Linux has a VFS called __pipefs__ that is mounted in the kernel (not in user space)

    > __[PipeFS](http://www.linux.org/threads/pipefs-sockfs-debugfs-and-securityfs.5383/)__ is a unique virtual filesystem. __This filesystem is mounted inside the kernel__ rather than in the userspace. While most filesystems are mounted under "/", PipeFS is mounted on "pipe:", __making PipeFS its own root__ (yes, a second root filesystem). 
    >
    > This filesystem is one superblock and cannot exceed that amount system-wide. The entry point of this filesystem/second-root is the system-call "pipe()". Unlike the other virtual/pseudo filesystems, this one cannot be viewed.
    >
    > Many of you may be wondering what purpose this PipeFS filesystem serves. Unix pipes use this filesystem. When a pipe is used (eg. ls | less), __the pipe() system-call makes a new pipe object on this filesystem__. Without this filesystem, pipes cannot be made. 
    >
    > Also, threads and forks communicate together via pipes. Without PipeFS, processes could not fork and threads could not communicate. 
    >
    > Network pipes also rely on this virtual/pseudo filesystem.

1. pipefs has a single super block and is mounted at it's own root (pipe:), alongside /

1. pipefs cannot be viewed directly unlike most file systems

1. The entry to pipefs is via the pipe(2) syscall

1. The pipe(2) syscall used by shells for piping with the | operator (or manually from any other process) creates a new file in pipefs which behaves pretty much like a normal file

1. The file on the left hand side of the pipe operator has its stdout redirected to the temporary file created in pipefs

1. The file on the right hand side of the pipe operator has its stdin set to the file on pipefs

1. pipefs is stored in memory and through some kernel magic

Ref: http://unix.stackexchange.com/q/148401
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[[Design] Cryptographic standard, AES and RSA ]]></title>
    <link href="http://www.shuatiblog.com/blog/2015/06/09/Cryptographic-standards-AES-RSA/"/>
    <updated>2015-06-09T00:00:00+08:00</updated>
    <id>http://www.shuatiblog.com/blog/2015/06/09/Cryptographic-standards-AES-RSA</id>
    <content type="html"><![CDATA[# Overview

## 3 areas of cryptographic standard:

1. encryption standard

    1. Data Encryption Standard (obsolete)
    1. Triple DES
    1. __Advanced Encryption Standard (AES)__
    1. __RSA__
    1. OpenPGP
    1. CipherSaber

1. hash standard

    1. __MD5__
    1. __SHA-1__
    1. SHA-2
    1. HMAC
    1. PBKDF2

1. digital signature standard

    1. Digital Signature Algorithm (DSA)
    1. RSA
    1. Elliptic

## Symmetric-key algorithm 

[Use the same cryptographic keys](http://en.wikipedia.org/wiki/Symmetric-key_algorithm) for both encryption and decryption. 

The keys represent a shared secret between two parties, and maintain a private information link. 

This requirement that both parties have access to the secret key is one of the main drawbacks. 

## Public-key cryptography 

The public key is used: 

1. encrypt plaintext 
1. verify a digital signature

private key is used: 

1. decrypt ciphertext 
1. create a digital signature.

# Encryption standard

## RSA Vs. AES

__RSA is very computationally expensive__ by comparison with AES. It involves mathematics with very large numbers, whilst AES can be implemented with relatively simple bit operations. 

[RSA is a public-key encryption algorithm](http://security.stackexchange.com/questions/10949/encryption-should-i-be-using-rsa-or-aes) (asymmetric), while AES is a symmetric key algorithm. Often a cryptosystem will use both algorithms. 

[A good compromise is to](http://stackoverflow.com/questions/13238674/aes-vs-rsa-to-encrypt-large-size-of-data) use RSA to encrypt the symmetric key that is then used in AES encryption of the larger data.

## GitHub

uses RSA encryption.

# hash standard

## MD5

The MD5 message-digest algorithm is a widely used cryptographic hash function producing a 128-bit (16-byte) hash value, or 32 digit Hex.

> d -> 8277e0910d750195b448797616e091ad
>
> good morning -> 2b849500e4585dab4196ec9a415edf8f

## SHA-1

SHA-1 produces a 160-bit (20-byte) hash value, or 40 digit Hex.

## For more

About MD5, SHA-1 and other, refer to __[Design] Cryptographic Hash, MD5 and Digital Signature__

# digital signature standard

A valid digital signature gives a recipient confidence that the message was created by a known sender.

commonly used for software distribution, financial transactions 

<img class="middle" src="/assets/images/digital_signature.png">

[To create a digital signature](http://searchsecurity.techtarget.com/definition/digital-signature), signing software (such as an email program) creates a one-way hash of the data to be signed. The private key is then used to encrypt the hash. 

> The reason for encrypting the hash instead of entire message is that a hash function can convert an arbitrary input into a fixed length value, which is usually much shorter. 

Other party validate the integrity of the data by using the signer's public key to decrypt the hash.

> Note: you can choose to '__ Add digital signature to this message __' in Microsoft Office. 
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[[Design] Linux and TCP ports ]]></title>
    <link href="http://www.shuatiblog.com/blog/2015/06/08/linux-and-tcp-ports/"/>
    <updated>2015-06-08T00:00:00+08:00</updated>
    <id>http://www.shuatiblog.com/blog/2015/06/08/linux-and-tcp-ports</id>
    <content type="html"><![CDATA[# Overview 

[a port](http://en.wikipedia.org/wiki/Port_%28computer_networking%29) is __a software construct serving as a communications endpoint__ in a computer's host operating system.

purpose of ports is to uniquely identify different applications or processes running on a single computer and thereby __enable them to share a single physical connection to a packet-switched network__ like the Internet.

The protocols that __primarily use ports__ are the Transport Layer protocols, such as TCP and UDP. 

__Port info can be viewed on Linux /etc/services files__.

## there're only 65536 ports

In TCP/IP stack, port number field is just 16bit size unsigned integer. Port number thus ranging from 0 to 65535.

## well-known ports 

__Well-known ports__ (or Privileged Ports) are those from 0 through 1023. 

+ 20 & 21: File Transfer Protocol (FTP)
+ 22: Secure Shell (SSH)
+ 23: Telnet remote login service
+ 25: Simple Mail Transfer Protocol (SMTP)
+ 53: Domain Name System (DNS) service
+ 80: Hypertext Transfer Protocol (HTTP) used in the World Wide Web
+ 110: Post Office Protocol (POP3)
+ 119: Network News Transfer Protocol (NNTP)
+ 143: Internet Message Access Protocol (IMAP)
+ 161: Simple Network Management Protocol (SNMP)
+ 194: Internet Relay Chat (IRC)
+ 443: HTTP Secure (HTTPS)
+ 465: SMTP Secure (SMTPS)

## Socket

[Socket is combination of](http://www.linuxnix.com/2011/05/important-port-numbers-linux-system-administrator.html) software Port and IP address.

## Protocol number

In an IP header, [the Protocol field identifies the service](https://technet.microsoft.com/en-us/library/cc959827.aspx) in the next higher level in the protocol stack to which data is passed. __Do not confuse this with port number, which is used for communication by TCP/UDP__. 

<table>
<tbody><tr><th>
<p>
Service</p>
</th><th>
<p>
Protocol Number</p>
</th></tr>
<tr><td>
<p>
Internet Control Message Protocol (ICMP)</p>
</td><td>
<p>
1</p>
</td></tr>
<tr><td>
<p>
Transmission Control Protocol (TCP)</p>
</td><td>
<p>
6</p>
</td></tr>
<tr><td>
<p>
User Datagram Protocol (UDP)</p>
</td><td>
<p>
17</p>
</td></tr>
<tr><td>
<p>
General Routing Encapsulation (PPTP data over GRE)</p>
</td><td>
<p>
47</p>
</td></tr>
<tr><td>
<p>
Authentication Header (AH) IPSec</p>
</td><td>
<p>
51</p>
</td></tr>
<tr><td>
<p>
Encapsulation Security Payload (ESP) IPSec</p>
</td><td>
<p>
50</p>
</td></tr>
<tr><td>
<p>
Exterior Gateway Protocol (EGP)</p>
</td><td>
<p>
8</p>
</td></tr>
<tr><td>
<p>
Gateway-Gateway Protocol (GGP)</p>
</td><td>
<p>
3</p>
</td></tr>
<tr><td>
<p>
Host Monitoring Protocol (HMP)</p>
</td><td>
<p>
20</p>
</td></tr>
<tr><td>
<p>
Internet Group Management Protocol (IGMP)</p>
</td><td>
<p>
88</p>
</td></tr>
<tr><td>
<p>
MIT Remote Virtual Disk (RVD)</p>
</td><td>
<p>
66</p>
</td></tr>
<tr><td>
<p>
OSPF Open Shortest Path First</p>
</td><td>
<p>
89</p>
</td></tr>
<tr><td>
<p>
PARC Universal Packet Protocol (PUP)</p>
</td><td>
<p>
12</p>
</td></tr>
<tr><td>
<p>
Reliable Datagram Protocol (RDP)</p>
</td><td>
<p>
27</p>
</td></tr>
<tr><td>
<p>
Reservation Protocol (RSVP) QoS</p>
</td><td>
<p>
46</p>
</td></tr>
</tbody></table>

> [When the IP packet contain TCP data](https://learningnetwork.cisco.com/thread/61029) the protocol number field will have the value 6 in it, so the payload will be sent to the TCP stack, TCP would then use the port numbers to send the data to the correct application. The same is for UDP with protocol number 17.
 
> Another way to look at the IP protocol number field is, if we didn't have this field in the IP packet header, IP would only be capable of carrying one type of data, while adding this field allowed the IP to carry multiple types of data differentiated by the protocol number, the same goes for TCP/UDP using TCP/UDP ports to serve multiple applications and Ethernet using the Ethertype, and so on.

## can multiple app bind to (or listen to) the same port?

Can't. [Because You can only have one application](http://stackoverflow.com/questions/1694144/can-two-applications-listen-to-the-same-port) listening on a single port at one time. 

> the app opens a port, gets a handle to it, and the OS notifies it (via that handle) when a client connection (or a packet in UDP case) arrives.
>
> If the OS allowed two apps to open the same port, how would it know which one to notify?


]]></content>
  </entry>
  
</feed>
