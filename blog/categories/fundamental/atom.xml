<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Fundamental | Woodstock Blog]]></title>
  <link href="http://okckd.github.io/blog/categories/fundamental/atom.xml" rel="self"/>
  <link href="http://okckd.github.io/"/>
  <updated>2015-01-13T21:17:09+08:00</updated>
  <id>http://okckd.github.io/</id>
  <author>
    <name><![CDATA[Charlie Brown]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[[Fundamental] Travelling Salesman Problem]]></title>
    <link href="http://okckd.github.io/blog/2014/08/30/Travelling-salesman-problem/"/>
    <updated>2014-08-30T00:00:00+08:00</updated>
    <id>http://okckd.github.io/blog/2014/08/30/Travelling-salesman-problem</id>
    <content type="html"><![CDATA[### TSP problem

[Given a list of cities](http://en.wikipedia.org/wiki/Travelling_salesman_problem) and the distances between each pair of cities, what is the shortest possible route that visits each city exactly once and returns to the origin city? 

It is an NP-hard problem in combinatorial optimization. We will discuss 2 category of solutions: 

1. Exact algorithms
1. Heuristic and approximation algorithms

### Exact algorithms

1. __Brute force search__, which the run time is O(n!), which is impossible for 20 cities. 

1. __DP__ Held–Karp algorithm. O(n^2 x 2^n). 

1. __Branch-and-bound__ algorithm. This can process 40-60 cities. 

### Heuristic and approximation algorithms

1. __Greedy__, or Nearest Neighbour algorithm. (an improved version is called Nearest Fragment algorithm, which connect NN in groups)

1. __Minimum Spanning Tree (MST)__, build the [MST](http://en.m.wikipedia.org/wiki/Minimum_spanning_tree) using [Kruskal's algorithm](http://en.wikipedia.org/wiki/Kruskal's_algorithm) and then do a __Depth-first Tree Tour__. [link](http://www.youtube.com/watch?v=HWHZAtQl1vI) to video. 

	1. Sort all edges from small to large, then add edges into MST as long as no cycle is created. In the end, a MST is achieved. 
	
	1. Do Depth-first Tree Tour(DFTT)
	
	1. Length of DFTT is 2 x weight of MST.
	
	1. Skip some nodes that's only visited once. 

	1. We get an legitimate solution. 

### Iterative improvement

Now these are the solutions. However we can improve it by doing __2-opt Swap__. 

It means selecting 2 edges at random. If swapping results in an improvement, then keep it. Keep doing this. [link](http://www.youtube.com/watch?v=SC5CX8drAtU) to video. 
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[[Fundamental] Min-Max Algorithm]]></title>
    <link href="http://okckd.github.io/blog/2014/08/30/Min-max-algorithm/"/>
    <updated>2014-08-30T00:00:00+08:00</updated>
    <id>http://okckd.github.io/blog/2014/08/30/Min-max-algorithm</id>
    <content type="html"><![CDATA[### Definition

For every two-person, zero-sum game with finitely many strategies, there exists a value V and a mixed strategy for each player, such that

1. Given player 2's strategy, the best payoff possible for player 1 is V, and
1. Given player 1's strategy, the best payoff possible for player 2 is −V.

Equivalently, Player 1's strategy guarantees him a payoff of V regardless of Player 2's strategy. 

Put it in a simple way: MAX tries to __max the utility__, and MIN try to __min it__. 

<img class="middle" src="/assets/images/minmax-example-1.png">

### Steps

1. Have a __heuristic evaluation function__, which gives a value to non-final game states. 
1. Generate the values down to terminal states. 
1. Min-max calculate the utility, like this: 

<img class="middle" src="/assets/images/minmax-example-2.png">

### An example

Othello game:

> A player can place a new piece in a position if there exists at least one straight (horizontal, vertical, or diagonal) occupied line between the new piece and another piece of the same kind, with one or more contiguous pieces from the opponent player between them. 
>
> After placing the new piece, the pieces from the opponent player will be captured and become the pieces from the same player. 
>
> The player with the most pieces on the board wins. 

First, the __heuristic evaluation function__:

<img class="middle" src="/assets/images/minmax-example-2.png">

Now, generate terminal level utility values: 

<img class="middle" src="/assets/images/minmax-example-3.png">

Now, do min-max algorithm: 

<img class="middle" src="/assets/images/minmax-example-4.png">

### Pruning

The performance of the naïve minimax algorithm may be improved dramatically, without affecting the result, [by the use of](http://en.wikipedia.org/wiki/Minimax#Minimax_algorithm_with_alternate_moves) __alpha-beta pruning__. 

[Alpha–beta pruning](http://en.wikipedia.org/wiki/Alpha%E2%80%93beta_pruning) is a search algorithm that seeks to decrease the number of nodes that are evaluated by the minimax algorithm in its search tree. 

<img class="middle" src="/assets/images/minmax-ab-pruning.png">
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[[Fundamental] A-Star Search]]></title>
    <link href="http://okckd.github.io/blog/2014/08/30/A-start-search/"/>
    <updated>2014-08-30T00:00:00+08:00</updated>
    <id>http://okckd.github.io/blog/2014/08/30/A-start-search</id>
    <content type="html"><![CDATA[### Definition

A* is a computer algorithm that is widely used in pathfinding and graph traversal. 

It uses a knowledge-plus-heuristic cost function like this: 

> f (n) = g(n) + h(n)
>
> f (n): estimated total cost of path through n to goal
>
> g(x) = past path-cost function
>
> h(x) = future path-cost function, which is an admissible "heuristic estimate" of the distance from x to the goal

What sets A* __apart from a greedy best-first search__ is that it also takes the distance already traveled into account.

### Implementation

[Maintains a priority queue](http://en.wikipedia.org/wiki/A*_search_algorithm#Process) (lower f(x) means higher priority). At each step, node with the lowest f(x) value is removed from the queue, and neighbors are added to the queue. 

This continues until a goal node has a lower f value than any node in the queue. Goal found! 

### Relationship with Dijkstra

__[Dijkstra is a special case](http://stackoverflow.com/a/1332478) for A*__ (when the [heuristics is 0](http://en.wikipedia.org/wiki/Dijkstra%27s_algorithm#Algorithm)).

Illustration (A-star):

<img class="middle" src="/assets/images/path-find-Astar.gif">

Illustration (Dijkstra's algorithm):

<img class="middle" src="/assets/images/path-find-Dijkstras.gif">
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[[Fundamental] Recap on Java HashMap]]></title>
    <link href="http://okckd.github.io/blog/2014/05/10/Recap-java-hashmap/"/>
    <updated>2014-05-10T00:00:00+08:00</updated>
    <id>http://okckd.github.io/blog/2014/05/10/Recap-java-hashmap</id>
    <content type="html"><![CDATA[#### The HashMap

<blockquote cite="http://www.sparknotes.com/cs/searching/hashtables/section1.html">
<div>
<a href="http://www.sparknotes.com/cs/searching/hashtables/section1.html">link</a>
</div>
<p>
A hash table is made up of two parts: an array (the actual table where the data to be searched is stored) and a mapping function, known as a hash function. 
</p>
<p>
The hash function is a mapping from the input space to the integer space that defines the indices of the array. In other words, the hash function provides a way for assigning numbers to the input data such that the data can then be stored at the array index corresponding to the assigned number.
</p>
</blockquote>

For example, if I want to store <"Durant">, I pass "Durant" into the hash function, and get (let's say) number 3. So in the Hash Table, it will store table(3 -> "Durant"). 

In this way, the __searching of HashMap can almost achieve  O(1) time in best case__ (like array access). 

However,

<blockquote cite="http://stackoverflow.com/a/9214421">
<div>
<a href="http://stackoverflow.com/a/9214421">link</a>
</div>
<p>
For average case, It really is (as the wikipedia page says) O(1+n/k) where K is the hash table size. If K is large enough, then the result is effectively O(1). But suppose K is 10 and N is 100. In that case each bucket will have on average 10 entries, so the search time is definitely not O(1); it is a linear search through up to 10 entries.
</p>
</blockquote>

In practise, we will just assume search in HashMap always O(1). 

Below is a great conclusion.

<blockquote cite="http://stackoverflow.com/a/9214594">
<div>
<a href="http://stackoverflow.com/a/9214594">link</a>
</div>
<p><a href="http://en.wikipedia.org/wiki/Hash_table">Hash tables</a> are <code>O(1)</code> <strong>average and <a href="http://en.wikipedia.org/wiki/Amortized_analysis">amortized</a></strong> case complexity, however is suffers from <code>O(n)</code> <strong>worst case</strong> time complexity. [And I think this is where your confusion is]</p>

<p>Hash tables suffer from <code>O(n)</code> worst time complexity due to two reasons:</p>

<ol>
<li>If too many elements were hashed into the same key: looking inside this key may take <code>O(n)</code> time.</li>
<li>Once a hash table has passed its <a href="http://en.wikipedia.org/wiki/Load_balancing_%28computing%29">load balance</a> - it has to rehash [create a new bigger table, and re-insert each element to the table]. </li>
</ol>

<p>However, it is said to be <code>O(1)</code> average and amortized case because:</p>

<ol>
<li>It is very rare that many items will be hashed to the same key [if you chose a good hash function and you don't have too big load balance.</li>
<li>The rehash operation, which is <code>O(n)</code>, can at most happen after <code>n/2</code> ops, which are all assumed <code>O(1)</code>: Thus when you sum the average time per op, you get : <code>(n*O(1) + O(n)) / n) = O(1)</code></li>
</ol>
</blockquote>]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[[Fundamental] Java Bit Operation]]></title>
    <link href="http://okckd.github.io/blog/2014/05/10/Java-bit-operation/"/>
    <updated>2014-05-10T00:00:00+08:00</updated>
    <id>http://okckd.github.io/blog/2014/05/10/Java-bit-operation</id>
    <content type="html"><![CDATA[### Bit operators

<table border="2">
  <tr>
    <th>operator</th>
    <th>what is means</th>
  </tr>
  <tr>
    <td>~</td>
    <td>invert every bit</td>
  </tr>
  <tr>
    <td>&lt;&lt;</td>
    <td>shift left (same as *2)</td>
  </tr>
  <tr>
    <td>&gt;&gt;</td>
    <td>signed shift right</td>
  </tr>
  <tr>
    <td>&gt;&gt;&gt;</td>
    <td>unsigned shift right</td>
  </tr>
  <tr>
    <td>^</td>
    <td>XOR</td>
  </tr>
  <tr>
    <td>|</td>
    <td>OR</td>
  </tr>
</table>
<br />

Note the unsigned right shift operator ">>>" shifts a __zero into the leftmost position__, while the leftmost position after ">>" __depends on sign extension__.
]]></content>
  </entry>
  
</feed>
