<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: fundamental | Woodstock Blog]]></title>
  <link href="http://okckd.github.io/blog/categories/fundamental/atom.xml" rel="self"/>
  <link href="http://okckd.github.io/"/>
  <updated>2015-01-24T17:52:26+08:00</updated>
  <id>http://okckd.github.io/</id>
  <author>
    <name><![CDATA[Charlie Brown]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[[Fundamental] Travelling salesman problem ]]></title>
    <link href="http://okckd.github.io/blog/2014/08/30/Travelling-salesman-problem/"/>
    <updated>2014-08-30T00:00:00+08:00</updated>
    <id>http://okckd.github.io/blog/2014/08/30/Travelling-salesman-problem</id>
    <content type="html"><![CDATA[<h3>TSP problem</h3>

<p><a href="http://en.wikipedia.org/wiki/Travelling_salesman_problem">Given a list of cities</a> and the distances between each pair of cities, what is the shortest possible route that visits each city exactly once and returns to the origin city?</p>

<p>It is an NP-hard problem in combinatorial optimization. We will discuss 2 category of solutions:</p>

<ol>
<li>Exact algorithms</li>
<li>Heuristic and approximation algorithms</li>
</ol>


<h3>Exact algorithms</h3>

<ol>
<li><p><strong>Brute force search</strong>, which the run time is O(n!), which is impossible for 20 cities.</p></li>
<li><p><strong>DP</strong> Held–Karp algorithm. O(n<sup>2</sup> x 2<sup>n</sup>).</p></li>
<li><p><strong>Branch-and-bound</strong> algorithm. This can process 40-60 cities.</p></li>
</ol>


<h3>Heuristic and approximation algorithms</h3>

<ol>
<li><p><strong>Greedy</strong>, or Nearest Neighbour algorithm. (an improved version is called Nearest Fragment algorithm, which connect NN in groups)</p></li>
<li><p><strong>Minimum Spanning Tree (MST)</strong>, build the <a href="http://en.m.wikipedia.org/wiki/Minimum_spanning_tree">MST</a> using <a href="http://en.wikipedia.org/wiki/Kruskal's_algorithm">Kruskal&rsquo;s algorithm</a> and then do a <strong>Depth-first Tree Tour</strong>. <a href="http://www.youtube.com/watch?v=HWHZAtQl1vI">link</a> to video.</p>

<ol>
<li><p>Sort all edges from small to large, then add edges into MST as long as no cycle is created. In the end, a MST is achieved.</p></li>
<li><p>Do Depth-first Tree Tour(DFTT)</p></li>
<li><p>Length of DFTT is 2 x weight of MST.</p></li>
<li><p>Skip some nodes that&rsquo;s only visited once.</p></li>
<li><p>We get an legitimate solution.</p></li>
</ol>
</li>
</ol>


<h3>Iterative improvement</h3>

<p>Now these are the solutions. However we can improve it by doing <strong>2-opt Swap</strong>.</p>

<p>It means selecting 2 edges at random. If swapping results in an improvement, then keep it. Keep doing this. <a href="http://www.youtube.com/watch?v=SC5CX8drAtU">link</a> to video.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[[Fundamental] Min-Max Algorithm ]]></title>
    <link href="http://okckd.github.io/blog/2014/08/30/Min-max-algorithm/"/>
    <updated>2014-08-30T00:00:00+08:00</updated>
    <id>http://okckd.github.io/blog/2014/08/30/Min-max-algorithm</id>
    <content type="html"><![CDATA[<h3>Definition</h3>

<p>For every two-person, zero-sum game with finitely many strategies, there exists a value V and a mixed strategy for each player, such that</p>

<ol>
<li>Given player 2&rsquo;s strategy, the best payoff possible for player 1 is V, and</li>
<li>Given player 1&rsquo;s strategy, the best payoff possible for player 2 is −V.</li>
</ol>


<p>Equivalently, Player 1&rsquo;s strategy guarantees him a payoff of V regardless of Player 2&rsquo;s strategy.</p>

<p>Put it in a simple way: MAX tries to <strong>max the utility</strong>, and MIN try to <strong>min it</strong>.</p>

<p>{% img middle /assets/images/minmax-example-1.png %}</p>

<h3>Steps</h3>

<ol>
<li>Have a <strong>heuristic evaluation function</strong>, which gives a value to non-final game states.</li>
<li>Generate the values down to terminal states.</li>
<li>Min-max calculate the utility, like this:</li>
</ol>


<p>{% img middle /assets/images/minmax-example-2.png %}</p>

<h3>An example</h3>

<p>Othello game:</p>

<blockquote><p>A player can place a new piece in a position if there exists at least one straight (horizontal, vertical, or diagonal) occupied line between the new piece and another piece of the same kind, with one or more contiguous pieces from the opponent player between them.</p>

<p>After placing the new piece, the pieces from the opponent player will be captured and become the pieces from the same player.</p>

<p>The player with the most pieces on the board wins.</p></blockquote>

<p>First, the <strong>heuristic evaluation function</strong>:</p>

<p>{% img middle /assets/images/minmax-example-2.png %}</p>

<p>Now, generate terminal level utility values:</p>

<p>{% img middle /assets/images/minmax-example-3.png %}</p>

<p>Now, do min-max algorithm:</p>

<p>{% img middle /assets/images/minmax-example-4.png %}</p>

<h3>Pruning</h3>

<p>The performance of the naïve minimax algorithm may be improved dramatically, without affecting the result, <a href="http://en.wikipedia.org/wiki/Minimax#Minimax_algorithm_with_alternate_moves">by the use of</a> <strong>alpha-beta pruning</strong>.</p>

<p><a href="http://en.wikipedia.org/wiki/Alpha%E2%80%93beta_pruning">Alpha–beta pruning</a> is a search algorithm that seeks to decrease the number of nodes that are evaluated by the minimax algorithm in its search tree.</p>

<p>{% img middle /assets/images/minmax-ab-pruning.png %}</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[[Fundamental] A-Star Search ]]></title>
    <link href="http://okckd.github.io/blog/2014/08/30/A-start-search/"/>
    <updated>2014-08-30T00:00:00+08:00</updated>
    <id>http://okckd.github.io/blog/2014/08/30/A-start-search</id>
    <content type="html"><![CDATA[<h3>Definition</h3>

<p>A* is a computer algorithm that is widely used in pathfinding and graph traversal.</p>

<p>It uses a knowledge-plus-heuristic cost function like this:</p>

<blockquote><p>f (n) = g(n) + h(n)</p>

<p>f (n): estimated total cost of path through n to goal</p>

<p>g(x) = past path-cost function</p>

<p>h(x) = future path-cost function, which is an admissible &ldquo;heuristic estimate&rdquo; of the distance from x to the goal</p></blockquote>

<p>What sets A* <strong>apart from a greedy best-first search</strong> is that it also takes the distance already traveled into account.</p>

<h3>Implementation</h3>

<p><a href="http://en.wikipedia.org/wiki/A*_search_algorithm#Process">Maintains a priority queue</a> (lower f(x) means higher priority). At each step, node with the lowest f(x) value is removed from the queue, and neighbors are added to the queue.</p>

<p>This continues until a goal node has a lower f value than any node in the queue. Goal found!</p>

<h3>Relationship with Dijkstra</h3>

<p><strong><a href="http://stackoverflow.com/a/1332478">Dijkstra is a special case</a> for A*</strong> (when the <a href="http://en.wikipedia.org/wiki/Dijkstra%27s_algorithm#Algorithm">heuristics is 0</a>).</p>

<p>Illustration (A-star):</p>

<p>{% img middle /assets/images/path-find-Astar.gif %}</p>

<p>Illustration (Dijkstra&rsquo;s algorithm):</p>

<p>{% img middle /assets/images/path-find-Dijkstras.gif %}</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[[Fundamental] Recap on Java HashMap ]]></title>
    <link href="http://okckd.github.io/blog/2014/05/10/Recap-java-hashmap/"/>
    <updated>2014-05-10T00:00:00+08:00</updated>
    <id>http://okckd.github.io/blog/2014/05/10/Recap-java-hashmap</id>
    <content type="html"><![CDATA[<h4>The HashMap</h4>

<blockquote cite="http://www.sparknotes.com/cs/searching/hashtables/section1.html">
<div>
<a href="http://www.sparknotes.com/cs/searching/hashtables/section1.html">link</a>
</div>
<p>
A hash table is made up of two parts: an array (the actual table where the data to be searched is stored) and a mapping function, known as a hash function. 
</p>
<p>
The hash function is a mapping from the input space to the integer space that defines the indices of the array. In other words, the hash function provides a way for assigning numbers to the input data such that the data can then be stored at the array index corresponding to the assigned number.
</p>
</blockquote>


<p>For example, if I want to store &lt;&ldquo;Durant&rdquo;>, I pass &ldquo;Durant&rdquo; into the hash function, and get (let&rsquo;s say) number 3. So in the Hash Table, it will store table(3 &ndash;> &ldquo;Durant&rdquo;).</p>

<p>In this way, the <strong>searching of HashMap can almost achieve  O(1) time in best case</strong> (like array access).</p>

<p>However,</p>

<blockquote cite="http://stackoverflow.com/a/9214421">
<div>
<a href="http://stackoverflow.com/a/9214421">link</a>
</div>
<p>
For average case, It really is (as the wikipedia page says) O(1+n/k) where K is the hash table size. If K is large enough, then the result is effectively O(1). But suppose K is 10 and N is 100. In that case each bucket will have on average 10 entries, so the search time is definitely not O(1); it is a linear search through up to 10 entries.
</p>
</blockquote>


<p>In practise, we will just assume search in HashMap always O(1).</p>

<p>Below is a great conclusion.</p>

<blockquote cite="http://stackoverflow.com/a/9214594">
<div>
<a href="http://stackoverflow.com/a/9214594">link</a>
</div>
<p><a href="http://en.wikipedia.org/wiki/Hash_table">Hash tables</a> are <code>O(1)</code> <strong>average and <a href="http://en.wikipedia.org/wiki/Amortized_analysis">amortized</a></strong> case complexity, however is suffers from <code>O(n)</code> <strong>worst case</strong> time complexity. [And I think this is where your confusion is]</p>

<p>Hash tables suffer from <code>O(n)</code> worst time complexity due to two reasons:</p>

<ol>
<li>If too many elements were hashed into the same key: looking inside this key may take <code>O(n)</code> time.</li>
<li>Once a hash table has passed its <a href="http://en.wikipedia.org/wiki/Load_balancing_%28computing%29">load balance</a> - it has to rehash [create a new bigger table, and re-insert each element to the table]. </li>
</ol>

<p>However, it is said to be <code>O(1)</code> average and amortized case because:</p>

<ol>
<li>It is very rare that many items will be hashed to the same key [if you chose a good hash function and you don't have too big load balance.</li>
<li>The rehash operation, which is <code>O(n)</code>, can at most happen after <code>n/2</code> ops, which are all assumed <code>O(1)</code>: Thus when you sum the average time per op, you get : <code>(n*O(1) + O(n)) / n) = O(1)</code></li>
</ol>
</blockquote>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[[Fundamental] Java Bit Operation ]]></title>
    <link href="http://okckd.github.io/blog/2014/05/10/Java-bit-operation/"/>
    <updated>2014-05-10T00:00:00+08:00</updated>
    <id>http://okckd.github.io/blog/2014/05/10/Java-bit-operation</id>
    <content type="html"><![CDATA[<h3>Bit operators</h3>

<table border="2">
  <tr>
    <th>operator</th>
    <th>what is means</th>
  </tr>
  <tr>
    <td>~</td>
    <td>invert every bit</td>
  </tr>
  <tr>
    <td>&lt;&lt;</td>
    <td>shift left (same as *2)</td>
  </tr>
  <tr>
    <td>&gt;&gt;</td>
    <td>signed shift right</td>
  </tr>
  <tr>
    <td>&gt;&gt;&gt;</td>
    <td>unsigned shift right</td>
  </tr>
  <tr>
    <td>^</td>
    <td>XOR</td>
  </tr>
  <tr>
    <td>|</td>
    <td>OR</td>
  </tr>
</table>


<br />


<p>Note the unsigned right shift operator &ldquo;>>>&rdquo; shifts a <strong>zero into the leftmost position</strong>, while the leftmost position after &ldquo;>>&rdquo; <strong>depends on sign extension</strong>.</p>
]]></content>
  </entry>
  
</feed>
