
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>Shuatiblog.com</title>
  <meta name="author" content="CodeMonkey">

  
  <meta name="description" content="Stats Facebook has 1.5 billion monthly active users, 970 million daily active users as of June 2015. image from statista.com. In 2009, Facebook &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://www.shuatiblog.com/">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="/javascripts/ender.js"></script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <link href="/atom.xml" rel="alternate" title="Shuatiblog.com" type="application/atom+xml">
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href="http://fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="http://fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">

  
  <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-52495723-2']);
    _gaq.push(['_trackPageview']);

    (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
  </script>


</head>

<body   >
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  
<form action="https://www.google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="q" value="site:www.shuatiblog.com" />
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>
  
<ul class="main-navigation">
    <li><a href="/">
        <span class="blue_light">
            Shuatiblog.com
        </span>
       
    </a></li>
  <li><a href="/">Blog</a></li>
  <li><a href="/blog/archives">Archives</a></li>
  <li><a href="/about">About me</a></li>
</ul>

</nav>
  <div id="main">
    <div id="content">
      <div class="blog-index">
  
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2015/09/02/Facebook-photo-storage/">[Design] Facebook Photo Storage</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2015-09-02T00:00:00+08:00" pubdate data-updated="true"></time>
        
         | <a href="/blog/2015/09/02/Facebook-photo-storage/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><h1>Stats</h1>

<p>Facebook has 1.5 billion monthly active users, 970 million daily active users <a href="http://newsroom.fb.com/company-info/">as of June 2015</a>.</p>

<p><img class="middle" src="/assets/images/facebook-user-count.png"></p>

<p>image from <a href="http://www.statista.com/statistics/264810/number-of-monthly-active-facebook-users-worldwide/">statista.com</a>.</p>

<p>In 2009, Facebook stores 15 billion photos for the user, which grows at 220 million per week, and 550,000 per second at peak.</p>

<p>It&rsquo;s 2015 now, you might want to mulitply these numbers by 3~6.</p>

<p>I have roughly estimated the statistics of Facebook users, Facebook photos and growth rate, just to give you an idea of the size of data Facebook has got:</p>

<blockquote><p>Total user: 1.5b</p>

<p>Total photoes: 150b, which is 100 photo/user</p>

<p>Each photo got 4 different sizes, so 600b photos are stored.</p>

<p>New photo per day: 500m</p>

<p>New photo per second: 6,000</p>

<p>Peak incoming photo per second: 3m</p></blockquote>

<h1>Old architecture</h1>

<p>3 tiers design:</p>

<ol>
<li><p><strong>Upload tier</strong> receives users’ photo uploads, scales the original images and saves them on the NFS storage tier.</p></li>
<li><p><strong>Photo serving tier</strong> receives HTTP requests for photo images and serves them from the NFS storage tier.</p></li>
<li><p><strong>NFS storage tier</strong> built on top of commercial storage appliances.</p></li>
</ol>


<blockquote><p><strong><a href="https://en.wikipedia.org/wiki/Network_File_System">Network File System</a></strong> (NFS) is a distributed file system protocol originally developed by Sun Microsystems in 1984, allowing a user on a client computer to access files over a network much like local storage is accessed.</p></blockquote>

<h2>Problem</h2>

<ol>
<li><p>there is an <strong>enormous amount of metadata</strong></p>

<p> &hellip; so much that is <a href="https://code.facebook.com/posts/685565858139515/needle-in-a-haystack-efficient-storage-of-billions-of-photos/">exceeds the caching abilities of the NFS storage tier</a>, <strong> resulting in multiple I/O operations</strong> per photo upload or read request</p></li>
</ol>


<h2>Solution</h2>

<ol>
<li><p>relies heavily on CDNs to serve photos.</p></li>
<li><p>Cachr: a caching server tier caching Facebook &ldquo;profile&rdquo; images.</p></li>
<li><p>NFS file handle cache &ndash; deployed on the photo serving tier eliminates some of the NFS storage tier metadata overhead</p></li>
</ol>


<h1>Haystack Photo Infrastructure</h1>

<p>The new photo infrastructure merges the <strong>photo serving</strong> and <strong>storage tier</strong> into one physical tier. It implements <strong>a HTTP based photo server</strong> which stores photos in a generic object store called Haystack.</p>

<p>Goal: eliminate any unnecessary metadata overhead for photo read operations, so that each read I/O operation was only reading actual photo data</p>

<p>5 main functional layers:</p>

<ol>
<li><p>HTTP server</p></li>
<li><p>Photo Store</p></li>
<li><p>Haystack Object Store</p></li>
<li><p>Filesystem</p></li>
<li><p>Storage</p></li>
</ol>


<h2>Storage</h2>

<p>The commodity machine HW typically is 2x quadcore CPU + 32GB RAM + 512MB NV-RAM cache + 12TB SATA drives.</p>

<blockquote><p><a href="https://en.wikipedia.org/wiki/Non-volatile_random-access_memory">Non-volatile random-access memory</a> (NVRAM) is random-access memory that retains its information when power is turned off (non-volatile).</p>

<p>This is in contrast to dynamic random-access memory (DRAM) and static random-access memory (SRAM)</p></blockquote>

<p>So each <strong>storage blade</strong> is around 10TB. Configured as <strong>RAID-6</strong> partition.</p>

<blockquote><p><a href="http://searchstorage.techtarget.com/definition/RAID-6-redundant-array-of-independent-disks">RAID 6</a>, also known as double-parity RAID, uses two parity stripes on each disk. It allows for two disk failures within the RAID set before any data is lost.</p></blockquote>

<p>Pros:</p>

<ol>
<li>adequate redundancy</li>
<li>excellent read performance</li>
<li>low storage cost down</li>
</ol>


<p>Cons:</p>

<p><strong>The poor write performance</strong> is partially mitigated by the <strong>RAID controller NVRAM write-back cache</strong>. Since the reads are mostly random, the NVRAM cache is fully reserved for writes.</p>

<p><strong>The disk caches are disabled</strong> in order to guarantee data consistency in the event of a crash or a power loss.</p>

<h2>Filesystem</h2>

<h3>How does filesystem read pictures?</h3>

<p>Photo read requests result in <strong>read() system calls</strong> at known offsets in these files.</p>

<p>Each file in the filesystem is represented by a structure called an inode which contains a block map that maps the logical file offset to the physical block offset on the physical volume.</p>

<p>For large files, the block map can be quite large.</p>

<h3>Problem</h3>

<p><strong>Block based filesystems</strong> maintain mappings for <strong>each logical block</strong>, and for large files, this information will not typically fit into the cached inode and is stored in indirect address blocks instead, which must be traversed in order to read the data for a file.</p>

<p>There can be several layers of indirection, so a single read could result in <strong>several I/Os</strong> (if not cached).</p>

<h3>Solution</h3>

<p><strong>Extent based filesystems</strong> maintain mappings only for contiguous ranges of blocks (extents). A block map for a contiguous large file could consist of only one extent which would fit in the inode itself.</p>

<blockquote><p><a href="https://goo.gl/uQA35V">An extent</a> is a contiguous area of storage reserved for a file in a file system, represented as a range. A file can consist of zero or more extents; <strong>one file fragment requires one extent</strong>. The direct benefit is in storing each range compactly as two numbers, instead of canonically storing every block number in the range.</p>

<p>Extent-based file systems can also <strong>eliminate most of the metadata overhead of large files</strong> that would traditionally be taken up by the block allocation tree&hellip; saving on storage space is pretty slight, but&hellip; <strong>the reduction in metadata is significant and reduces exposure to file system corruption</strong> as one bad sector in the <em>block allocation tree</em> causes much greater data loss than one bad sector in stored data.</p></blockquote>

<h3>Problem of Extent-based file systems</h3>

<p>However, if the file is severely fragmented and its blocks are not contiguous on the underlying volume, its block map can grow large as well.</p>

<h3>The solution</h3>

<p>Fragmentation can be mitigated by <strong>aggressively allocating a large chunk of space</strong> whenever growing the physical file.</p>

<p>Currently, the filesystem of choice is XFS, an extent based filesystem providing efficient file preallocation.</p>

<blockquote><p><strong><a href="https://en.wikipedia.org/wiki/XFS">XFS</a></strong> is a high-performance 64-bit journaling file system created by Silicon Graphics, Inc (SGI) in 1993.</p>

<p>&hellip;was ported to the Linux kernel in 2001. As of June 2014, XFS is supported by most Linux distributions, some of which use it as the default file system.</p>

<p>XFS enables <strong>extreme scalability of I/O threads</strong>, file system bandwidth, and size of files and of the file system itself when spanning multiple physical storage devices.</p>

<p>Space allocation is performed via extents with <strong>data structures stored in B+ trees</strong>, improving the overall performance of the file system, especially when handling large files.</p>

<p><strong>Delayed allocation</strong> assists in the prevention of file system fragmentation; <strong>online defragmentation</strong> is also supported. A feature unique to XFS is the <strong>pre-allocation of I/O bandwidth</strong> at a pre-determined rate, which is suitable for many real-time applications.</p></blockquote>

<h2>Haystack</h2>

<p>Haystack is a simple <strong>log structured (append-only) object store</strong>. Many images store in one Haystack. Typically, <a href="http://jishu.zol.com.cn/17742.html">Haystack Store is 100GB size</a>.</p>

<p>A Haystack consists of two files:</p>

<ol>
<li><strong>haystack store file</strong> (containing the needles)

<ol>
<li>superblock</li>
<li>needles (1 needle is 1 image)</li>
</ol>
</li>
<li><strong>an index file</strong></li>
</ol>


<h3>1. haystack store file</h3>

<p><img class="middle" src="/assets/images/851582_1409519009260319_311676661_n.jpg"></p>

<ol>
<li><p>The first 8KB of the haystack store is occupied by the <strong>superblock</strong>.</p></li>
<li><p>following the superblock are <strong>needles</strong></p>

<p> <strong>Needles represents the stored objects</strong>. Needle consisting of a header, the data, and a footer:</p>

<p> <img class="middle" src="/assets/images/851578_319395058204993_541487263_n.jpg"></p>

<p> A needle is uniquely identified by its &lt;Offset, Key, Alternate Key, Cookie> tuple.</p>

<p> Haystack doesn’t put any restriction on the values of the keys, and there can be needles with duplicate keys.</p></li>
</ol>


<h3>2. Index File</h3>

<p><strong>Needle</strong> consisting of a header, the data, and a footer:</p>

<p><img class="middle" src="/assets/images/851582_1374324519464800_699636937_n.jpg"></p>

<p>The index file provides the minimal metadata required to locate a particular needle in the haystack store file.</p>

<p><img class="middle" src="/assets/images/851582_314454922033518_1196942525_n.jpg"></p>

<p>The index file is not critical, as it can be rebuilt from the haystack store file if required.</p>

<p>The main purpose of the index: quick loading of the needle metadata into memory without traversing the larger Haystack store file, since the index is usually less than 1% the size of the store file.</p>

<h3>Summary</h3>

<p>All needles are stored in Haystack store file, and their location information is stored in Index File.</p>

<p>What is Needle? Needles represents the stored objects (1 needle &ndash; 1 image).</p>

<h2>Haystack Operations</h2>

<ol>
<li><p><strong>write</strong></p>

<p> append new needle to haystack store file.</p>

<p> later, corresponding index records are <strong>updated async</strong>.</p>

<p> In case of failure, any partial needles are discarded, and fix index from the end of the haystack.</p>

<p> You can&rsquo;t overwrite any needle, but you can insert using same key. Later, the needle <strong>with dup keys but largest offset</strong> became the most recent one.</p></li>
<li><p><strong>read</strong></p>

<p> <strong>parameters passed in</strong>: offset, key, alt key, cookie, data size</p>

<p> if key, alt key and cookie matches, and checksum correct and needle is not marked as deleted, return.</p></li>
<li><p><strong>delete</strong></p>

<p> marks needle as deleted (set 1 bit), but index is not modified.</p>

<p> the deleted space is not reclaimed unless <strong>compact the haystack</strong></p></li>
</ol>


<h2>Photo Store Server</h2>

<p>Photo Store Server is responsible for accepting HTTP requests and translating them to the corresponding Haystack store operations.</p>

<p>In order to minimize the number of I/Os required to retrieve photos, the server keeps an <strong>in-memory index of all photo offsets</strong>.</p>

<p>At startup, <strong>the (photo) server reads the haystack index file and populates the in-memory index</strong>. The in-memory index is different from the index file in Haystack, as it stores lesser information, like this:</p>

<p><img class="middle" src="/assets/images/851584_503528913060377_1268325854_n.jpg"></p>

<ol>
<li><p><strong>Photo Store Write/Modify Operation</strong></p>

<ol>
<li>writes photos to the haystack</li>
<li>updates the in-memory index</li>
</ol>


<p> if there are duplicate images, the one stored at a larger offset is valid.</p></li>
<li><p><strong>Photo Store Read Operation</strong></p>

<p> passed in:</p>

<ol>
<li>haystack id</li>
<li>a photo key,</li>
<li>size</li>
<li>cookie</li>
</ol>


<p> The server performs a lookup in the in-memory index based on the photo key and retrieves the offset of the needle containing the requested image.</p>

<p> Since haystack delete operation doesn’t update the haystack index file record. Therefore a freshly populated in-memory index can contain stale entries for the previously deleted photos. Read such photo will fail and the in-memory index is updated to 0.</p></li>
<li><p><strong>Photo Store Delete Operation</strong></p>

<p> After calling the haystack delete operation, the in-memory index is updated to &lsquo;offset = zero&rsquo;</p></li>
<li><p><strong>Compaction</strong></p>

<p> Compaction is an online operation which reclaims the space used by the deleted and duplicate needles.</p>

<p> creates a new haystack</p></li>
<li><p><strong>HTTP Server</strong></p>

<p> evhttp server</p>

<p> multiple threads, with each serving a single HTTP request. Workload is mostly I/O bound, thus the performance of the HTTP server is not critical.</p></li>
</ol>


<h1>Summary</h1>

<p>Storing photos as needles in the haystack <strong>eliminates the metadata overhead</strong> by aggregating hundreds of thousands of images in a single haystack store file.</p>

<p>This keeps the metadata overhead very small and allows us to <strong>store each needle’s location in the store file in an in-memory index</strong>.</p>

<p>This allows retrieval of an image’s data in <strong>a minimal number of I/O operations</strong>, eliminating all unnecessary metadata overhead.</p>

<p>Ref: <a href="https://code.facebook.com/posts/685565858139515/needle-in-a-haystack-efficient-storage-of-billions-of-photos/">https://code.facebook.com/posts/685565858139515/needle-in-a-haystack-efficient-storage-of-billions-of-photos/</a></p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2015/08/30/how-google-search-works/">[Design] How Google Search Works</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2015-08-30T00:00:00+08:00" pubdate data-updated="true"></time>
        
         | <a href="/blog/2015/08/30/how-google-search-works/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><h1>Overview</h1>

<p>Launched on Sep 15th, 1997</p>

<p><strong>60 trillion individual pages. 100 million GB data</strong>.</p>

<p><strong>40,000 search per second</strong>, or 3 billion search per day.</p>

<p>As of Feb 2015, 65% market share in US.</p>

<h1>1. Crawl</h1>

<p>Google crawl from 1 page to another using <strong><a href="https://support.google.com/webmasters/answer/182072?vid=1-635765406868848825-432642872">Googlebot</a></strong>. It starts from previous urls crawled, or augmented with <strong><a href="https://en.wikipedia.org/wiki/Site_map">Sitemap data</a></strong></p>

<blockquote><p><strong>A sitemap</strong> is a list of pages of a web site accessible to crawlers or users. It can be either a document in any form used as a planning tool for Web design, or a Web page that lists the pages on a Web site, typically organized in hierarchical fashion.</p></blockquote>

<h1>2. Indexing</h1>

<p>Compile the data (key content tags, atrributes, like title tags, ALT attributes). Google don&rsquo;t process rich media or dynamic files.</p>

<h1>3. Algorithm</h1>

<p>When search, pull all relevant results from the Index.</p>

<p>Rank the result based on 200+ factors, one of which is the <strong><a href="https://en.wikipedia.org/wiki/PageRank">PageRank</a></strong> for a given page.</p>

<blockquote><p><strong>PageRank</strong> is the measure of the importance of a page based on the incoming links from other pages. In simple terms, each link to a page on your site from another site adds to your site&rsquo;s PageRank.</p>

<p>Not all links are equal: Google works hard to identify spam links. The best types of links are those that are given based on the quality of your content.</p></blockquote>

<p>To rank higher, follow <a href="https://support.google.com/webmasters/answer/35769?vid=1-635765406868848825-432642872">Webmaster Guidelines</a>.</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2015/08/30/design-class4-2/">[NineChap System Design] Class 4.2: Search Engine</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2015-08-30T00:00:00+08:00" pubdate data-updated="true"></time>
        
         | <a href="/blog/2015/08/30/design-class4-2/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content">
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2015/08/30/design-class4-1/">[NineChap System Design] Class 4.1: Crawler</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2015-08-30T00:00:00+08:00" pubdate data-updated="true"></time>
        
         | <a href="/blog/2015/08/30/design-class4-1/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><h1>Overview</h1>

<p><strong>KISS &ndash; Keep It Simple, Sweetie</strong>.</p>

<p>In Today&rsquo;s lecture:</p>

<ol>
<li>write a crawler</li>
<li>thread-saft consumer &amp; producer</li>
<li>GFS, BigTable and MapReduce</li>
<li>Top 10 keyword/anagram using MapReduce</li>
<li>Log analysis</li>
</ol>


<h1>News Aggregator App</h1>

<ol>
<li><p>Info Collection</p>

<p> crawler</p></li>
<li><p>Info retrieval: rank, search and recommend.</p>

<p> They are in fact, all related to <strong>sorting</strong>.</p></li>
</ol>


<p><img class="middle" src="/assets/images/design-class4-News-Aggregator.png"></p>

<h2>Step 1, Info collection with crawler</h2>

<h3>crawler code</h3>

<p>Python:</p>

<pre><code>import urllib2

# request
url = "www.google.com"
request = urllib2.Request(url)
response = urllib2.urlopen(request)
page = response.read()

# save the file
webFile = open('webpage.html', 'web')
webFile.write(page)
webFile.close()
</code></pre>

<h3>Network process</h3>

<p>Use of <strong>socket</strong>.</p>

<p><img class="middle" src="/assets/images/design-class4-web-socket-1.png"></p>

<p>Socket is like the cellphone in the Call Center example.</p>

<blockquote><p><strong><a href="https://en.wikipedia.org/wiki/Network_socket">socket</a></strong> is an endpoint of an inter-process communication across a computer network.</p>

<p>Today, most communication between computers is based on the Internet Protocol; therefore most network sockets are <strong>Internet sockets</strong>.</p></blockquote>

<p>What is socket? Where is it?</p>

<p><img class="middle" src="/assets/images/design-class4-web-socket-2.png"></p>

<p>It&rsquo;s in-between <strong>Application Layer</strong> (HTTP, FTP, DNS) and <strong>Transport layer</strong> (UDP, TCP).</p>

<p>Remembering that socket is like a cellphone. It is an <strong>abstraction layer</strong>, that hinds the complexity of lower layer, thus making it easier to sende data in application layer.</p>

<h3>How is client connected to Server?</h3>

<p>3-way handshake. Read <strong>[Design] TCP 3-Way Handshake</strong></p>

<h3>HTML</h3>

<p><a href="http://www.w3schools.com/js/js_htmldom.asp">DOM tree</a>:</p>

<p><img class="middle" src="/assets/images/html-dom-tree.gif"></p>

<blockquote><p><a href="http://www.w3.org/TR/DOM-Level-2-Core/introduction.html">Document Object Model</a> (DOM) is an application programming interface (API) for valid HTML and well-formed XML documents. It <strong>defines the logical structure of documents</strong> and the way a document is accessed and manipulated.</p></blockquote>

<h3>How to crawler all the news</h3>

<ol>
<li>Go to index page</li>
<li>identify all the links (regex)</li>
</ol>


<h2>Crawl more websites</h2>

<h3>Simple design</h3>

<ol>
<li>use crawlers to find out all list pages</li>
<li>send the new lists to a Scheduler</li>
<li>Scheduler will use crawlers again, to crawl pages.</li>
</ol>


<p><img class="middle" src="/assets/images/design-class4-cralwer-arch-1.png"></p>

<p>This design is bad, cuz there is crawler waste. How can we <strong>reuse</strong> these crawlers???</p>

<h3>Adv design</h3>

<p>Design crawler that can crawl <strong>both list and pages</strong> information.</p>

<blockquote><p>Look at our crawler: the text extraction logic and Regex for <em>abc.com</em> and <em>bfe.com</em> are totally different. However, they both share the same crawling techniques.</p></blockquote>

<p>So we pass in all info a crawler task needs. Like:</p>

<p><img class="middle" src="/assets/images/design-class4-cralwer-arch-2.png"></p>

<ol>
<li><p>we gave <strong>more priority to list pages than content pages</strong>. Otherwise, your content get out of date soon.</p></li>
<li><p>Type include both list/content and source info.</p></li>
<li><p>status can be done, working, or new.</p></li>
<li><p>timestamps helps us make sure each crawler runs every hour (let&rsquo;s say)</p></li>
</ol>


<p>So when schedule <strong>pick the next crawler task</strong> to run, it will choose <strong>based on Priority</strong>. However if the <strong>timestamp (availableTime) is not yet reached</strong>, the job won&rsquo;t be executed.</p>

<p>If you crawler <strong>runs until endTime</strong> and haven&rsquo;t finish, force finish it. We should also add <strong>task created time</strong> to the info.</p>

<h3>How to identify similar news?</h3>

<p>Calculate the similarity between pages. More on this subject later.</p>

<h2>How to design Scheduler?</h2>

<p><img class="middle" src="/assets/images/design-class4-cralwer-arch-3.png"></p>

<h3>Solution with Sleep</h3>

<p>Define variables:</p>

<pre><code>taskTable&lt;table&gt; - store task lists
pageTable&lt;page&gt; - store page contents

task.url
task.state = new/working/done
task.type = list/page
</code></pre>

<p>code:</p>

<pre><code>while (true) {
    // get 1 task. If can't get, wait
    taskTable.lock();               // IMPORTANT
    newTask = taskTable.findOne(state == 'new')

    if (!newTask) {
        taskTable.unlock();         // IMPORTANT
        sleep(1000);                // IMPORTANT
        continue;
    }

    newTask.state = "working";
    taskTable.unlock();

    // execute the task, and insert to
    // either taskTable or pageTable
    newPage = Crawl(newTask.url);

    if (newTask.state === 'list') {
        // insert all urls to taskTable
        taskTable.lock();
        foreach (url in newPage) {
            taskTable.add(new task(url));
        }

        // mark the task as "done"
        newTask.state = "done";     // IMPORTANT
        taskTable.unlock();
    } else {
        // insert page content to pageTable
        pageTable.lock();
        pageTable.add(newPage.content());
        pageTable.unlock();

        // mark the task as "done"
        taskTable.lock();
        newTask.state = "done";     // IMPORTANT
        taskTable.unlock();
    }
}
</code></pre>

<h3>Solution with Conditional Variable</h3>

<p>What is Conditional Variable:</p>

<blockquote><p><a href="https://goo.gl/xOFXrY">A condition variable</a> is basically <strong>a container of threads that are waiting on a certain condition</strong>.</p>

<p>Monitors provide a mechanism for threads to temporarily give up exclusive access in order to wait for some condition to be met, before regaining exclusive access and resuming their task.</p></blockquote>

<p><img class="middle" src="/assets/images/design-class4-condition-variable.png"></p>

<p>Look at last 3 lines of code. <strong>Before going to sleep, CV have to release the lock</strong>, so that other threads can access the taskTable.</p>

<p>Then CV goes to sleep. <strong>Right after CV has been waken up</strong>, it has to lock the mutex again.</p>

<p>Solution w/ cv:</p>

<pre><code>while (true) {
    // get 1 task. If can't get, wait
    taskTable.lock();
    newTask = taskTable.findOne(state == 'new')

    if (!newTask) {
        taskTable.unlock();
        Cond_Wait(cond, taskTable);  // Modified
        continue;
    }

    newTask.state = "working";
    taskTable.unlock();

    // execute the task, and insert to
    // either taskTable or pageTable
    newPage = Crawl(newTask.url);

    if (newTask.state === 'list') {
        // insert all urls to taskTable
        taskTable.lock();
        foreach (url in newPage) {
            taskTable.add(new task(url));
            Cond_Signal(cond);       // Modified
        }

        // mark the task as "done"
        newTask.state = "done";
        taskTable.unlock();
    } else {
        // insert page content to pageTable
        pageTable.lock();
        pageTable.add(newPage.content());
        pageTable.unlock();

        // mark the task as "done"
        taskTable.lock();
        newTask.state = "done";
        taskTable.unlock();
    }
}
</code></pre>

<p>Why Good: no need to busy-spin (example above have to always wait 1 second). So this solution is better.</p>

<h3>Solution with Semaphore</h3>

<p>This is better than Condition Variable, cuz it&rsquo;s easier to implement. And Semaphore not only locks thread, it also <strong>can lock process</strong>.</p>

<p>CV locks on a certain condition. But Semaphore locks the numbers (of task, or resources etc).</p>

<p>Semaphore implementation (fairly difficult, read for interest):</p>

<pre><code>Wait(semaphore) {
    Lockf(semaphore);
    semaphore.value--;
    if (semaphore.value &lt; 0) {
        semaphore.processWaitList.Add(this.process);
        Release(semaphore);
        Block(this.process);
    } else {
        Release(semaphore);
    }
}

Signal(semaphore) {
    Lock(semaphore);
    semaphore.value++;
    if (semaphore.value &lt;= 0) {
        process = semaphore.processWaitList.pop();
        Wakeup(process);
    }
    Release(semaphore);
}
</code></pre>

<p>Note that in Java and C++, Wait() == acquire() and Signal() == release(). Read more <a href="http://tutorials.jenkov.com/java-util-concurrent/semaphore.html">Jenkov&rsquo;s post</a>.</p>

<p>code w/ semaphore:</p>

<pre><code>while (true) {
    // get 1 task. If can't get, wait
    Wait(numberOfNewTask);           // Modified

    taskTable.lock();
    newTask = taskTable.findOne(state == 'new')
    newTask.state = "working";
    taskTable.unlock();

    // execute the task, and insert to
    // either taskTable or pageTable
    newPage = Crawl(newTask.url);

    if (newTask.state === 'list') {
        // insert all urls to taskTable
        taskTable.lock();
        foreach (url in newPage) {
            taskTable.add(new task(url));
            Signal(numberOfNewTask); // Modified
        }

        // mark the task as "done"
        newTask.state = "done";
        taskTable.unlock();
    } else {
        // insert page content to pageTable
        pageTable.lock();
        pageTable.add(newPage.content());
        pageTable.unlock();

        // mark the task as "done"
        taskTable.lock();
        newTask.state = "done";
        taskTable.unlock();
    }
}
</code></pre>

<p><strong>What happens in Line 3 &lsquo;Wait(numberOfNewTask)&rsquo;</strong>? Well, the programs checks on the numberOfNewTask (counter) variable, and:</p>

<ol>
<li>If there is 1 or more tasks, just proceed.</li>
<li>If no tasks available, block itself and wait there. (Later someone will wake it up and it will resume).</li>
</ol>


<h3>Design an consumer-producer</h3>

<p>Stay tuned for future post.</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2015/08/28/design-class3-2/">[NineChap System Design] Class 3.2: Web Service</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2015-08-28T00:00:00+08:00" pubdate data-updated="true"></time>
        
         | <a href="/blog/2015/08/28/design-class3-2/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><h1>Question 4</h1>

<p><strong>fix MP3 problem</strong></p>

<p>The process of fetching a MP3 (from CDN):</p>

<p><img class="middle" src="/assets/images/design-class3-client-request-mp3.png"></p>

<ol>
<li>aquire MP3 link, and send request</li>
<li>send request to CDN</li>
<li>CDN receive request, find MP3</li>
<li>response to client</li>
<li>play the music</li>
</ol>


<p><img class="middle" src="/assets/images/design-class3-client-request-mp3-errors.png"></p>

<p>Question: in step 2, there&rsquo;s more Network error, but in step 4, there&rsquo;s no Network error, but Timeout. Why?</p>

<h2>Fix step 2, Network error</h2>

<p>Problem is: MP3 url invalid. It actually comes from a failed CDN sever.</p>

<p>Solution: fix the server.</p>

<h2>Fix step 3, CDN can&rsquo;t find MP3</h2>

<p>Problem associated with <strong>Anti-Leech</strong>.</p>

<blockquote><p><strong><a href="https://en.wikipedia.org/wiki/Leech_(computing">a leech</a>)</strong> is one who benefits, usually deliberately, from others&#8217; information or effort but does not offer anything in return.</p>

<p>Example: Wi-Fi leeches, Direct linking (or hot-linking) and In most P2P-networks, leeching is whose who download too much.</p>

<p><strong><a href="https://answers.yahoo.com/question/index?qid=1006042926419">Anti-Leech</a></strong> specializes in protecting file downloads and stopping bandwidth leeching.</p></blockquote>

<p>See that some P2P and leeching software will steal your url links, so the MP3 url expiration time is 5 minutes.</p>

<p>So when CDN server&rsquo;s clock and web server&rsquo;s clock are not synchronized well, MP3 url can expire.</p>

<p>Solution: every 10 minutes sync CDN clock with web server clock.</p>

<h2>Fix step 4, Timeout error</h2>

<p>Some MP3 are relatively large. Thus timeout.</p>

<blockquote><p>MP3 performs better at higher bps, and aac(Advanced Audio Coding) works better at lower bps.</p></blockquote>

<p>Solution:</p>

<ol>
<li><p>compress MP3 to 48bps, or use aac format. So, play lower-rate music first, then switch automatically.</p></li>
<li><p>pre-load a music while previous is playing.</p></li>
<li><p>optimize CDN</p></li>
</ol>


<blockquote><p><strong><a href="https://en.wikipedia.org/wiki/Content_delivery_network">CDN</a></strong> content delivery network is a large <strong>distributed system of servers</strong> deployed in <strong>multiple data centers</strong> across the Internet.</p>

<p>The goal of a CDN is to serve content to end-users with high availability and high performance.</p></blockquote>

<p><img class="middle" src="/assets/images/design-class3-CDN.png"></p>

<p>Which CDN should client choose?</p>

<blockquote><p>Not DNS, but web server calculates which to choose. It can be calculated using IP distance, or ISP provider, but not accurate.</p>

<p>We can also use local desktop apps (in different locations) to ping CDN servers. This may violate user privacy, though.</p></blockquote>

<h2>Fix step 5, Fail to play</h2>

<p>Problem: some files got wrong decoding.</p>

<h2>Fix step 6, unkown error</h2>

<p>Problem: some users close the page while MP3 loading.</p>

<h1>Question 5</h1>

<p><strong>fix player problem</strong></p>

<p>Problem: iOS device can never play Flash.</p>

<p>Solution: develop HTML5 player.</p>

<h2>5.2 how to evaluate that you solved the problem</h2>

<ol>
<li><p>user complains</p></li>
<li><p><strong>important</strong>: daily retention rate!</p></li>
</ol>


<p>We can&rsquo;t use daily active user, cuz it depends on marketing, competitors, and infrastructure changes.</p>

<p><strong>One day retention rate</strong>:</p>

<p><img class="middle" src="/assets/images/design-class3-user-retention.png"></p>

<blockquote><p>Today’s visitor = {U1, U3, U7, U9, U10}</p>

<p>Tomorrow&rsquo;s visitor = {U2, U3, U9,}</p>

<p>Today’s one day retention rate = 2/5</p></blockquote>

<h1>Question 6 秒杀</h1>

<h2>Design</h2>

<p>Queue A and Queue B</p>

<p><img class="middle" src="/assets/images/design-class3-miao-sha.png"></p>

<h3>Queue A</h3>

<p>Many queues, each one locates on a individual web server or reverse proxy. It is mainly used to accept large amount of requests coming from the clients.</p>

<p>Each machine may takes 10,000 or more requests per second.</p>

<p>Queue A will redirect most requests to a static page (cached).</p>

<h3>Queue B</h3>

<p>Queue B is a single machine, to aviod distributed problems. It takes in small amount of requests and decides results (eg. redirect to payment page).</p>

<blockquote><p>Now, why do we need 2 queues, not 1?</p>

<p>Think about a hospital. Queue A is the hospital lobby and security guard, and Queue B is the queue of patience.</p></blockquote>

<h2>How to reduce traffic</h2>

<ol>
<li>no image</li>
<li>cache more static pages</li>
<li>reverse proxy: batch sending the requests</li>
</ol>


<p>Also, can use front-end javascript to prevent clicking. There are method to bypass, so we need to check IP or do some filtering.</p>

<h2>How to keep it simple?</h2>

<ol>
<li>no DB: basic logic. But rmb to use a log file</li>
<li>no lock</li>
</ol>


<h2>How to improve stability</h2>

<ol>
<li>use new server to do <strong>Miao Sha</strong>, in case of crash</li>
<li>asyc prcessing everything! Don&rsquo;t let other people wait, in case of crash.</li>
</ol>


<h3>How to defend hackers</h3>

<ol>
<li>IP address (to defent auto softwares), but it&rsquo;s easy for hackers to fake IP address</li>
<li>CAPTCHA</li>
</ol>


<blockquote><p><strong><a href="https://en.wikipedia.org/wiki/CAPTCHA">CAPTCHA</a></strong> (an acronym for &ldquo;Completely Automated Public Turing test to tell Computers and Humans Apart&rdquo;) is a type of challenge-response test used in computing to determine whether or not the user is human.</p></blockquote>

<h2>follow-up</h2>

<p>How to design 12306 (support several million QPS)</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2015/08/28/design-class3-1/">[NineChap System Design] Class 3.1: Web Service</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2015-08-28T00:00:00+08:00" pubdate data-updated="true"></time>
        
         | <a href="/blog/2015/08/28/design-class3-1/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><h1>Overview</h1>

<p>Today we&rsquo;ll look at 6 examples of problems associated with Web Service:</p>

<ol>
<li>how the internet works</li>
<li>DNS</li>
<li>Web server</li>
<li>Music Player</li>
<li>MP3 file</li>
<li>秒杀</li>
</ol>


<h1>Question 0</h1>

<p><strong>how to solve raido-play failures</strong></p>

<pre><code>&gt; Failure rate  = % user who can't listen to music properly

&gt; = # user who fail to plya one song / # total users
</code></pre>

<p>Misson: reduce failure rate.</p>

<h2>How does server identify a user?</h2>

<p><img class="middle" src="/assets/images/design-class3-http-request-overview.png"></p>

<blockquote><p>If a server uses <strong>Cookie</strong> to identify unique users, the result might be > real users.</p>

<p>However, if server uses <strong>IP address</strong>, the result might be &lt; real users.</p></blockquote>

<h2>How to collect data for failure rate</h2>

<h3>Version 1</h3>

<p>Log:</p>

<ol>
<li>user send a log to server when it visits</li>
<li>user send another log after it plays a song</li>
<li>we can identify users who failed to play a song</li>
</ol>


<p><img class="middle" src="/assets/images/design-class3-server-failure-rate-1.png"></p>

<blockquote><p>In fact, everything should be logged, including play, pause, switch song, refresh etc.</p></blockquote>

<h3>Version 2</h3>

<p>User login are, in fact, <strong>automatically logged</strong> when user visits. Thus user ONLY have to send log <strong>after it plays music</strong>.</p>

<h2>Summary</h2>

<ol>
<li>define failure rate</li>
<li>user cookie to identify user</li>
<li>use log to collect failure data</li>
<li>analysis pattern of failure againt date/time</li>
</ol>


<h1>Question 1</h1>

<p><strong>the process of playing music</strong></p>

<p><img class="middle" src="/assets/images/design-class3-web-browser-17-steps.png"></p>

<ol>
<li>Prepare</li>
<li>Send DNS request</li>
<li>Prepare DNS reply</li>
<li>Send DNS reply</li>
<li><p>Process DNS reply</p>

<p> &ndash;</p></li>
<li><p>Send webpage request</p></li>
<li>Prepare webpage reply</li>
<li>Send webpage reply</li>
<li><p>Process webpage</p>

<p> &ndash;</p></li>
<li><p>Request music player</p></li>
<li>Prepare music player</li>
<li>Send music player</li>
<li><p>Process music player</p>

<p>&ndash;</p></li>
<li><p>Request MP3</p></li>
<li>Prepare MP3</li>
<li>Send MP3</li>
<li>Play MP3</li>
</ol>


<p>What is process Music Play?</p>

<blockquote><p>Local browser will do rendering, flash decoding etc. If any point of this 17 steps went wrong, the music-play fails.</p></blockquote>

<p>Is there a system/browser default Music Play?</p>

<blockquote><p>HTML player is, but flash player is not. So the flash module have to be requested every time.</p></blockquote>

<h2>Real data: failure rate 20%</h2>

<p>In practise, the real failure rate is 20%. Which is:</p>

<ol>
<li>8% DNS</li>
<li>5% Web</li>
<li>5% MP3</li>
<li>2% Player</li>
</ol>


<h1>Question 2</h1>

<p><strong>fix DNS problem</strong></p>

<p>First of all, how to find out DNS failures? There are 2 ways. First way, help desk do it. Second way is to use the Desktop app to help detect the host address.</p>

<h2>Step 1. HOSTs hijack</h2>

<p>Some users&#8217; host file can modified by competitors.</p>

<ol>
<li>ping the website url</li>
<li>modify host file manually or by desktop app</li>
</ol>


<h2>Step 2. ISP</h2>

<p>Each ISP have different DNS service. Eg. CSTNET fails to update the latest DNS, after a server change.</p>

<p>After this step, DNS failure rate fall from 8% to 1%. Why still 1%? Some companies bans music play in company web.</p>

<h1>Question 3</h1>

<p><strong>fix the web problem</strong></p>

<p>Highest failure rate:</p>

<ol>
<li>3pm office hour</li>
<li>9pm highest bandwidth nation-wide</li>
</ol>


<p><img class="middle" src="/assets/images/design-class3-web-failure-graph.png"></p>

<h2>Solution 1, reverse proxy</h2>

<p>Reverse proxy w/ more servers. Reverse proxy acts like a load balancer.</p>

<p><img class="middle" src="/assets/images/design-class3-reverse-proxly.png"></p>

<blockquote><p><strong><a href="https://en.wikipedia.org/wiki/Reverse_proxy">Reverse proxy</a></strong> is a type of proxy server that retrieves resources on behalf of a client from one or more servers. These resources are then returned to the client as though they originated from the proxy server itself.</p></blockquote>

<p><a href="https://www.nginx.com/resources/glossary/reverse-proxy-server/">Common uses for a reverse proxy server</a> include:</p>

<blockquote><ol>
<li><p>Load balancing</p>

<p>act as a “traffic cop,” sitting in front of your back-end servers and client requests. Try to <strong>maximizes speed and capacity utilization</strong> while ensuring <strong>no one server is overloaded</strong>.</p>

<p>If a server goes down, the load balancer redirects traffic to the remaining online servers.</p></li>
<li><p>Web acceleration</p>

<p> can compress inbound and outbound data, as well as <strong>cache commonly requested content</strong></p>

<p> also perform additional tasks such as SSL encryption to take <strong>load off of your web servers</strong></p></li>
<li><p>Security and anonymity</p>

<p> By intercepting requests headed for your back-end servers, a reverse proxy server protects their identities and acts as an additional defense against security attacks.</p></li>
</ol>
</blockquote>

<h2>Solution 2, reduce size of web page</h2>

<ol>
<li>simplify javascript files</li>
<li>compress images (lower dpi)</li>
<li>merge large images to 1 image (less requests)</li>
<li>lazy loading (Pinterest uses it a lot)</li>
</ol>


<h2>Solution 3, more cacheable pages</h2>

<p> <strong>Change dynamic webpages to static pages</strong>. The advantage of this is:</p>

<ol>
<li>more search engine friendly.</li>
<li>more cache friendly.</li>
</ol>


<h3>Summary on caching</h3>

<p>Caching can happen at place Number 1, 2 and 3:</p>

<p><img class="middle" src="/assets/images/design-class3-web-hosting-4-layers.png"></p>

<p>AT Number 4, we can add <strong>more servers</strong>. Number 3, <strong>reverse proxy</strong>. Number 2 is <strong>caching within the ISP network</strong>, which avoids requesting info again from backend. Number 1 is <strong>front-end browser cache</strong>.</p>

<p>After this step, Web failure rate fall from 7% to 4%. Why still 4%? Well, these failure is mainly from the junk users created by marketing.</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2015/08/26/design-class2-2/">[NineChap System Design] Class 2.2: Database</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2015-08-26T00:00:00+08:00" pubdate data-updated="true"></time>
        
         | <a href="/blog/2015/08/26/design-class2-2/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><h1>Question 5</h1>

<p>Continue from last post, now let&rsquo;s <strong>support VIP services</strong>.</p>

<p>User could buy VIP services using his acccount balance.</p>

<pre><code>class ProService {
    int userId;
    double money;
    long endTime;

    public addMoney(){}
    public buyPro(){}
}
</code></pre>

<h2>Q5.1: System crash when purchasing VIP</h2>

<p>Solution: <strong>transaction with log</strong></p>

<pre><code>WriteLOG
Transaction_1123: BEGIN
money=20; endTime=16_07_2016
</code></pre>

<p>If system crash happens here, system will read the log, recover and roll back all original data. Try not to complete the transaction &ndash; just fail it.</p>

<pre><code>WriteLOG
Transaction_1123: BEGIN
money=20; endTime=16_07_2016
WriteLOG
Transaction_1123: END
money=10; endTime=16_08_2016
</code></pre>

<blockquote><p>What happens if system crash during writing the log? or during the rollback?</p></blockquote>

<h2>Q5.2: dataset contains bad data</h2>

<ol>
<li>one user id have 2 corresponding pro-services information.</li>
<li>Shallow user: a pro-services info does not have corresponding user.</li>
</ol>


<p>Solution: have a checker class.</p>

<h2>Q5.3: simutaneous purchase by 2 users</h2>

<p>Solution: lock.</p>

<ol>
<li>first process lock money &amp; endTime.</li>
<li>Read money = 20</li>
<li>another process try to lock, but end up waiting (sleeping).</li>
<li>first process do the job, and release the lock.</li>
<li>another process wakes up.</li>
</ol>


<blockquote><p>lock have time-out settings. It can be applied in distributed system as well.</p></blockquote>

<p>Question: does lock make your execution slow?</p>

<ol>
<li><p>If another process is sleeping, CPU will be fully consumed by other process. So it won&rsquo;t impact.</p></li>
<li><p>You can do some async processing, too.</p></li>
<li><p>When you lock, try to lock only a small piece of code, not the entire method. In DB, lock only a row, not a table.</p></li>
<li><p>Java <a href="https://en.wikipedia.org/wiki/Compare-and-swap">CAS</a> (Compare and swap )</p></li>
</ol>


<h2>Q5.4: Server crash</h2>

<p>Solution: duplication.</p>

<ol>
<li><p>How many copies?</p>

<p> Google did 3. Normally 2 in same data center, and 1 in another location.</p>

<p> Backup data normally is on another machine. But there&rsquo;s also <a href="https://en.wikipedia.org/wiki/RAID">RAID</a> (redundant array of independent disks) which:</p>

<blockquote><p>combines multiple physical disk drive components into a single logical unit for the purposes of <strong>data redundancy, performance improvement</strong>, or both.</p></blockquote></li>
<li><p>When does the copy happen?</p>

<p> Option 1 is <strong>doing everyday nightly</strong>. This is called a &lsquo;check point&rsquo;.</p>

<p> Option 2 is use another server to support <strong>Shadow Redundancy</strong>. All data from Machine 0 will be copied to Machine 1 WHILE it happens. The result is, Machine 1 is identical to Machine 0. If Machine 0 crashes, Machine 1 may be behind less than 1 second.</p>

<p> The way to duplicate is either re-play all the actions, or to read Machine 0&rsquo;s log and apply the new data.</p></li>
<li><p>How to copy?</p>

<p> User send data to 1 server, and from that server, pipeline. This ensures good usage of server bandwith, and serial transfer of data ensures low latency (several ms).</p>

<p> It&rsquo;s also possible to do tree-like transfer, but the above method is preferred cuz all machine consume same bandwidth.</p></li>
<li><p>What is log?</p>

<p> It is actually &lsquo;checkpoint&rsquo; + log. It allows you to rollback.</p></li>
</ol>


<p>Data redundancy &ndash; Summary:</p>

<p><img class="middle" src="/assets/images/design-class2-data-redundancy-1.png"></p>

<h2>Final note: Data inconsistency</h2>

<p>Main sources of inconsistency comes from:</p>

<ol>
<li>network fault</li>
<li>disk error</li>
</ol>


<p>The disk eror is solved by <strong>checksum</strong> (compare during disk writing).</p>

<h1>Summary</h1>

<p><strong><a href="https://en.wikipedia.org/wiki/ACID">ACID</a> (Atomicity, Consistency, Isolation, Durability)</strong>  is a set of properties that guarantee that database transactions are processed reliably.</p>

<ol>
<li><p><strong>Atomicity: all or nothing</strong></p>

<p> Q5.1: System crash when purchasing VIP</p></li>
<li><p><strong>Consistency</strong>: validate according to defined rules</p>

<p> Q5.2: dataset contains bad data</p></li>
<li><p><strong>Isolation</strong>: independency between transactions <strong>(lock)</strong></p>

<p> Q5.3: simutaneous purchase by 2 users</p></li>
<li><p><strong>Durability</strong>: stored permanently</p>

<p> Q5.4: Server crash</p></li>
</ol>


<p><img class="middle" src="/assets/images/design-class2-summary.png"></p>

<p>Additional Questions:</p>

<ol>
<li>design a user system (Netflix 2015)</li>
</ol>


<p>Hint: table design, register, login/out, password check, find password.</p>

<ol>
<li>Design payment system (Yelp, BigCommerce 2015)</li>
</ol>


<p>Hint: the question does not ask about table/ds design itself, but rather the problems associated with payment. Read about ACID principle.</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2015/08/26/design-class2-1/">[NineChap System Design] Class 2.1: Database</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2015-08-26T00:00:00+08:00" pubdate data-updated="true"></time>
        
         | <a href="/blog/2015/08/26/design-class2-1/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><h1>Overview</h1>

<p>This class covers database design:</p>

<ol>
<li>design data with class and inheritance</li>
<li>design a user system (Netflix 2015)</li>
<li>design a payment system (Yelp, BigCommerce 2015)</li>
</ol>


<h1>Question 1</h1>

<p><strong>design account (login/out) system</strong> for our radio app.</p>

<h2>Step one, scenario</h2>

<ol>
<li>register, update, remove account</li>
<li>login/out</li>
<li>user balance, VIP services</li>
</ol>


<h2>Step Two, necessary</h2>

<ol>
<li><p>Ask</p>

<ol>
<li>total user: 100 million</li>
<li>daily user: 1 million</li>
</ol>
</li>
<li><p>predict</p>

<ol>
<li>daily active user in 3 month: 10 million</li>
<li>register percentage: 1%</li>
<li>daily new register: 100 thousand</li>
</ol>
</li>
<li><p>more predict</p>

<ol>
<li>login percentage: 15%</li>
<li>average login frequency: 1.2 (ppl may input wrong password 20% of time)</li>
<li>daily login attempts: 10 million * 15% * 1.2 = 1.8 million</li>
<li>average login frequency: 1.8 million / 24hr = 21 login/sec</li>
<li>normal login frequency: 21 * 2 = 42 login/sec</li>
<li>peak login frequency: 42 * 3 = 126 login/sec</li>
</ol>
</li>
</ol>


<h2>Step Three, Application</h2>

<p><img class="middle" src="/assets/images/design-class2-app-design.png"></p>

<h2>Step Four, Kilobit</h2>

<p>Data &ndash; User table should contain name and password. What else?</p>

<pre><code>class User {
    int userId; (primary key)
    String name;
    String password;
}
</code></pre>

<p>Data &ndash; User Table</p>

<pre><code>class UserTable {
    list&lt;User&gt; table;

    public insert(){}
    public delete(User){}
    public update(User){}
    public User select(){}
}
</code></pre>

<blockquote><p><strong><a href="https://en.wikipedia.org/wiki/Create,_read,_update_and_delete">CRUD</a></strong>, (Sometimes called SCRUD with an &ldquo;S&rdquo; for Search) are the four basic functions of persistent storage.</p></blockquote>

<h1>Question 2</h1>

<p><strong>verification and forbidden accounts</strong></p>

<p>We have to know the concept of <strong>Account State Lifecycle Graph</strong>:</p>

<p><img class="middle" src="/assets/images/design-class2-account-life-cycle.png"></p>

<ol>
<li><p>ban: fake user, advertising users&hellip; bannned by the management</p></li>
<li><p>inactive: user choose to suspend his own account, voluntarily.</p></li>
<li><p>delete account: normally we won&rsquo;t remove all related data (just make userId as &ldquo;deleted&rdquo;). Otherwise a lot of data can be violated. All your chatting history <strong>actually remains</strong>.</p></li>
</ol>


<h2>redesign User Table</h2>

<p>Old User table:</p>

<pre><code>class User {
    int userId; (primary key)
    String name;
    String password;
}
</code></pre>

<p>Modified User table:</p>

<pre><code>class User {
    int userId;
    char name[10];
    char hiddenPassword[10];
    int state;
}
</code></pre>

<ol>
<li><p>We added state, to support Account life cycle.</p></li>
<li><p>We changed username to fixed size, for better performance on searching and storing. Can prevent certain attacks, too.</p></li>
<li><p>save encrypted password.</p></li>
</ol>


<h1>Question 3</h1>

<p><strong>design login/out process</strong></p>

<ol>
<li>User account auto logged out after a certain period of time.</li>
<li>multiple account logged in at same time.</li>
</ol>


<p><img class="middle" src="/assets/images/design-class2-session-life-cycle.png"></p>

<h2>Session</h2>

<p><strong>Session is a conversation</strong> between user and server.</p>

<ol>
<li>User can have >1 session, if he log in from different devices.</li>
<li>Session must be verified, thus we have to keep <strong>sessionId</strong>.</li>
</ol>


<p>Session status: &ldquo;iPad online&rdquo;, &ldquo;PC online&rdquo;&hellip;</p>

<p>Modify User table:</p>

<pre><code>class User {
    int userId;
    char name[10];
    char hiddenPassword[10];
    int state;
    List&lt;session&gt; sessionList;
}
</code></pre>

<p>Important in Session table:</p>

<ol>
<li>device ID</li>
<li><p>time-out period</p>

<p> class Session {
     private sessionId;
     int userId;</p>

<pre><code> int deviceCode;
 long timeOut;
</code></pre>

<p> }</p></li>
</ol>


<p>User table would include a <strong>session list</strong>.</p>

<h2>further improvement: session</h2>

<ol>
<li>we update sessionList very frequently.</li>
<li>size of sessionList is dynamic.</li>
</ol>


<p>Solution: seperate the table.</p>

<p><img class="middle" src="/assets/images/design-class2-user-session-table.png"></p>

<p>Question: When to clean up the session data (considering huge amount of data and frequent calculation)?</p>

<blockquote><p>Answer: every end of day. Or store sessions in-memory, so it lose all the data when machine restarts (it is used in Gaming platforms). Or we can clean up one user&rsquo;s session list whenever the user did a new log-in.</p>

<p>We do not remove session whenever it expires. It&rsquo;s too much calculation.</p></blockquote>

<h2>further improvement: inheritance</h2>

<p>Apply inheritance to UserTable and SessionTable:</p>

<pre><code>class Table {
    list&lt;Row*&gt; table;

    public insert(){}
    public delete(){}
    public update(){}
    public User select(){}
}

class UserTable extends Table {
}

class SessionTable extends Table {
}
</code></pre>

<p>As for the Row class:</p>

<pre><code>class Row {
    List&lt;Attributes&gt; row;
}

class User extends Row {
}

class Session extends Row {
}
</code></pre>

<h1>Question 4</h1>

<p><strong>design search algorithm</strong></p>

<ol>
<li>find my userId</li>
<li>find my userId range</li>
</ol>


<p>Solution 1: add <strong>HashMap</strong> in the table. Can do search in O(1), but can&rsquo;t find range.</p>

<p>Solution 2: <strong>BST data structure</strong>. Can do search range and search in O(log2 n) time.</p>

<h2>Best solution: B+ tree</h2>

<p><strong><a href="https://en.wikipedia.org/wiki/B%2B_tree">B+ tree</a></strong> &ndash; everything in O(logb n) which is <strong>close to constant time</strong>.</p>

<p>Plus, B+ tree is hard disk friendly. Read more on a future post.</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2015/08/24/three-property-object/">[Java OOP] Three Properties of Class/Object</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2015-08-24T00:00:00+08:00" pubdate data-updated="true"></time>
        
         | <a href="/blog/2015/08/24/three-property-object/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><h1>Objects</h1>

<p>Much of the power and flexibility of modern software analysis and design derives from its use of objects.</p>

<h1>Classes</h1>

<p>Classes create an abstract representation of the world, letting you discard unnecessary details.</p>

<h1>The 3 properties</h1>

<h2>Class</h2>

<ol>
<li><p>properties</p></li>
<li><p><strong>behavior</strong></p></li>
<li><p>relationships to other objects</p></li>
</ol>


<h2>Object</h2>

<ol>
<li><p>state</p></li>
<li><p><strong>behavior</strong></p></li>
<li><p>identity</p></li>
</ol>


<p>Ref: <a href="http://javadevwannabe.blogspot.sg/2012/02/state-behavior-and-identity.html?m=1">http://javadevwannabe.blogspot.sg/2012/02/state-behavior-and-identity.html?m=1</a></p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2015/08/23/design-class1-3/">[NineChap System Design] Class 1.3: Improvement</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2015-08-23T00:00:00+08:00" pubdate data-updated="true"></time>
        
         | <a href="/blog/2015/08/23/design-class1-3/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><h1>From Level 0 to Level 1</h1>

<p>Refer to the previous question. How can we improve???</p>

<ol>
<li>performance</li>
<li>scalability</li>
<li>robustness</li>
</ol>


<h2>performance</h2>

<p>A better algo: Inverted Index</p>

<p><img class="middle" src="/assets/images/design-class1-reco-2.png"></p>

<p>Avg performance increase to ~ 20ns (with some optimization of MapReduce procedure, discuss later).</p>

<p><strong>Max QPS increase to 50</strong>.</p>

<h2>scalability</h2>

<p>Use a <strong>dispatcher</strong> to re-direct the requests to multiple machines.</p>

<p><img class="middle" src="/assets/images/design-class1-reco-3.png"></p>

<h3>How many machines do we need then?</h3>

<p>Well we need 500 QPS. The algo above achieves ~ 50 QPS. <strong>Should we need 10 machines</strong>?</p>

<p>The answer is NO. A machine with 8 (or 16) core CPU could be able to handle.</p>

<p>We can also have a <strong>hot-standby</strong>, to be safe.</p>

<blockquote><p>hot standby is used as a failover mechanism to provide reliability in system configurations.</p>

<p>When a key component fails, the hot spare is switched into operation.</p></blockquote>

<h2>robustness</h2>

<p>Tips about system design for senior engineers:</p>

<blockquote><p><strong>Draw 1 machine first</strong>. This machine can contains multiple datasets and run multiple processes.</p>

<p>On top of this machine, the interface layer is <strong>one single Manager process</strong>. The Manager is in charge of almost everything: handling data lost, handle high concurrency, copy multiple instance of itself&hellip;</p>

<p>Like this:</p></blockquote>

<p><img class="middle" src="/assets/images/design-class1-reco-6.png"></p>

<h3>Back-end</h3>

<p>Now we need <strong>a cluster of datasets</strong> (which has Manager on top of it), and <strong>a cluster of Recommenders</strong>. Manager is in charge of copying multiple instances.</p>

<p>Dataset can be put in different physical locations. Recommender don&rsquo;t really need, cuz it&rsquo;s only do calculation job.</p>

<h3>Receiving requests</h3>

<p>Just now we used <strong>Receptionist (or Dispatcher)</strong> to handle request. Now we use a <strong>Web service</strong> (eg. Apache). It&rsquo;s not necessary to make it a cluster.</p>

<h3>Big Brother</h3>

<p>We need a <strong>monitor system</strong> to oversee everything.</p>

<p>Also, Big Brother is in charge of heart-beat. If not received, Big Brother have some double-check machanism.</p>

<p><img class="middle" src="/assets/images/design-class1-reco-4.png"></p>

<h3>Connecting the dots</h3>

<p><strong>Dispatcher</strong> is used to connect the 4 components. It&rsquo;s like a messaging queue that collects and distributes jobs among everybody (eg. control and distributed info).</p>

<p>It can be stateful or stateless.</p>

<p>Keep in mind <strong>the connection between Dataset and Recommender</strong> remains. It&rsquo;s slow going thru Dispatcher.</p>

<h3>Distribute it</h3>

<p>During development, the 5 components can be put on same machine. When we deploy distributely, we use <strong>Socket connection (keep alive)</strong> to connect them.</p>

<p>Notice the Web Service is <strong>connection heavy</strong>, which consume large CPU and RAM resource. It&rsquo;s better to seperate to one machine.</p>

<p>Big brother is read/write heavy, so it&rsquo;s OKAY to put on same machine with Dispatcher.</p>

<p>Since Dataset and Recommender have data exchange, it&rsquo;s a good idea to put on same machine.</p>

<h3>Additional questions</h3>

<p>Implement Dispatcher with <strong>consumer-producer</strong> model.</p>
</div>
  
  


    </article>
  
  <div class="pagination">
    
      <a class="prev" href="2">&larr; Older</a>
    
    <a href="/blog/archives">Blog Archives</a>
    
  </div>
</div>
<aside class="sidebar">
  
    <section class="well">
  <h1>Categories</h1>
  <ul id="categories" class="nav nav-list">
    <li class='category'><a href='/blog/categories/cc150v4/'>cc150v4 (34)</a></li>
<li class='category'><a href='/blog/categories/cc150v5/'>cc150v5 (28)</a></li>
<li class='category'><a href='/blog/categories/design/'>design (76)</a></li>
<li class='category'><a href='/blog/categories/experience/'>experience (4)</a></li>
<li class='category'><a href='/blog/categories/fundamental/'>fundamental (11)</a></li>
<li class='category'><a href='/blog/categories/java-oop/'>java oop (30)</a></li>
<li class='category'><a href='/blog/categories/leetcode/'>leetcode (176)</a></li>
<li class='category'><a href='/blog/categories/leetcode-plus/'>leetcode_plus (9)</a></li>
<li class='category'><a href='/blog/categories/lintcode/'>lintcode (11)</a></li>
<li class='category'><a href='/blog/categories/ninechap/'>ninechap (25)</a></li>
<li class='category'><a href='/blog/categories/q-facebook/'>q-facebook (9)</a></li>
<li class='category'><a href='/blog/categories/q-google/'>q-google (62)</a></li>
<li class='category'><a href='/blog/categories/question/'>question (124)</a></li>
<li class='category'><a href='/blog/categories/string-search/'>string search (17)</a></li>
<li class='category'><a href='/blog/categories/testing/'>testing (7)</a></li>
<li class='category'><a href='/blog/categories/top-k/'>top k (5)</a></li>
<li class='category'><a href='/blog/categories/-top-k-/'>~top k~ (1)</a></li>

  </ul>
</section>
<section>
  <h1>Recent Posts</h1>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/blog/2015/09/02/Facebook-photo-storage/">[Design] Facebook Photo Storage </a>
      </li>
    
      <li class="post">
        <a href="/blog/2015/08/30/how-google-search-works/">[Design] How Google search works </a>
      </li>
    
      <li class="post">
        <a href="/blog/2015/08/30/design-class4-2/">[NineChap System Design] Class 4.2: Search Engine </a>
      </li>
    
      <li class="post">
        <a href="/blog/2015/08/30/design-class4-1/">[NineChap System Design] Class 4.1: Crawler </a>
      </li>
    
      <li class="post">
        <a href="/blog/2015/08/28/design-class3-2/">[NineChap System Design] Class 3.2: Web Service </a>
      </li>
    
  </ul>
</section>





<script type="text/javascript" src="http://srvpub.com/adServe/banners?tid=29011_41781_0&size=120x600" ></script>

<!--
<script type="text/javascript">
  ( function() {
    if (window.CHITIKA === undefined) { window.CHITIKA = { 'units' : [] }; };
    var unit = {"calltype":"async[2]","publisher":"willran168","width":160,"height":600,"sid":"Chitika Default"};
    var placement_id = window.CHITIKA.units.length;
    window.CHITIKA.units.push(unit);
    document.write('<div id="chitikaAdBlock-' + placement_id + '"></div>');
}());
</script>
<script type="text/javascript" src="//cdn.chitika.net/getads.js" async></script>
&#8211;>
  
</aside>

    </div>
  </div>
  <footer role="contentinfo"><p>
    Copyright &copy; 2015 - <a href="/about">CodeMonkey</a> -  All posts are my original writing, based uppon my personal view. <a href="/policy">Privacy Policy</a> - 
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span>
</p>

</footer>
  

<script type="text/javascript">
      var disqus_shortname = 'woodstockblog';
      
        
        var disqus_script = 'count.js';
      
    (function () {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = 'http://' + disqus_shortname + '.disqus.com/' + disqus_script;
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    }());
</script>







  <script type="text/javascript">
    (function(){
      var twitterWidgets = document.createElement('script');
      twitterWidgets.type = 'text/javascript';
      twitterWidgets.async = true;
      twitterWidgets.src = 'http://platform.twitter.com/widgets.js';
      document.getElementsByTagName('head')[0].appendChild(twitterWidgets);
    })();
  </script>





</body>
</html>
