
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>Shuatiblog.com</title>
  <meta name="author" content="CodeMonkey">

  
  <meta name="description" content="Question link Given a matrix where every element is either ‘O’ or ‘X’, find the largest sub-square surrounded by ‘X’. (meaning that the 4 edges are &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://www.shuatiblog.com/posts/3/">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="/javascripts/ender.js"></script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <link href="/atom.xml" rel="alternate" title="Shuatiblog.com" type="application/atom+xml">
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href="http://fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="http://fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">

  
  <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-52495723-2']);
    _gaq.push(['_trackPageview']);

    (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
  </script>


</head>

<body   >
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  
<form action="https://www.google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="q" value="site:www.shuatiblog.com" />
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>
  
<ul class="main-navigation">
    <li><a href="/">
        <span class="blue_light">
            Shuatiblog.com
        </span>
       
    </a></li>
  <li><a href="/">Blog</a></li>
  <li><a href="/blog/archives">Archives</a></li>
  <li><a href="/about">About me</a></li>
</ul>

</nav>
  <div id="main">
    <div id="content">
      <div class="blog-index">
  
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2015/10/07/largest-subsquare-with-edge-filled/">[Question] Largest Sub-square With Edges Filled</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2015-10-07T00:00:00-05:00" pubdate data-updated="true"></time>
        
         | <a href="/blog/2015/10/07/largest-subsquare-with-edge-filled/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><h3>Question</h3>

<p><a href="www.geeksforgeeks.org/given-matrix-o-x-find-largest-subsquare-surrounded-x/index.html">link</a></p>

<blockquote><p>Given a matrix where every element is either ‘O’ or ‘X’, find the largest sub-square surrounded by ‘X’. (meaning that the 4 edges are filled with &lsquo;X&rsquo;)</p>

<p>Example Input:</p></blockquote>

<pre><code> {'X', 'O', 'X', 'X', 'X'},
 {'X', 'X', 'X', 'X', 'X'},
 {'X', 'X', 'O', 'X', 'O'},
 {'X', 'X', 'X', 'X', 'X'},
 {'X', 'X', 'X', 'O', 'O'},
</code></pre>

<blockquote><p>Output: 3. The square submatrix starting at (1, 1) is the largest sub-squre.</p>

<p>Example Input:</p></blockquote>

<pre><code> {'X', 'O', 'X', 'X', 'X', 'X'},
 {'X', 'O', 'X', 'X', 'O', 'X'},
 {'X', 'X', 'X', 'O', 'O', 'X'},
 {'X', 'X', 'X', 'X', 'X', 'X'},
 {'X', 'X', 'X', 'O', 'X', 'O'},
</code></pre>

<blockquote><p>Output: 4. The square submatrix starting at (0, 2) is the largest</p></blockquote>

<h3>Solution</h3>

<p>Read a very similar question &ndash; <strong>[Question] Maximum Square Sub-matrix With All 1s</strong></p>

<p>Typical DP question. Now the solution is to build 2 arrays to cache info. One horizontally and one, vertical.</p>

<blockquote><p>create two auxiliary arrays hor[N][N] and ver[N][N].</p>

<p>hor[i][j] is the number of horizontal continuous ‘X’ characters till mat[i][j] in mat[][].</p>

<p>ver[i][j] is the number of vertical continuous ‘X’ characters till mat[i][j] in mat[][].</p></blockquote>

<pre><code>mat[6][6] =  X  O  X  X  X  X
             X  O  X  X  O  X
             X  X  X  O  O  X
             O  X  X  X  X  X
             X  X  X  O  X  O
             O  O  X  O  O  O

hor[6][6] = 1  0  1  2  3  4
            1  0  1  2  0  1
            1  2  3  0  0  1
            0  1  2  3  4  5
            1  2  3  0  1  0
            0  0  1  0  0  0

ver[6][6] = 1  0  1  1  1  1
            2  0  2  2  0  2
            3  1  3  0  0  3
            0  2  4  1  1  4
            1  3  5  0  2  0
            0  0  6  0  0  0
</code></pre>

<p>After we got these, start from the bottom-right corner row by row up&hellip; For every mat[i][j], we compare hor[i][j] with ver[i][j] and pick the smaller one.</p>

<p>All we need to do next, is to check the other 2 edges. This solution is O(n<sup>3</sup>).</p>

<h3>Code</h3>

<p>C++ code provided by <a href="www.geeksforgeeks.org/given-matrix-o-x-find-largest-subsquare-surrounded-x/index.html">G4G</a>:</p>

<pre><code>int findSubSquare(int mat[][N])
{
    int max = 1; // Initialize result

    // Initialize the left-top value in hor[][] and ver[][]
    int hor[N][N], ver[N][N];
    hor[0][0] = ver[0][0] = (mat[0][0] == 'X');

    // Fill values in hor[][] and ver[][]
    for (int i=0; i&lt;N; i++)
    {
        for (int j=0; j&lt;N; j++)
        {
            if (mat[i][j] == 'O')
                ver[i][j] = hor[i][j] = 0;
            else
            {
                hor[i][j] = (j==0)? 1: hor[i][j-1] + 1;
                ver[i][j] = (i==0)? 1: ver[i-1][j] + 1;
            }
        }
    }

    // Start from the rightmost-bottommost corner element and find
    // the largest ssubsquare with the help of hor[][] and ver[][]
    for (int i = N-1; i&gt;=1; i--)
    {
        for (int j = N-1; j&gt;=1; j--)
        {
            // Find smaller of values in hor[][] and ver[][]
            // A Square can only be made by taking smaller
            // value
            int small = getMin(hor[i][j], ver[i][j]);

            // At this point, we are sure that there is a right
            // vertical line and bottom horizontal line of length
            // at least 'small'.

            // We found a bigger square if following conditions
            // are met:
            // 1)If side of square is greater than max.
            // 2)There is a left vertical line of length &gt;= 'small'
            // 3)There is a top horizontal line of length &gt;= 'small'
            while (small &gt; max)
            {
                if (ver[i][j-small+1] &gt;= small &amp;&amp;
                    hor[i-small+1][j] &gt;= small)
                {
                    max = small;
                }
                small--;
            }
        }
    }
    return max;
}
</code></pre>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2015/10/07/closest-leaf-binary-tree/">[Question] Find Cloest Leaf in Binary Tree</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2015-10-07T00:00:00-05:00" pubdate data-updated="true"></time>
        
         | <a href="/blog/2015/10/07/closest-leaf-binary-tree/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><h3>Question</h3>

<p><a href="www.geeksforgeeks.org/find-closest-leaf-binary-tree/index.html">link</a></p>

<blockquote><p>Given a Binary Tree and a key, find distance of the closest leaf.</p>

<p>Examples:</p></blockquote>

<pre><code>          1
        /    \    
       2       3
             /   \  
            5     6   
           /       \
          7         8
         / \       /
        9  10     11

Closest key to '8' is '11', so distance is 1 for '8'
Closest key to '3' is '2', so distance is 2 for '3'
Closest key to '5' is either '9' or '10', so distance is 2 for '5'
Closest key to '2' is '2' itself, so distance is 0 for '2' 
</code></pre>

<h3>Solution</h3>

<blockquote><p>traverse the given tree in preorder and keep track of ancestors (in a caching data struture, either it&rsquo;s List or an array with a correct pointer)</p></blockquote>

<p>When we find our target, we do 2 things:</p>

<ol>
<li><p>find <strong>closest distance on lower subtrees of current node</strong>.</p></li>
<li><p>for every ancester, find the <strong>closest distance on lower subtrees</strong>, then add with <strong>distance to ancester</strong>.</p></li>
</ol>


<p>Finally, return the smallest value seen above.</p>

<h3>Code</h3>

<p>Inspired by the code from <a href="www.geeksforgeeks.org/find-closest-leaf-binary-tree/index.html">G4G</a></p>

<pre><code>int answer;

public int findClosest(TreeNode root, int key) {
    answer = Integer.MAX_VALUE;
    helper(root, key, new ArrayList&lt;TreeNode&gt;());
    return answer;
}

private void helper(TreeNode node, int key, List&lt;TreeNode&gt; path) {
    if (node == null) {
        return;
    } else if (node.val != key) {
        path.add(node);
        helper(node.left, key, path);
        helper(node.right, key, path);
        path.remove(path.size() - 1);
    } else {
        // key matches with current node value
        answer = lenToLowerLeaf(node);
        // answer initially = cloest leaf from lower

        int len = path.size();
        for (int i = 0; i &lt; len; i++) {
            // for every ancestor, calculate distance and compare
            int ithToLowerLeaf = lenToLowerLeaf(path.get(i));
            answer = Math.min(answer, (len - i) + ithToLowerLeaf);
        }
    }
}

private int lenToLowerLeaf(TreeNode node) {
    if (node == null) {
        return Integer.MAX_VALUE;
    } else if (node.left == null &amp;&amp; node.right == null) {
        return 0;
    } else {
        return 1 + Math.min(lenToLowerLeaf(node.left), lenToLowerLeaf(node.right));
    }
}
</code></pre>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2015/10/07/all-string-placing-space/">[Amazon] All Strings by Placing Spaces</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2015-10-07T00:00:00-05:00" pubdate data-updated="true"></time>
        
         | <a href="/blog/2015/10/07/all-string-placing-space/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><h3>Question</h3>

<p><a href="www.geeksforgeeks.org/print-possible-strings-can-made-placing-spaces/index.html">link</a></p>

<blockquote><p>Given a string, print all possible strings that can be made by placing spaces (zero or one) in between them.</p>

<p>Input:  str[] = &ldquo;ABC&rdquo;</p>

<p>Output:</p></blockquote>

<pre><code>    ABC
    AB C
    A BC
    A B C
</code></pre>

<h3>Solution</h3>

<p>recursion.</p>

<h3>Code</h3>

<pre><code>public void printAll(String input) {
    if (input == null || input.length() &lt;= 1) {
        // since we insert space in-between chars, so
        return;
    }
    int len = input.length();
    // len &gt;= 2
    helper(input, len - 1);
}

private void helper(String s, int p) {
    if (p == 1) {
        System.out.println(s);
        // no insertion
        System.out.println(s.substring(0, 1) + " " + s.substring(1));
        // insert at position 1
    } else {
        helper(s, p - 1);
        helper(s.substring(0, p) + " " + s.substring(p), p - 1);
    }
}
</code></pre>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2015/10/04/seven-bridge/">[Fundamental] the 7 Bridges Problem</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2015-10-04T00:00:00-05:00" pubdate data-updated="true"></time>
        
         | <a href="/blog/2015/10/04/seven-bridge/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><h1>Overview</h1>

<p>In East Prussia(普鲁士), people try to walk all <a href="https://en.wikipedia.org/wiki/Seven_Bridges_of_K%C3%B6nigsberg">7 bridges</a> w/o crossing a bridge twice.</p>

<p>Leonhard Euler (pronounced &ldquo;oiler&rdquo;) – Swiss</p>

<h1>Euler path</h1>

<p>An Euler path, also called an Eulerian trail, is a walk on the graph edges of a graph which uses each graph edge in the original graph exactly once.</p>

<h2>Degree</h2>

<p>Node degree of a vertex: the number of edges incident with it.</p>

<h2>Euler Theorem</h2>

<p>A graph contains an euler path iffeither of the following cases hold:</p>

<ol>
<li>All except for two nodes have even degrees – the 2 odd-degree nodes must be start and end points</li>
<li>all nodes have even degrees.</li>
</ol>


<h1>Application</h1>

<p>networks, distributed systems, coding theory</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2015/10/02/shorest-manhattan-distance/">[Google] Shortest Manhattan Distance</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2015-10-02T00:00:00-05:00" pubdate data-updated="true"></time>
        
         | <a href="/blog/2015/10/02/shorest-manhattan-distance/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><h3>Question</h3>

<p><a href="http://www.mitbbs.com/article_t/JobHunting/33054861.html">link</a></p>

<blockquote><p>给一个 n*m 的房间，房间里存在各种可能的墙，房间的格子里已经放了 e 个器材，要
求新放一个器材，放置位置距其它 e 个器材的距离最近。Breadth-first search.</p></blockquote>

<h3>Solution</h3>

<blockquote><p>对 e个设备 BFS, 求每个设备到每个可以放新器材的点的距离，然后叠加。</p>

<p>最后O（n<sup>2</sup>）一遍找最小值。复杂度O（e*n<sup>2</sup>）</p></blockquote>

<p>As for whether we choose to check each equipment position, or check each vacant position, it&rsquo;s decided by how many equipment is there. If very little equipments (e is small), then this solution should work.</p>

<p>However, what is there is obstacles in the matrix?</p>

<p>We have to use BFS then. It took more space usage, but the time complexity should be same.</p>

<h3>Code</h3>

<pre><code>public void findCenter(int[][] input, int numberOfEquip) {
    int m = input.length;
    int n = input[0].length;

    // there's gonna be m * n positions
    // we gonna cumulate (numberOfEquip) distances for each position
    int[] dis = new int[m * n];

    // from the input map, find Equipments
    for (int i = 0; i &lt; m; i++) {
        for (int j = 0; j &lt; n; j++) {
            if (input[i][j] == 1) {
                // 1 represents equipment
                // when found, add the distance to every position
                cumulateDistance(i, j, dis, m, n);
            }
        }
    }

    // find the smallest cumulated distance from dis[].
    int sIndex = 0;
    int smallest = dis[0];
    for (int i = 0; i &lt; m * n; i++) {
        if (dis[i] &lt; smallest) {
            smallest = dis[i];
            sIndex = i;
        }
    }

    // index sIndex is the final answer
    System.out.println("Answer: " + (sIndex / n) + " " + (sIndex % n));
}

private void cumulateDistance(int x, int y, int[] dis, int m, int n) {
    for (int i = 0; i &lt; m * n; i++) {
        int a = i / n;
        int b = i % n;
        dis[i] += Math.abs(a - x) + Math.abs(b - y);
    }
}
</code></pre>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2015/09/02/Facebook-photo-storage/">[Design] Facebook Photo Storage</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2015-09-02T00:00:00-05:00" pubdate data-updated="true"></time>
        
         | <a href="/blog/2015/09/02/Facebook-photo-storage/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><h1>Stats</h1>

<p>Facebook has 1.5 billion monthly active users, 970 million daily active users <a href="http://newsroom.fb.com/company-info/">as of June 2015</a>.</p>

<p><img class="middle" src="/assets/images/facebook-user-count.png"></p>

<p>image from <a href="http://www.statista.com/statistics/264810/number-of-monthly-active-facebook-users-worldwide/">statista.com</a>.</p>

<p>In 2009, Facebook stores 15 billion photos for the user, which grows at 220 million per week, and 550,000 per second at peak.</p>

<p>It&rsquo;s 2015 now, you might want to mulitply these numbers by 3~6.</p>

<p>I have roughly estimated the statistics of Facebook users, Facebook photos and growth rate, just to give you an idea of the size of data Facebook has got:</p>

<blockquote><p>Total user: 1.5b</p>

<p>Total photoes: 150b, which is 100 photo/user</p>

<p>Each photo got 4 different sizes, so 600b photos are stored.</p>

<p>New photo per day: 500m</p>

<p>New photo per second: 6,000</p>

<p>Peak incoming photo per second: 3m</p></blockquote>

<h1>Old architecture</h1>

<p>3 tiers design:</p>

<ol>
<li><p><strong>Upload tier</strong> receives users’ photo uploads, scales the original images and saves them on the NFS storage tier.</p></li>
<li><p><strong>Photo serving tier</strong> receives HTTP requests for photo images and serves them from the NFS storage tier.</p></li>
<li><p><strong>NFS storage tier</strong> built on top of commercial storage appliances.</p></li>
</ol>


<blockquote><p><strong><a href="https://en.wikipedia.org/wiki/Network_File_System">Network File System</a></strong> (NFS) is a distributed file system protocol originally developed by Sun Microsystems in 1984, allowing a user on a client computer to access files over a network much like local storage is accessed.</p></blockquote>

<h2>Problem</h2>

<ol>
<li><p>there is an <strong>enormous amount of metadata</strong></p>

<p> &hellip; so much that is <a href="https://code.facebook.com/posts/685565858139515/needle-in-a-haystack-efficient-storage-of-billions-of-photos/">exceeds the caching abilities of the NFS storage tier</a>, <strong> resulting in multiple I/O operations</strong> per photo upload or read request</p></li>
</ol>


<h2>Solution</h2>

<ol>
<li><p>relies heavily on CDNs to serve photos.</p></li>
<li><p>Cachr: a caching server tier caching Facebook &ldquo;profile&rdquo; images.</p></li>
<li><p>NFS file handle cache &ndash; deployed on the photo serving tier eliminates some of the NFS storage tier metadata overhead</p></li>
</ol>


<h1>Haystack Photo Infrastructure</h1>

<p>The new photo infrastructure merges the <strong>photo serving</strong> and <strong>storage tier</strong> into one physical tier. It implements <strong>a HTTP based photo server</strong> which stores photos in a generic object store called Haystack.</p>

<p>Goal: eliminate any unnecessary metadata overhead for photo read operations, so that each read I/O operation was only reading actual photo data</p>

<p>5 main functional layers:</p>

<ol>
<li><p>HTTP server</p></li>
<li><p>Photo Store</p></li>
<li><p>Haystack Object Store</p></li>
<li><p>Filesystem</p></li>
<li><p>Storage</p></li>
</ol>


<h2>Storage</h2>

<p>The commodity machine HW typically is 2x quadcore CPU + 32GB RAM + 512MB NV-RAM cache + 12TB SATA drives.</p>

<blockquote><p><a href="https://en.wikipedia.org/wiki/Non-volatile_random-access_memory">Non-volatile random-access memory</a> (NVRAM) is random-access memory that retains its information when power is turned off (non-volatile).</p>

<p>This is in contrast to dynamic random-access memory (DRAM) and static random-access memory (SRAM)</p></blockquote>

<p>So each <strong>storage blade</strong> is around 10TB. Configured as <strong>RAID-6</strong> partition.</p>

<blockquote><p><a href="http://searchstorage.techtarget.com/definition/RAID-6-redundant-array-of-independent-disks">RAID 6</a>, also known as double-parity RAID, uses two parity stripes on each disk. It allows for two disk failures within the RAID set before any data is lost.</p></blockquote>

<p>Pros:</p>

<ol>
<li>adequate redundancy</li>
<li>excellent read performance</li>
<li>low storage cost down</li>
</ol>


<p>Cons:</p>

<p><strong>The poor write performance</strong> is partially mitigated by the <strong>RAID controller NVRAM write-back cache</strong>. Since the reads are mostly random, the NVRAM cache is fully reserved for writes.</p>

<p><strong>The disk caches are disabled</strong> in order to guarantee data consistency in the event of a crash or a power loss.</p>

<h2>Filesystem</h2>

<h3>How does filesystem read pictures?</h3>

<p>Photo read requests result in <strong>read() system calls</strong> at known offsets in these files.</p>

<p>Each file in the filesystem is represented by a structure called an inode which contains a block map that maps the logical file offset to the physical block offset on the physical volume.</p>

<p>For large files, the block map can be quite large.</p>

<h3>Problem</h3>

<p><strong>Block based filesystems</strong> maintain mappings for <strong>each logical block</strong>, and for large files, this information will not typically fit into the cached inode and is stored in indirect address blocks instead, which must be traversed in order to read the data for a file.</p>

<p>There can be several layers of indirection, so a single read could result in <strong>several I/Os</strong> (if not cached).</p>

<h3>Solution</h3>

<p><strong>Extent based filesystems</strong> maintain mappings only for contiguous ranges of blocks (extents). A block map for a contiguous large file could consist of only one extent which would fit in the inode itself.</p>

<blockquote><p><a href="https://goo.gl/uQA35V">An extent</a> is a contiguous area of storage reserved for a file in a file system, represented as a range. A file can consist of zero or more extents; <strong>one file fragment requires one extent</strong>. The direct benefit is in storing each range compactly as two numbers, instead of canonically storing every block number in the range.</p>

<p>Extent-based file systems can also <strong>eliminate most of the metadata overhead of large files</strong> that would traditionally be taken up by the block allocation tree&hellip; saving on storage space is pretty slight, but&hellip; <strong>the reduction in metadata is significant and reduces exposure to file system corruption</strong> as one bad sector in the <em>block allocation tree</em> causes much greater data loss than one bad sector in stored data.</p></blockquote>

<h3>Problem of Extent-based file systems</h3>

<p>However, if the file is severely fragmented and its blocks are not contiguous on the underlying volume, its block map can grow large as well.</p>

<h3>The solution</h3>

<p>Fragmentation can be mitigated by <strong>aggressively allocating a large chunk of space</strong> whenever growing the physical file.</p>

<p>Currently, the filesystem of choice is XFS, an extent based filesystem providing efficient file preallocation.</p>

<blockquote><p><strong><a href="https://en.wikipedia.org/wiki/XFS">XFS</a></strong> is a high-performance 64-bit journaling file system created by Silicon Graphics, Inc (SGI) in 1993.</p>

<p>&hellip;was ported to the Linux kernel in 2001. As of June 2014, XFS is supported by most Linux distributions, some of which use it as the default file system.</p>

<p>XFS enables <strong>extreme scalability of I/O threads</strong>, file system bandwidth, and size of files and of the file system itself when spanning multiple physical storage devices.</p>

<p>Space allocation is performed via extents with <strong>data structures stored in B+ trees</strong>, improving the overall performance of the file system, especially when handling large files.</p>

<p><strong>Delayed allocation</strong> assists in the prevention of file system fragmentation; <strong>online defragmentation</strong> is also supported. A feature unique to XFS is the <strong>pre-allocation of I/O bandwidth</strong> at a pre-determined rate, which is suitable for many real-time applications.</p></blockquote>

<h2>Haystack</h2>

<p>Haystack is a simple <strong>log structured (append-only) object store</strong>. Many images store in one Haystack. Typically, <a href="http://jishu.zol.com.cn/17742.html">Haystack Store is 100GB size</a>.</p>

<p>A Haystack consists of two files:</p>

<ol>
<li><strong>haystack store file</strong> (containing the needles)

<ol>
<li>superblock</li>
<li>needles (1 needle is 1 image)</li>
</ol>
</li>
<li><strong>an index file</strong></li>
</ol>


<h3>1. haystack store file</h3>

<p><img class="middle" src="/assets/images/851582_1409519009260319_311676661_n.jpg"></p>

<ol>
<li><p>The first 8KB of the haystack store is occupied by the <strong>superblock</strong>.</p></li>
<li><p>following the superblock are <strong>needles</strong></p>

<p> <strong>Needles represents the stored objects</strong>. Needle consisting of a header, the data, and a footer:</p>

<p> <img class="middle" src="/assets/images/851578_319395058204993_541487263_n.jpg"></p>

<p> A needle is uniquely identified by its &lt;Offset, Key, Alternate Key, Cookie> tuple.</p>

<p> Haystack doesn’t put any restriction on the values of the keys, and there can be needles with duplicate keys.</p></li>
</ol>


<h3>2. Index File</h3>

<p><strong>Needle</strong> consisting of a header, the data, and a footer:</p>

<p><img class="middle" src="/assets/images/851582_1374324519464800_699636937_n.jpg"></p>

<p>The index file provides the minimal metadata required to locate a particular needle in the haystack store file.</p>

<p><img class="middle" src="/assets/images/851582_314454922033518_1196942525_n.jpg"></p>

<p>The index file is not critical, as it can be rebuilt from the haystack store file if required.</p>

<p>The main purpose of the index: quick loading of the needle metadata into memory without traversing the larger Haystack store file, since the index is usually less than 1% the size of the store file.</p>

<h3>Summary</h3>

<p>All needles are stored in Haystack store file, and their location information is stored in Index File.</p>

<p>What is Needle? Needles represents the stored objects (1 needle &ndash; 1 image).</p>

<h2>Haystack Operations</h2>

<ol>
<li><p><strong>write</strong></p>

<p> append new needle to haystack store file.</p>

<p> later, corresponding index records are <strong>updated async</strong>.</p>

<p> In case of failure, any partial needles are discarded, and fix index from the end of the haystack.</p>

<p> You can&rsquo;t overwrite any needle, but you can insert using same key. Later, the needle <strong>with dup keys but largest offset</strong> became the most recent one.</p></li>
<li><p><strong>read</strong></p>

<p> <strong>parameters passed in</strong>: offset, key, alt key, cookie, data size</p>

<p> if key, alt key and cookie matches, and checksum correct and needle is not marked as deleted, return.</p></li>
<li><p><strong>delete</strong></p>

<p> marks needle as deleted (set 1 bit), but index is not modified.</p>

<p> the deleted space is not reclaimed unless <strong>compact the haystack</strong></p></li>
</ol>


<h2>Photo Store Server</h2>

<p>Photo Store Server is responsible for accepting HTTP requests and translating them to the corresponding Haystack store operations.</p>

<p>In order to minimize the number of I/Os required to retrieve photos, the server keeps an <strong>in-memory index of all photo offsets</strong>.</p>

<p>At startup, <strong>the (photo) server reads the haystack index file and populates the in-memory index</strong>. The in-memory index is different from the index file in Haystack, as it stores lesser information, like this:</p>

<p><img class="middle" src="/assets/images/851584_503528913060377_1268325854_n.jpg"></p>

<ol>
<li><p><strong>Photo Store Write/Modify Operation</strong></p>

<ol>
<li>writes photos to the haystack</li>
<li>updates the in-memory index</li>
</ol>


<p> if there are duplicate images, the one stored at a larger offset is valid.</p></li>
<li><p><strong>Photo Store Read Operation</strong></p>

<p> passed in:</p>

<ol>
<li>haystack id</li>
<li>a photo key,</li>
<li>size</li>
<li>cookie</li>
</ol>


<p> The server performs a lookup in the in-memory index based on the photo key and retrieves the offset of the needle containing the requested image.</p>

<p> Since haystack delete operation doesn’t update the haystack index file record. Therefore a freshly populated in-memory index can contain stale entries for the previously deleted photos. Read such photo will fail and the in-memory index is updated to 0.</p></li>
<li><p><strong>Photo Store Delete Operation</strong></p>

<p> After calling the haystack delete operation, the in-memory index is updated to &lsquo;offset = zero&rsquo;</p></li>
<li><p><strong>Compaction</strong></p>

<p> Compaction is an online operation which reclaims the space used by the deleted and duplicate needles.</p>

<p> creates a new haystack</p></li>
<li><p><strong>HTTP Server</strong></p>

<p> evhttp server</p>

<p> multiple threads, with each serving a single HTTP request. Workload is mostly I/O bound, thus the performance of the HTTP server is not critical.</p></li>
</ol>


<h1>Summary</h1>

<p>Storing photos as needles in the haystack <strong>eliminates the metadata overhead</strong> by aggregating hundreds of thousands of images in a single haystack store file.</p>

<p>This keeps the metadata overhead very small and allows us to <strong>store each needle’s location in the store file in an in-memory index</strong>.</p>

<p>This allows retrieval of an image’s data in <strong>a minimal number of I/O operations</strong>, eliminating all unnecessary metadata overhead.</p>

<p>Ref: <a href="https://code.facebook.com/posts/685565858139515/needle-in-a-haystack-efficient-storage-of-billions-of-photos/">https://code.facebook.com/posts/685565858139515/needle-in-a-haystack-efficient-storage-of-billions-of-photos/</a></p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2015/08/30/how-google-search-works/">[Design] How Google Search Works</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2015-08-30T00:00:00-05:00" pubdate data-updated="true"></time>
        
         | <a href="/blog/2015/08/30/how-google-search-works/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><h1>Overview</h1>

<p>Launched on Sep 15th, 1997</p>

<p><strong>60 trillion individual pages. 100 million GB data</strong>.</p>

<p><strong>40,000 search per second</strong>, or 3 billion search per day.</p>

<p>As of Feb 2015, 65% market share in US.</p>

<h1>1. Crawl</h1>

<p>Google crawl from 1 page to another using <strong><a href="https://support.google.com/webmasters/answer/182072?vid=1-635765406868848825-432642872">Googlebot</a></strong>. It starts from previous urls crawled, or augmented with <strong><a href="https://en.wikipedia.org/wiki/Site_map">Sitemap data</a></strong></p>

<blockquote><p><strong>A sitemap</strong> is a list of pages of a web site accessible to crawlers or users. It can be either a document in any form used as a planning tool for Web design, or a Web page that lists the pages on a Web site, typically organized in hierarchical fashion.</p></blockquote>

<h1>2. Indexing</h1>

<p>Compile the data (key content tags, atrributes, like title tags, ALT attributes). Google don&rsquo;t process rich media or dynamic files.</p>

<h1>3. Algorithm</h1>

<p>When search, pull all relevant results from the Index.</p>

<p>Rank the result based on 200+ factors, one of which is the <strong><a href="https://en.wikipedia.org/wiki/PageRank">PageRank</a></strong> for a given page.</p>

<blockquote><p><strong>PageRank</strong> is the measure of the importance of a page based on the incoming links from other pages. In simple terms, each link to a page on your site from another site adds to your site&rsquo;s PageRank.</p>

<p>Not all links are equal: Google works hard to identify spam links. The best types of links are those that are given based on the quality of your content.</p></blockquote>

<p>To rank higher, follow <a href="https://support.google.com/webmasters/answer/35769?vid=1-635765406868848825-432642872">Webmaster Guidelines</a>.</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2015/08/30/design-class4-2/">[NineChap System Design] Class 4.2: Search Engine</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2015-08-30T00:00:00-05:00" pubdate data-updated="true"></time>
        
         | <a href="/blog/2015/08/30/design-class4-2/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content">
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2015/08/30/design-class4-1/">[NineChap System Design] Class 4.1: Crawler</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2015-08-30T00:00:00-05:00" pubdate data-updated="true"></time>
        
         | <a href="/blog/2015/08/30/design-class4-1/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><h1>Overview</h1>

<p><strong>KISS &ndash; Keep It Simple, Sweetie</strong>.</p>

<p>In Today&rsquo;s lecture:</p>

<ol>
<li>write a crawler</li>
<li>thread-saft consumer &amp; producer</li>
<li>GFS, BigTable and MapReduce</li>
<li>Top 10 keyword/anagram using MapReduce</li>
<li>Log analysis</li>
</ol>


<h1>News Aggregator App</h1>

<ol>
<li><p>Info Collection</p>

<p> crawler</p></li>
<li><p>Info retrieval: rank, search and recommend.</p>

<p> They are in fact, all related to <strong>sorting</strong>.</p></li>
</ol>


<p><img class="middle" src="/assets/images/design-class4-News-Aggregator.png"></p>

<h2>Step 1, Info collection with crawler</h2>

<h3>crawler code</h3>

<p>Python:</p>

<pre><code>import urllib2

# request
url = "www.google.com"
request = urllib2.Request(url)
response = urllib2.urlopen(request)
page = response.read()

# save the file
webFile = open('webpage.html', 'web')
webFile.write(page)
webFile.close()
</code></pre>

<h3>Network process</h3>

<p>Use of <strong>socket</strong>.</p>

<p><img class="middle" src="/assets/images/design-class4-web-socket-1.png"></p>

<p>Socket is like the cellphone in the Call Center example.</p>

<blockquote><p><strong><a href="https://en.wikipedia.org/wiki/Network_socket">socket</a></strong> is an endpoint of an inter-process communication across a computer network.</p>

<p>Today, most communication between computers is based on the Internet Protocol; therefore most network sockets are <strong>Internet sockets</strong>.</p></blockquote>

<p>What is socket? Where is it?</p>

<p><img class="middle" src="/assets/images/design-class4-web-socket-2.png"></p>

<p>It&rsquo;s in-between <strong>Application Layer</strong> (HTTP, FTP, DNS) and <strong>Transport layer</strong> (UDP, TCP).</p>

<p>Remembering that socket is like a cellphone. It is an <strong>abstraction layer</strong>, that hinds the complexity of lower layer, thus making it easier to sende data in application layer.</p>

<h3>How is client connected to Server?</h3>

<p>3-way handshake. Read <strong>[Design] TCP 3-Way Handshake</strong></p>

<h3>HTML</h3>

<p><a href="http://www.w3schools.com/js/js_htmldom.asp">DOM tree</a>:</p>

<p><img class="middle" src="/assets/images/html-dom-tree.gif"></p>

<blockquote><p><a href="http://www.w3.org/TR/DOM-Level-2-Core/introduction.html">Document Object Model</a> (DOM) is an application programming interface (API) for valid HTML and well-formed XML documents. It <strong>defines the logical structure of documents</strong> and the way a document is accessed and manipulated.</p></blockquote>

<h3>How to crawler all the news</h3>

<ol>
<li>Go to index page</li>
<li>identify all the links (regex)</li>
</ol>


<h2>Crawl more websites</h2>

<h3>Simple design</h3>

<ol>
<li>use crawlers to find out all list pages</li>
<li>send the new lists to a Scheduler</li>
<li>Scheduler will use crawlers again, to crawl pages.</li>
</ol>


<p><img class="middle" src="/assets/images/design-class4-cralwer-arch-1.png"></p>

<p>This design is bad, cuz there is crawler waste. How can we <strong>reuse</strong> these crawlers???</p>

<h3>Adv design</h3>

<p>Design crawler that can crawl <strong>both list and pages</strong> information.</p>

<blockquote><p>Look at our crawler: the text extraction logic and Regex for <em>abc.com</em> and <em>bfe.com</em> are totally different. However, they both share the same crawling techniques.</p></blockquote>

<p>So we pass in all info a crawler task needs. Like:</p>

<p><img class="middle" src="/assets/images/design-class4-cralwer-arch-2.png"></p>

<ol>
<li><p>we gave <strong>more priority to list pages than content pages</strong>. Otherwise, your content get out of date soon.</p></li>
<li><p>Type include both list/content and source info.</p></li>
<li><p>status can be done, working, or new.</p></li>
<li><p>timestamps helps us make sure each crawler runs every hour (let&rsquo;s say)</p></li>
</ol>


<p>So when schedule <strong>pick the next crawler task</strong> to run, it will choose <strong>based on Priority</strong>. However if the <strong>timestamp (availableTime) is not yet reached</strong>, the job won&rsquo;t be executed.</p>

<p>If you crawler <strong>runs until endTime</strong> and haven&rsquo;t finish, force finish it. We should also add <strong>task created time</strong> to the info.</p>

<h3>How to identify similar news?</h3>

<p>Calculate the similarity between pages. More on this subject later.</p>

<h2>How to design Scheduler?</h2>

<p><img class="middle" src="/assets/images/design-class4-cralwer-arch-3.png"></p>

<h3>Solution with Sleep</h3>

<p>Define variables:</p>

<pre><code>taskTable&lt;table&gt; - store task lists
pageTable&lt;page&gt; - store page contents

task.url
task.state = new/working/done
task.type = list/page
</code></pre>

<p>code:</p>

<pre><code>while (true) {
    // get 1 task. If can't get, wait
    taskTable.lock();               // IMPORTANT
    newTask = taskTable.findOne(state == 'new')

    if (!newTask) {
        taskTable.unlock();         // IMPORTANT
        sleep(1000);                // IMPORTANT
        continue;
    }

    newTask.state = "working";
    taskTable.unlock();

    // execute the task, and insert to
    // either taskTable or pageTable
    newPage = Crawl(newTask.url);

    if (newTask.state === 'list') {
        // insert all urls to taskTable
        taskTable.lock();
        foreach (url in newPage) {
            taskTable.add(new task(url));
        }

        // mark the task as "done"
        newTask.state = "done";     // IMPORTANT
        taskTable.unlock();
    } else {
        // insert page content to pageTable
        pageTable.lock();
        pageTable.add(newPage.content());
        pageTable.unlock();

        // mark the task as "done"
        taskTable.lock();
        newTask.state = "done";     // IMPORTANT
        taskTable.unlock();
    }
}
</code></pre>

<h3>Solution with Conditional Variable</h3>

<p>What is Conditional Variable:</p>

<blockquote><p><a href="https://goo.gl/xOFXrY">A condition variable</a> is basically <strong>a container of threads that are waiting on a certain condition</strong>.</p>

<p>Monitors provide a mechanism for threads to temporarily give up exclusive access in order to wait for some condition to be met, before regaining exclusive access and resuming their task.</p></blockquote>

<p><img class="middle" src="/assets/images/design-class4-condition-variable.png"></p>

<p>Look at last 3 lines of code. <strong>Before going to sleep, CV have to release the lock</strong>, so that other threads can access the taskTable.</p>

<p>Then CV goes to sleep. <strong>Right after CV has been waken up</strong>, it has to lock the mutex again.</p>

<p>Solution w/ cv:</p>

<pre><code>while (true) {
    // get 1 task. If can't get, wait
    taskTable.lock();
    newTask = taskTable.findOne(state == 'new')

    if (!newTask) {
        taskTable.unlock();
        Cond_Wait(cond, taskTable);  // Modified
        continue;
    }

    newTask.state = "working";
    taskTable.unlock();

    // execute the task, and insert to
    // either taskTable or pageTable
    newPage = Crawl(newTask.url);

    if (newTask.state === 'list') {
        // insert all urls to taskTable
        taskTable.lock();
        foreach (url in newPage) {
            taskTable.add(new task(url));
            Cond_Signal(cond);       // Modified
        }

        // mark the task as "done"
        newTask.state = "done";
        taskTable.unlock();
    } else {
        // insert page content to pageTable
        pageTable.lock();
        pageTable.add(newPage.content());
        pageTable.unlock();

        // mark the task as "done"
        taskTable.lock();
        newTask.state = "done";
        taskTable.unlock();
    }
}
</code></pre>

<p>Why Good: no need to busy-spin (example above have to always wait 1 second). So this solution is better.</p>

<h3>Solution with Semaphore</h3>

<p>This is better than Condition Variable, cuz it&rsquo;s easier to implement. And Semaphore not only locks thread, it also <strong>can lock process</strong>.</p>

<p>CV locks on a certain condition. But Semaphore locks the numbers (of task, or resources etc).</p>

<p>Semaphore implementation (fairly difficult, read for interest):</p>

<pre><code>Wait(semaphore) {
    Lockf(semaphore);
    semaphore.value--;
    if (semaphore.value &lt; 0) {
        semaphore.processWaitList.Add(this.process);
        Release(semaphore);
        Block(this.process);
    } else {
        Release(semaphore);
    }
}

Signal(semaphore) {
    Lock(semaphore);
    semaphore.value++;
    if (semaphore.value &lt;= 0) {
        process = semaphore.processWaitList.pop();
        Wakeup(process);
    }
    Release(semaphore);
}
</code></pre>

<p>Note that in Java and C++, Wait() == acquire() and Signal() == release(). Read more <a href="http://tutorials.jenkov.com/java-util-concurrent/semaphore.html">Jenkov&rsquo;s post</a>.</p>

<p>code w/ semaphore:</p>

<pre><code>while (true) {
    // get 1 task. If can't get, wait
    Wait(numberOfNewTask);           // Modified

    taskTable.lock();
    newTask = taskTable.findOne(state == 'new')
    newTask.state = "working";
    taskTable.unlock();

    // execute the task, and insert to
    // either taskTable or pageTable
    newPage = Crawl(newTask.url);

    if (newTask.state === 'list') {
        // insert all urls to taskTable
        taskTable.lock();
        foreach (url in newPage) {
            taskTable.add(new task(url));
            Signal(numberOfNewTask); // Modified
        }

        // mark the task as "done"
        newTask.state = "done";
        taskTable.unlock();
    } else {
        // insert page content to pageTable
        pageTable.lock();
        pageTable.add(newPage.content());
        pageTable.unlock();

        // mark the task as "done"
        taskTable.lock();
        newTask.state = "done";
        taskTable.unlock();
    }
}
</code></pre>

<p><strong>What happens in Line 3 &lsquo;Wait(numberOfNewTask)&rsquo;</strong>? Well, the programs checks on the numberOfNewTask (counter) variable, and:</p>

<ol>
<li>If there is 1 or more tasks, just proceed.</li>
<li>If no tasks available, block itself and wait there. (Later someone will wake it up and it will resume).</li>
</ol>


<h3>Design an consumer-producer</h3>

<p>Stay tuned for future post.</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2015/08/28/design-class3-2/">[NineChap System Design] Class 3.2: Web Service</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2015-08-28T00:00:00-05:00" pubdate data-updated="true"></time>
        
         | <a href="/blog/2015/08/28/design-class3-2/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><h1>Question 4</h1>

<p><strong>fix MP3 problem</strong></p>

<p>The process of fetching a MP3 (from CDN):</p>

<p><img class="middle" src="/assets/images/design-class3-client-request-mp3.png"></p>

<ol>
<li>aquire MP3 link, and send request</li>
<li>send request to CDN</li>
<li>CDN receive request, find MP3</li>
<li>response to client</li>
<li>play the music</li>
</ol>


<p><img class="middle" src="/assets/images/design-class3-client-request-mp3-errors.png"></p>

<p>Question: in step 2, there&rsquo;s more Network error, but in step 4, there&rsquo;s no Network error, but Timeout. Why?</p>

<h2>Fix step 2, Network error</h2>

<p>Problem is: MP3 url invalid. It actually comes from a failed CDN sever.</p>

<p>Solution: fix the server.</p>

<h2>Fix step 3, CDN can&rsquo;t find MP3</h2>

<p>Problem associated with <strong>Anti-Leech</strong>.</p>

<blockquote><p><strong><a href="https://en.wikipedia.org/wiki/Leech_(computing">a leech</a>)</strong> is one who benefits, usually deliberately, from others&#8217; information or effort but does not offer anything in return.</p>

<p>Example: Wi-Fi leeches, Direct linking (or hot-linking) and In most P2P-networks, leeching is whose who download too much.</p>

<p><strong><a href="https://answers.yahoo.com/question/index?qid=1006042926419">Anti-Leech</a></strong> specializes in protecting file downloads and stopping bandwidth leeching.</p></blockquote>

<p>See that some P2P and leeching software will steal your url links, so the MP3 url expiration time is 5 minutes.</p>

<p>So when CDN server&rsquo;s clock and web server&rsquo;s clock are not synchronized well, MP3 url can expire.</p>

<p>Solution: every 10 minutes sync CDN clock with web server clock.</p>

<h2>Fix step 4, Timeout error</h2>

<p>Some MP3 are relatively large. Thus timeout.</p>

<blockquote><p>MP3 performs better at higher bps, and aac(Advanced Audio Coding) works better at lower bps.</p></blockquote>

<p>Solution:</p>

<ol>
<li><p>compress MP3 to 48bps, or use aac format. So, play lower-rate music first, then switch automatically.</p></li>
<li><p>pre-load a music while previous is playing.</p></li>
<li><p>optimize CDN</p></li>
</ol>


<blockquote><p><strong><a href="https://en.wikipedia.org/wiki/Content_delivery_network">CDN</a></strong> content delivery network is a large <strong>distributed system of servers</strong> deployed in <strong>multiple data centers</strong> across the Internet.</p>

<p>The goal of a CDN is to serve content to end-users with high availability and high performance.</p></blockquote>

<p><img class="middle" src="/assets/images/design-class3-CDN.png"></p>

<p>Which CDN should client choose?</p>

<blockquote><p>Not DNS, but web server calculates which to choose. It can be calculated using IP distance, or ISP provider, but not accurate.</p>

<p>We can also use local desktop apps (in different locations) to ping CDN servers. This may violate user privacy, though.</p></blockquote>

<h2>Fix step 5, Fail to play</h2>

<p>Problem: some files got wrong decoding.</p>

<h2>Fix step 6, unkown error</h2>

<p>Problem: some users close the page while MP3 loading.</p>

<h1>Question 5</h1>

<p><strong>fix player problem</strong></p>

<p>Problem: iOS device can never play Flash.</p>

<p>Solution: develop HTML5 player.</p>

<h2>5.2 how to evaluate that you solved the problem</h2>

<ol>
<li><p>user complains</p></li>
<li><p><strong>important</strong>: daily retention rate!</p></li>
</ol>


<p>We can&rsquo;t use daily active user, cuz it depends on marketing, competitors, and infrastructure changes.</p>

<p><strong>One day retention rate</strong>:</p>

<p><img class="middle" src="/assets/images/design-class3-user-retention.png"></p>

<blockquote><p>Today’s visitor = {U1, U3, U7, U9, U10}</p>

<p>Tomorrow&rsquo;s visitor = {U2, U3, U9,}</p>

<p>Today’s one day retention rate = 2/5</p></blockquote>

<h1>Question 6 秒杀</h1>

<h2>Design</h2>

<p>Queue A and Queue B</p>

<p><img class="middle" src="/assets/images/design-class3-miao-sha.png"></p>

<h3>Queue A</h3>

<p>Many queues, each one locates on a individual web server or reverse proxy. It is mainly used to accept large amount of requests coming from the clients.</p>

<p>Each machine may takes 10,000 or more requests per second.</p>

<p>Queue A will redirect most requests to a static page (cached).</p>

<h3>Queue B</h3>

<p>Queue B is a single machine, to aviod distributed problems. It takes in small amount of requests and decides results (eg. redirect to payment page).</p>

<blockquote><p>Now, why do we need 2 queues, not 1?</p>

<p>Think about a hospital. Queue A is the hospital lobby and security guard, and Queue B is the queue of patience.</p></blockquote>

<h2>How to reduce traffic</h2>

<ol>
<li>no image</li>
<li>cache more static pages</li>
<li>reverse proxy: batch sending the requests</li>
</ol>


<p>Also, can use front-end javascript to prevent clicking. There are method to bypass, so we need to check IP or do some filtering.</p>

<h2>How to keep it simple?</h2>

<ol>
<li>no DB: basic logic. But rmb to use a log file</li>
<li>no lock</li>
</ol>


<h2>How to improve stability</h2>

<ol>
<li>use new server to do <strong>Miao Sha</strong>, in case of crash</li>
<li>asyc prcessing everything! Don&rsquo;t let other people wait, in case of crash.</li>
</ol>


<h3>How to defend hackers</h3>

<ol>
<li>IP address (to defent auto softwares), but it&rsquo;s easy for hackers to fake IP address</li>
<li>CAPTCHA</li>
</ol>


<blockquote><p><strong><a href="https://en.wikipedia.org/wiki/CAPTCHA">CAPTCHA</a></strong> (an acronym for &ldquo;Completely Automated Public Turing test to tell Computers and Humans Apart&rdquo;) is a type of challenge-response test used in computing to determine whether or not the user is human.</p></blockquote>

<h2>follow-up</h2>

<p>How to design 12306 (support several million QPS)</p>
</div>
  
  


    </article>
  
  <div class="pagination">
    
      <a class="prev" href="4">&larr; Older</a>
    
    <a href="/blog/archives">Blog Archives</a>
    
    <a class="next" href="2">Newer &rarr;</a>
    
  </div>
</div>
<aside class="sidebar">
  
    <section class="well">
  <h1>Categories</h1>
  <ul id="categories" class="nav nav-list">
    <li class='category'><a href='/blog/categories/cc150v4/'>cc150v4 (34)</a></li>
<li class='category'><a href='/blog/categories/cc150v5/'>cc150v5 (28)</a></li>
<li class='category'><a href='/blog/categories/design/'>design (77)</a></li>
<li class='category'><a href='/blog/categories/experience/'>experience (4)</a></li>
<li class='category'><a href='/blog/categories/fundamental/'>fundamental (18)</a></li>
<li class='category'><a href='/blog/categories/java-oop/'>java oop (36)</a></li>
<li class='category'><a href='/blog/categories/leetcode/'>leetcode (177)</a></li>
<li class='category'><a href='/blog/categories/leetcode-plus/'>leetcode_plus (9)</a></li>
<li class='category'><a href='/blog/categories/lintcode/'>lintcode (16)</a></li>
<li class='category'><a href='/blog/categories/ninechap/'>ninechap (25)</a></li>
<li class='category'><a href='/blog/categories/q-facebook/'>q-facebook (9)</a></li>
<li class='category'><a href='/blog/categories/q-google/'>q-google (63)</a></li>
<li class='category'><a href='/blog/categories/question/'>question (133)</a></li>
<li class='category'><a href='/blog/categories/testing/'>testing (5)</a></li>
<li class='category'><a href='/blog/categories/z-string-search/'>z-string-search (17)</a></li>
<li class='category'><a href='/blog/categories/z-testing/'>z-testing (2)</a></li>
<li class='category'><a href='/blog/categories/z-top-k/'>z-top-k (6)</a></li>

  </ul>
</section>
<section>
  <h1>Recent Posts</h1>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/blog/2015/11/21/swizzle-sort/">[Question] Swizzle Sort </a>
      </li>
    
      <li class="post">
        <a href="/blog/2015/11/18/strategy-pattern/">[Design] Strategy design pattern </a>
      </li>
    
      <li class="post">
        <a href="/blog/2015/11/15/partition-problem/">[Question] Partition Problem (divide array into halves) </a>
      </li>
    
      <li class="post">
        <a href="/blog/2015/11/04/Best-Time-to-Buy-and-Sell-Stock-IV/">[LeetCode 188] Best Time to Buy and Sell Stock IV </a>
      </li>
    
      <li class="post">
        <a href="/blog/2015/10/28/arraylist-implementation/">[Java OOP] Java ArrayList implementation </a>
      </li>
    
  </ul>
</section>





<script type="text/javascript" src="http://srvpub.com/adServe/banners?tid=29011_41781_0&size=120x600" ></script>

<!--
<script type="text/javascript">
  ( function() {
    if (window.CHITIKA === undefined) { window.CHITIKA = { 'units' : [] }; };
    var unit = {"calltype":"async[2]","publisher":"willran168","width":160,"height":600,"sid":"Chitika Default"};
    var placement_id = window.CHITIKA.units.length;
    window.CHITIKA.units.push(unit);
    document.write('<div id="chitikaAdBlock-' + placement_id + '"></div>');
}());
</script>
<script type="text/javascript" src="//cdn.chitika.net/getads.js" async></script>
&#8211;>
  
</aside>

    </div>
  </div>
  <footer role="contentinfo"><p>
    Copyright &copy; 2015 - <a href="/about">CodeMonkey</a> -  All posts are my original writing, based uppon my personal view. <a href="/policy">Privacy Policy</a> - 
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span>
</p>

</footer>
  

<script type="text/javascript">
      var disqus_shortname = 'woodstockblog';
      
        
        var disqus_script = 'count.js';
      
    (function () {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = 'http://' + disqus_shortname + '.disqus.com/' + disqus_script;
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    }());
</script>







  <script type="text/javascript">
    (function(){
      var twitterWidgets = document.createElement('script');
      twitterWidgets.type = 'text/javascript';
      twitterWidgets.async = true;
      twitterWidgets.src = 'http://platform.twitter.com/widgets.js';
      document.getElementsByTagName('head')[0].appendChild(twitterWidgets);
    })();
  </script>





</body>
</html>
